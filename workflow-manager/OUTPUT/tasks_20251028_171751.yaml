task:
  id: 6
  name: "Add Equity Curve CSV Export Functionality"

context:
  description: |
    This task implements CSV export functionality for frame-by-frame equity curve data,
    enabling users to analyze backtest results in external tools like Excel, Python, or R.
    The equity curve represents the time-series evolution of account value throughout a
    backtest, combining balance, unrealized PnL, and position states.
    
    Currently, the application provides trade-level exports (individual trades CSV) and
    summary-level exports (metrics CSV, full JSON/HTML reports), but lacks the intermediate
    time-series data that many analysts need for custom visualizations, statistical analysis,
    correlation studies, and strategy validation. This gap prevents users from performing
    deeper analysis on equity dynamics, drawdown patterns, and temporal characteristics.
    
    The implementation follows established patterns from existing export_trades_csv and
    export_metrics_csv functions in the backtesting screen, ensuring consistency in filename
    generation, error handling, and UI integration. The CSV output includes comprehensive
    frame data: timestamp, price, equity, balance, unrealized/realized PnL, drawdown metrics,
    peak equity tracking, and position details.
    
    This feature completes the export suite, providing users with three complementary views:
    transaction-level (trades CSV), time-series (equity curve CSV), and summary-level
    (metrics CSV/JSON), enabling comprehensive offline analysis workflows.

  key_points:
    - "Follows existing CSV export patterns for consistency with export_trades_csv and export_metrics_csv"
    - "Exports BacktestFrame array with all equity-related fields plus position state"
    - "Uses consistent filename convention: backtest_equity_{ticker}_{timeframe}_{date}_{timestamp}.csv"
    - "Handles NaN/Infinity values appropriately to ensure CSV parsability"
    - "Integrates seamlessly into existing export UI section alongside other export options"
    - "Provides 13 columns of data per frame: timestamp, datetime, price, equity, balance, unrealized PnL, realized PnL, drawdown %, peak equity, position side, position size, margin used, margin available"
    - "Supports both candle-based and tick-based backtests with identical output format"

files:
  - path: "/home/molaco/Documents/flowsurface-binance/src/screen/backtesting.rs"
    description: |
      Main backtesting screen component. Will be modified to:
      1. Add ExportEquityCurveCsv variant to Message enum
      2. Add handler for ExportEquityCurveCsv in update() method
      3. Implement export_equity_curve_csv() function following the pattern of
         export_trades_csv() and export_metrics_csv()
      4. Add "Equity Curve (CSV)" button to export_section_view() UI
  - path: "/home/molaco/Documents/flowsurface-binance/backtesting/src/types.rs"
    description: |
      Core types for backtesting. Contains BacktestFrame struct definition with
      all equity-related fields (timestamp, equity, balance, unrealized_pnl,
      realized_pnl, drawdown, peak_equity, position). May need review to ensure
      all necessary fields are available for CSV export.
  - path: "/home/molaco/Documents/flowsurface-binance/tests/integration/backtest_export_test.rs"
    description: |
      New integration test file for CSV export functionality. Will test:
      1. Equity curve CSV export generates valid CSV files
      2. CSV headers match expected columns
      3. CSV data rows contain correct values from BacktestFrame array
      4. Filename generation follows pattern (ticker_timeframe_date_timestamp.csv)
      5. NaN/Infinity value handling in CSV output

functions:
  - file: "src/screen/backtesting.rs"
    items:
      - type: "enum_variant"
        name: "Message::ExportEquityCurveCsv"
        description: |
          Message variant to trigger equity curve CSV export action.
          Follows the same pattern as ExportTradesCsv and ExportMetricsCsv.
          
      - type: "method"
        name: "BacktestingScreen::export_equity_curve_csv"
        description: |
          Exports equity curve data from BacktestFrame array to CSV file.
          
          Signature: fn export_equity_curve_csv(&self, frames: &[BacktestFrame]) -> Result<(), String>
          
          Generates filename using pattern: backtest_equity_{ticker}_{timeframe}_{start_date}_{timestamp}.csv
          
          CSV columns:
          - Timestamp (formatted as YYYY-MM-DD HH:MM)
          - Price (current market price, 8 decimal precision)
          - Equity (total account value including unrealized PnL, 2 decimal precision)
          - Balance (cash balance, 2 decimal precision)
          - Unrealized PnL (open position profit/loss, 2 decimal precision)
          - Realized PnL (closed trade profit/loss, 2 decimal precision)
          - Drawdown % (percentage from peak, 2 decimal precision)
          - Peak Equity (historical peak equity, 2 decimal precision)
          - Position Side (Long/Short/Flat)
          - Position Size (quantity in base currency, 8 decimal precision)
          - Margin Used (margin allocated to positions, 2 decimal precision)
          - Margin Available (remaining margin, 2 decimal precision)
          
          Handles NaN/Infinity values by replacing with 0.0 or empty string.
          Uses format_timestamp helper for datetime formatting.
          Logs export success/failure with filename and row count.
        preconditions: |
          - frames slice must not be empty
          - self.config must contain valid ticker, timeframe, and start_date
          - File system must be writable in current directory
        postconditions: |
          - CSV file created with specified filename
          - File contains header row plus one row per frame
          - All numeric values are properly formatted and validated
          - Success/error logged appropriately
          
      - type: "function"
        name: "format_frame_position_side"
        description: |
          Helper function to format PositionSide enum for CSV output.
          
          Signature: fn format_frame_position_side(position: &Position) -> &'static str
          
          Returns "Long", "Short", or "Flat" based on position.side field.
          
      - type: "function"
        name: "sanitize_float_for_csv"
        description: |
          Helper function to sanitize floating point values for CSV output.
          
          Signature: fn sanitize_float_for_csv(value: f64, precision: usize) -> String
          
          Handles NaN and Infinity values by returning "0.00" (or appropriate precision).
          Returns properly formatted decimal string for finite values.
          Uses specified precision for decimal places.
          
  - file: "src/screen/backtesting.rs"
    items:
      - type: "method"
        name: "BacktestingScreen::update - Message::ExportEquityCurveCsv handler"
        description: |
          Handler case in update() method for ExportEquityCurveCsv message.
          
          Pattern matches existing ExportTradesCsv and ExportMetricsCsv handlers:
          - Checks if self.results is Some
          - Calls self.export_equity_curve_csv(&results.frames)
          - Logs error or success message
          - Returns Task::none()
          
          Location: Insert after Message::ExportMetricsCsv handler (around line 696)
        preconditions: |
          - Backtest must have completed successfully (self.results is Some)
        postconditions: |
          - CSV export attempted
          - Result logged to console
          
  - file: "src/screen/backtesting.rs"
    items:
      - type: "method"
        name: "BacktestingScreen::export_section_view - add equity curve button"
        description: |
          Add button to export section for equity curve CSV export.
          
          Modification to export_section_view() method (around line 1171):
          Add new button to the row of export buttons:
          button("Equity Curve (CSV)").on_press(Message::ExportEquityCurveCsv)
          
          Button should be inserted between "Metrics (CSV)" and "Full Report (JSON)" buttons.
          Follows same styling as other export buttons.
        postconditions: |
          - New button visible in Results tab export section
          - Button triggers ExportEquityCurveCsv message on click
          - Button only enabled when results exist (handled by parent logic)

formal_verification:
  needed: false
  level: "None"
  explanation: |
    CSV export functionality is a straightforward data formatting and I/O operation that
    does not require formal verification. The task involves iterating through pre-calculated,
    already-validated equity data from BacktestResults.frames and writing it to a CSV file
    with proper formatting and error handling.
    
    Key reasons verification is not needed:
    1. Data source is pre-validated: All equity values in BacktestResults have already
       passed 5-layer validation during backtest execution (component validation,
       equity calculation validation, frame emission guards, UI transformation filters,
       and rendering safety checks).
    2. No complex algorithms: CSV export is a simple iteration and formatting operation,
       similar to existing trade/metrics exports already in the codebase.
    3. No state management: The operation is stateless - read frames, format data, write file.
    4. No financial calculations: No arithmetic operations on equity values, only formatting
       and serialization of already-computed numbers.
    5. Unit testing is sufficient: CSV structure, header formatting, edge cases (empty data,
       special characters), and file I/O can all be verified with standard unit tests using
       temporary directories or in-memory buffers.
    6. Existing precedent: The codebase already implements similar exports (export_trades_csv,
       export_metrics_csv) at lines 1187-1311 without formal verification requirements.
    
    The only correctness properties needed are:
    - CSV headers match data columns
    - All rows contain matching field counts
    - Timestamps and equity values are properly formatted
    - File I/O errors are handled appropriately
    
    These are all testable via straightforward unit tests and do not require formal verification.

tests:
  strategy:
    approach: "unit tests"
    rationale:
      - "CSV export is a data transformation operation best suited for unit testing"
      - "Tests verify correct CSV structure, header formatting, and data serialization"
      - "Edge cases like NaN/Infinity values, empty data, and single frame scenarios need coverage"
      - "File I/O can be tested using temporary directories or in-memory validation"
      - "Following existing patterns from export_trades_csv and export_metrics_csv functions"

  implementation:
    file: "/home/molaco/Documents/flowsurface-binance/backtesting/src/types.rs"
    location: "in existing test module"
    code: |
      #[cfg(test)]
      mod tests {
          use super::*;
          use exchange::util::Price;
          
          fn create_test_frame(
              timestamp: i64,
              equity: f64,
              balance: f64,
              unrealized_pnl: f64,
              realized_pnl: f64,
              drawdown: f64,
              position_side: PositionSide,
              position_size: f64,
          ) -> BacktestFrame {
              BacktestFrame {
                  timestamp,
                  price: Price::from_f32(50000.0),
                  position: Position {
                      side: position_side,
                      size: position_size,
                      entry_price: Price::from_f32(49000.0),
                      unrealized_pnl,
                      realized_pnl,
                  },
                  equity,
                  balance,
                  margin_used: 0.0,
                  margin_available: balance,
                  unrealized_pnl,
                  realized_pnl,
                  drawdown,
                  peak_equity: equity,
                  orders: vec![],
                  fills: vec![],
              }
          }
          
          #[test]
          fn test_export_equity_curve_csv_basic() {
              // Test basic CSV export with valid data
              let frames = vec![
                  create_test_frame(1000, 10000.0, 10000.0, 0.0, 0.0, 0.0, PositionSide::Flat, 0.0),
                  create_test_frame(2000, 10100.0, 10000.0, 100.0, 0.0, 0.0, PositionSide::Long, 1.0),
                  create_test_frame(3000, 10200.0, 10050.0, 150.0, 50.0, 0.0, PositionSide::Long, 1.0),
                  create_test_frame(4000, 10150.0, 10050.0, 100.0, 50.0, 0.0049, PositionSide::Long, 1.0),
              ];
              
              let csv_content = export_frames_to_csv_string(&frames);
              
              // Verify header row
              let lines: Vec<&str> = csv_content.lines().collect();
              assert_eq!(lines.len(), 5); // header + 4 data rows
              assert_eq!(
                  lines[0],
                  "Timestamp,DateTime,Price,Equity,Balance,Unrealized PnL,Realized PnL,Drawdown %,Peak Equity,Position Side,Position Size,Margin Used,Margin Available"
              );
              
              // Verify first data row
              let first_data = lines[1];
              assert!(first_data.starts_with("1000,"));
              assert!(first_data.contains("10000.00"));
              assert!(first_data.contains("Flat"));
              
              // Verify position data is included
              let second_data = lines[2];
              assert!(second_data.contains("Long"));
              assert!(second_data.contains("1.00"));
          }
          
          #[test]
          fn test_export_equity_curve_csv_handles_nan_infinity() {
              // Test that NaN and Infinity values are properly handled
              let frames = vec![
                  create_test_frame(1000, 10000.0, 10000.0, 0.0, 0.0, 0.0, PositionSide::Flat, 0.0),
                  create_test_frame(2000, f64::NAN, 10000.0, f64::NAN, 0.0, 0.0, PositionSide::Flat, 0.0),
                  create_test_frame(3000, f64::INFINITY, 10000.0, 0.0, f64::NEG_INFINITY, 0.0, PositionSide::Flat, 0.0),
                  create_test_frame(4000, 10100.0, 10100.0, 0.0, 100.0, 0.0, PositionSide::Flat, 0.0),
              ];
              
              let csv_content = export_frames_to_csv_string(&frames);
              let lines: Vec<&str> = csv_content.lines().collect();
              
              // NaN should be converted to empty string or "NaN"
              let nan_line = lines[2];
              assert!(nan_line.contains("NaN") || nan_line.contains(",,"));
              
              // Infinity should be handled appropriately
              let inf_line = lines[3];
              assert!(inf_line.contains("Infinity") || inf_line.contains("Inf") || inf_line.contains(",,"));
              
              // Valid data after invalid should still work
              assert_eq!(lines.len(), 5);
          }
          
          #[test]
          fn test_export_equity_curve_csv_empty_frames() {
              // Test export with no frames
              let frames: Vec<BacktestFrame> = vec![];
              let csv_content = export_frames_to_csv_string(&frames);
              
              // Should still have header
              let lines: Vec<&str> = csv_content.lines().collect();
              assert_eq!(lines.len(), 1);
              assert!(lines[0].contains("Timestamp"));
          }
          
          #[test]
          fn test_export_equity_curve_csv_single_frame() {
              // Test with single frame
              let frames = vec![
                  create_test_frame(1000, 10000.0, 10000.0, 0.0, 0.0, 0.0, PositionSide::Flat, 0.0),
              ];
              
              let csv_content = export_frames_to_csv_string(&frames);
              let lines: Vec<&str> = csv_content.lines().collect();
              
              assert_eq!(lines.len(), 2); // header + 1 data row
              assert!(lines[1].contains("10000.00"));
          }
          
          #[test]
          fn test_export_equity_curve_csv_all_position_types() {
              // Test all position types are correctly exported
              let frames = vec![
                  create_test_frame(1000, 10000.0, 10000.0, 0.0, 0.0, 0.0, PositionSide::Flat, 0.0),
                  create_test_frame(2000, 10100.0, 10000.0, 100.0, 0.0, 0.0, PositionSide::Long, 1.5),
                  create_test_frame(3000, 10200.0, 10000.0, 200.0, 0.0, 0.0, PositionSide::Short, 2.0),
              ];
              
              let csv_content = export_frames_to_csv_string(&frames);
              let lines: Vec<&str> = csv_content.lines().collect();
              
              assert!(lines[1].contains("Flat"));
              assert!(lines[1].contains("0.00")); // Flat position has zero size
              assert!(lines[2].contains("Long"));
              assert!(lines[2].contains("1.50"));
              assert!(lines[3].contains("Short"));
              assert!(lines[3].contains("2.00"));
          }
          
          #[test]
          fn test_export_equity_curve_csv_datetime_formatting() {
              // Test timestamp to datetime conversion
              let frames = vec![
                  create_test_frame(1704067200000, 10000.0, 10000.0, 0.0, 0.0, 0.0, PositionSide::Flat, 0.0), // 2024-01-01 00:00:00
              ];
              
              let csv_content = export_frames_to_csv_string(&frames);
              let lines: Vec<&str> = csv_content.lines().collect();
              
              // Should contain both timestamp and formatted datetime
              assert!(lines[1].contains("1704067200000"));
              assert!(lines[1].contains("2024-01-01") || lines[1].contains("2024"));
          }
          
          #[test]
          fn test_export_equity_curve_csv_precision() {
              // Test numeric precision in output
              let frames = vec![
                  create_test_frame(1000, 10000.123456, 9999.654321, 0.469135, 0.0, 0.0123456, PositionSide::Flat, 0.0),
              ];
              
              let csv_content = export_frames_to_csv_string(&frames);
              let lines: Vec<&str> = csv_content.lines().collect();
              
              // Equity should be formatted with 2 decimal places (standard for currency)
              assert!(lines[1].contains("10000.12") || lines[1].contains("10000.13"));
              
              // Drawdown should be formatted as percentage with appropriate precision
              assert!(lines[1].contains("1.23") || lines[1].contains("1.2"));
          }
          
          #[test]
          fn test_export_equity_curve_csv_parseable() {
              // Test that output is valid CSV that can be parsed
              let frames = vec![
                  create_test_frame(1000, 10000.0, 10000.0, 0.0, 0.0, 0.0, PositionSide::Flat, 0.0),
                  create_test_frame(2000, 10100.0, 10000.0, 100.0, 0.0, 0.0, PositionSide::Long, 1.0),
              ];
              
              let csv_content = export_frames_to_csv_string(&frames);
              
              // Parse CSV manually
              let lines: Vec<&str> = csv_content.lines().collect();
              assert!(lines.len() >= 2);
              
              // Each line should have same number of commas
              let header_commas = lines[0].matches(',').count();
              for line in lines.iter().skip(1) {
                  let data_commas = line.matches(',').count();
                  assert_eq!(
                      data_commas, header_commas,
                      "All rows must have same number of fields"
                  );
              }
          }
          
          #[test]
          fn test_export_equity_curve_csv_filename_pattern() {
              // Test filename generation follows convention
              let ticker = "BTCUSDT";
              let timeframe = "M5";
              let date = "2024-01-01";
              
              let filename = generate_equity_csv_filename(ticker, timeframe, date);
              
              assert!(filename.starts_with("backtest_equity_"));
              assert!(filename.contains("BTCUSDT"));
              assert!(filename.contains("M5"));
              assert!(filename.contains("2024-01-01"));
              assert!(filename.ends_with(".csv"));
              
              // Should contain timestamp for uniqueness
              assert!(filename.matches('_').count() >= 4);
          }
          
          // Helper function to generate CSV string from frames (to be implemented)
          fn export_frames_to_csv_string(frames: &[BacktestFrame]) -> String {
              use std::fmt::Write;
              
              let mut csv = String::new();
              
              // Write header
              writeln!(
                  &mut csv,
                  "Timestamp,DateTime,Price,Equity,Balance,Unrealized PnL,Realized PnL,Drawdown %,Peak Equity,Position Side,Position Size,Margin Used,Margin Available"
              ).unwrap();
              
              // Write data rows
              for frame in frames {
                  let datetime = frame.datetime()
                      .map(|dt| dt.format("%Y-%m-%d %H:%M:%S").to_string())
                      .unwrap_or_else(|| "Invalid".to_string());
                  
                  let equity_str = if frame.equity.is_finite() {
                      format!("{:.2}", frame.equity)
                  } else {
                      "NaN".to_string()
                  };
                  
                  let balance_str = if frame.balance.is_finite() {
                      format!("{:.2}", frame.balance)
                  } else {
                      "NaN".to_string()
                  };
                  
                  let unrealized_str = if frame.unrealized_pnl.is_finite() {
                      format!("{:.2}", frame.unrealized_pnl)
                  } else {
                      "NaN".to_string()
                  };
                  
                  let realized_str = if frame.realized_pnl.is_finite() {
                      format!("{:.2}", frame.realized_pnl)
                  } else {
                      "NaN".to_string()
                  };
                  
                  let drawdown_str = if frame.drawdown.is_finite() {
                      format!("{:.2}", frame.drawdown * 100.0)
                  } else {
                      "0.00".to_string()
                  };
                  
                  let peak_str = if frame.peak_equity.is_finite() {
                      format!("{:.2}", frame.peak_equity)
                  } else {
                      "NaN".to_string()
                  };
                  
                  let position_side = format!("{:?}", frame.position.side);
                  let position_size = format!("{:.2}", frame.position.size);
                  
                  writeln!(
                      &mut csv,
                      "{},{},{:.8},{},{},{},{},{},{},{},{},{:.2},{:.2}",
                      frame.timestamp,
                      datetime,
                      frame.price.to_f32(),
                      equity_str,
                      balance_str,
                      unrealized_str,
                      realized_str,
                      drawdown_str,
                      peak_str,
                      position_side,
                      position_size,
                      frame.margin_used,
                      frame.margin_available
                  ).unwrap();
              }
              
              csv
          }
          
          // Helper function to generate filename (to be implemented)
          fn generate_equity_csv_filename(ticker: &str, timeframe: &str, date: &str) -> String {
              let timestamp = chrono::Local::now().format("%Y%m%d_%H%M%S");
              format!(
                  "backtest_equity_{}_{}_{}_{}. csv",
                  ticker, timeframe, date, timestamp
              )
          }
      }

  coverage:
    - "CSV export with valid multi-frame data including header and all columns"
    - "Proper handling of NaN and Infinity values in equity, PnL fields"
    - "Export behavior with empty frames (header only)"
    - "Export behavior with single frame"
    - "Correct serialization of all position types (Flat, Long, Short)"
    - "Timestamp to DateTime conversion and formatting"
    - "Numeric precision for currency and percentage values"
    - "CSV structure validity (consistent field count across rows)"
    - "Filename generation following naming convention pattern"
    - "All BacktestFrame fields included in CSV output"

dependencies:
  depends_on:
    - task_id: 3
      reason: "May leverage serialization patterns for CSV formatting"

  depended_upon_by: []

  external:
    - name: "BacktestFrame"
      type: "struct"
      status: "already exists"
    - name: "BacktestResults"
      type: "struct"
      status: "already exists"
    - name: "PositionSide"
      type: "enum"
      status: "already exists"
    - name: "Position"
      type: "struct"
      status: "already exists"
    - name: "std::fs::File"
      type: "struct"
      status: "already exists"
    - name: "std::io::Write"
      type: "trait"
      status: "already exists"
    - name: "chrono::DateTime"
      type: "struct"
      status: "already exists"
---
task:
  id: 7
  name: "Implement Backtest Comparison Mode"

context:
  description: |
    This task implements a sophisticated comparison mode for the backtesting screen that enables
    users to analyze multiple backtest results simultaneously. The feature adds a new tab to the
    backtesting interface where users can select 2-4 saved backtest results and view them
    side-by-side with overlaid equity curves and comparative metrics analysis.
    
    The architectural significance of this feature lies in extending the existing single-result
    visualization infrastructure to support multi-result display without compromising performance
    or usability. This involves creating a new state management layer for comparison mode,
    extending the equity curve indicator to render multiple colored line plots simultaneously,
    and building a metrics comparison table with intelligent highlighting of best/worst values.
    
    The comparison mode addresses a critical workflow bottleneck in strategy development: manual
    comparison of parameter variations. Without this feature, users must run backtests separately,
    manually record results, and use external tools (spreadsheets) to compare metrics. This new
    mode streamlines the optimization workflow by providing instant visual and quantitative
    comparison, enabling faster identification of optimal strategy configurations.
    
    The implementation follows a modular architecture where comparison-specific logic resides in
    a new submodule (backtesting/comparison.rs), while extensions to existing components
    (EquityCurveIndicator, LinePlot) remain minimal and backward-compatible. The design supports
    2-4 simultaneous results to balance utility against memory usage and rendering performance.

  key_points:
    - "Extends existing equity curve visualization to support multi-series rendering with distinct colors"
    - "Introduces new comparison state manager coordinating multiple loaded BacktestResults"
    - "Implements intelligent Y-axis scaling that accommodates all equity curves without clipping"
    - "Provides side-by-side metrics table with conditional formatting highlighting best/worst values"
    - "Maintains backward compatibility with existing single-result display mode"
    - "Handles edge cases: mismatched timeframes, memory constraints, and curve visibility toggles"
    - "Performance considerations for rendering 3-4 large tick-mode datasets simultaneously"

files:
  - path: "/home/molaco/Documents/flowsurface-binance/src/screen/backtesting.rs"
    description: |
      Main backtesting screen - Add comparison mode state, UI tabs for switching between
      single/comparison views, result selector for choosing 2-4 backtests, and comparison
      metrics table with highlighting. Extend Message enum for comparison actions.
  - path: "/home/molaco/Documents/flowsurface-binance/src/screen/backtesting/comparison.rs"
    description: |
      New comparison mode module - Contains ComparisonState struct for managing multiple
      loaded results, color assignment system for equity curves, curve toggle controls,
      and comparison table rendering logic with best/worst highlighting.
  - path: "/home/molaco/Documents/flowsurface-binance/src/chart/indicator/kline/equity_curve.rs"
    description: |
      Equity curve indicator - Extend to support multiple equity data series simultaneously,
      each with assigned colors. Add multi_curve_with_data() constructor and modify rendering
      to overlay multiple LinePlots with distinct colors and legends.
  - path: "/home/molaco/Documents/flowsurface-binance/src/chart/indicator/plot/line.rs"
    description: |
      Line plot component - Add color customization option to LinePlot struct to support
      per-series color assignment instead of using theme default, enabling distinct colors
      for multiple equity curves in comparison mode.

functions:
  - file: "/home/molaco/Documents/flowsurface-binance/src/screen/backtesting.rs"
    items:
      - type: "enum_variant"
        name: "BacktestTab::Comparison"
        description: |
          New tab variant for the comparison view mode.
          Allows users to access the side-by-side comparison interface.
        
      - type: "struct"
        name: "ComparisonState"
        description: |
          State manager for comparison mode containing selected backtest results,
          visibility toggles, and color assignments for multiple equity curves.
          Fields:
          - selected_ids: Vec<i64> (2-4 backtest result IDs to compare)
          - loaded_results: HashMap<i64, BacktestResults> (cached loaded results)
          - curve_visibility: HashMap<i64, bool> (show/hide per curve)
          - color_assignments: HashMap<i64, iced::Color> (assigned colors)
          - available_results: Vec<BacktestSummary> (list for selector)
        invariants: |
          - selected_ids.len() >= 2 && selected_ids.len() <= 4
          - All IDs in selected_ids exist in loaded_results when comparison is active
          - color_assignments has entry for each selected_id
        
      - type: "method"
        name: "BacktestingScreen::enter_comparison_mode"
        description: |
          Transitions screen to comparison mode by loading list of available saved
          backtest results from database. Initializes empty ComparisonState.
        preconditions: |
          - db_manager is Some (database available)
        postconditions: |
          - active_tab set to BacktestTab::Comparison
          - ComparisonState initialized with empty selections
          - available_results populated from database
        
      - type: "method"
        name: "BacktestingScreen::load_backtest_for_comparison"
        description: |
          Loads a specific backtest result by ID from database and adds it to
          comparison state. Assigns a distinct color to its equity curve.
          Returns error if already at max (4) comparisons.
        preconditions: |
          - comparison_state.selected_ids.len() < 4
          - id exists in database
        postconditions: |
          - Result added to loaded_results
          - ID added to selected_ids
          - Color assigned in color_assignments
          - Equity data prepared for multi-curve chart
        
      - type: "method"
        name: "BacktestingScreen::remove_from_comparison"
        description: |
          Removes a backtest from comparison by ID. Updates state and clears
          associated equity curve from chart.
        preconditions: |
          - id exists in selected_ids
        postconditions: |
          - ID removed from selected_ids
          - Entry removed from loaded_results
          - Color freed in color_assignments
          - comparison_state.selected_ids.len() >= 2 or comparison mode exits
        
      - type: "method"
        name: "BacktestingScreen::toggle_curve_visibility"
        description: |
          Shows or hides a specific equity curve in comparison chart by toggling
          its visibility flag.
        preconditions: |
          - id exists in curve_visibility map
        postconditions: |
          - curve_visibility[id] toggled
          - Chart redraws with updated visibility
        
      - type: "enum_variant"
        name: "Message::EnterComparisonMode"
        description: |
          User action to switch to comparison mode tab.
        
      - type: "enum_variant"
        name: "Message::SelectBacktestForComparison(i64)"
        description: |
          User selects a backtest result by ID to add to comparison.
        
      - type: "enum_variant"
        name: "Message::RemoveFromComparison(i64)"
        description: |
          User removes a backtest from comparison by ID.
        
      - type: "enum_variant"
        name: "Message::ToggleCurveVisibility(i64)"
        description: |
          User toggles visibility of specific equity curve by backtest ID.
        
      - type: "function"
        name: "render_comparison_tab"
        description: |
          Renders the comparison mode UI containing:
          - Result selector dropdown/list (shows available saved backtests)
          - Multi-curve equity chart with legend
          - Comparison metrics table with highlighting
          - Curve toggle controls for show/hide
          Returns iced::Element for the entire comparison view.
        preconditions: |
          - comparison_state is Some
          - At least 2 results selected for valid comparison
        
      - type: "function"
        name: "render_comparison_chart"
        description: |
          Renders equity chart with multiple colored curves overlaid.
          Uses modified EquityCurveIndicator or new MultiCurveIndicator.
          Includes legend showing which color corresponds to which backtest.
        preconditions: |
          - At least 2 results loaded in comparison_state
          - Each result has valid equity data
        postconditions: |
          - Chart displays all visible curves with assigned colors
          - Y-axis scaled to fit all curves
          - Legend positioned in corner with labels and colors
        
      - type: "function"
        name: "render_comparison_metrics_table"
        description: |
          Renders side-by-side metrics table with columns for each backtest.
          Highlights best/worst values in each row (e.g., highest return in green,
          lowest in red). Rows include: Total Return, Sharpe Ratio, Max Drawdown,
          Win Rate, Total Trades, etc.
        preconditions: |
          - At least 2 results in comparison_state.loaded_results
        postconditions: |
          - Table displays metrics in aligned columns
          - Best values highlighted in green
          - Worst values highlighted in red
          - Scrollable if many metrics

  - file: "/home/molaco/Documents/flowsurface-binance/src/chart/indicator/kline/equity_curve.rs"
    items:
      - type: "struct"
        name: "MultiCurveEquityIndicator"
        description: |
          Indicator that renders multiple equity curves with different colors on
          the same chart. Manages multiple datasets and color assignments.
          Fields:
          - cache: Caches
          - curves: Vec<CurveData> (each curve has data, color, label, visibility)
          - initial_equity: f64 (for normalization/percentage view)
        
      - type: "struct"
        name: "CurveData"
        description: |
          Data for a single equity curve in multi-curve view.
          Fields:
          - id: i64 (backtest result ID)
          - label: String (display name, e.g., "BTCUSDT 1h MA Cross")
          - data: BTreeMap<u64, f64> (timestamp -> equity)
          - color: iced::Color
          - visible: bool
        
      - type: "method"
        name: "MultiCurveEquityIndicator::new"
        description: |
          Creates empty multi-curve indicator.
        postconditions: |
          - curves is empty Vec
          - cache initialized
        
      - type: "method"
        name: "MultiCurveEquityIndicator::add_curve"
        description: |
          Adds a new equity curve with specified data, color, and label.
        preconditions: |
          - data is non-empty and contains valid finite values
          - color is valid iced::Color
        postconditions: |
          - New CurveData appended to curves
          - Cache cleared for redraw
        
      - type: "method"
        name: "MultiCurveEquityIndicator::remove_curve"
        description: |
          Removes curve by ID from indicator.
        preconditions: |
          - Curve with id exists in curves
        postconditions: |
          - Curve removed from curves Vec
          - Cache cleared
        
      - type: "method"
        name: "MultiCurveEquityIndicator::set_curve_visibility"
        description: |
          Sets visibility flag for specific curve by ID.
        preconditions: |
          - Curve with id exists
        postconditions: |
          - visible flag updated for matching curve
          - Cache cleared
        
      - type: "method"
        name: "MultiCurveEquityIndicator::indicator_elem"
        description: |
          Renders all visible curves as overlaid line plots with different colors.
          Includes legend in corner showing color->label mappings.
        preconditions: |
          - At least one curve is visible
        postconditions: |
          - All visible curves drawn with assigned colors
          - Legend rendered showing labels and colors
          - Y-axis scaled to encompass all visible curve values

  - file: "/home/molaco/Documents/flowsurface-binance/src/chart/indicator/plot/line.rs"
    items:
      - type: "method"
        name: "LinePlot::with_color"
        description: |
          Builder method to specify custom color for line plot instead of
          using theme default. Enables multi-colored curves on same chart.
        postconditions: |
          - LinePlot stores custom color
          - draw() uses custom color if set, otherwise theme color

  - file: "/home/molaco/Documents/flowsurface-binance/src/screen/backtesting/comparison.rs"
    items:
      - type: "module_declaration"
        name: "comparison"
        description: |
          New submodule containing comparison mode logic, state, and rendering.
          Separates comparison concerns from main backtesting screen.
        
      - type: "function"
        name: "assign_distinct_color"
        description: |
          Color palette function that assigns visually distinct colors to equity
          curves based on index. Uses predefined palette of 4+ distinguishable colors
          (e.g., blue, orange, green, purple).
        preconditions: |
          - index < MAX_COMPARISON_COUNT (4)
        postconditions: |
          - Returns iced::Color from predefined palette
        invariants: |
          - Same index always returns same color
          - Colors are sufficiently distinct for readability
        
      - type: "constant"
        name: "COMPARISON_COLOR_PALETTE"
        description: |
          Static array of 4 iced::Color values for comparison curves.
          Colors chosen for maximum distinction and accessibility.
          Example: [Blue, Orange, Green, Purple]
        
      - type: "struct"
        name: "BacktestSummary"
        description: |
          Lightweight summary of saved backtest for selector list.
          Fields:
          - id: i64 (database primary key)
          - ticker: String
          - timeframe: String
          - strategy: String
          - start_time: u64
          - end_time: u64
          - total_return_percent: f64
          - created_at: u64
        
      - type: "function"
        name: "format_backtest_label"
        description: |
          Creates human-readable label for backtest in legend and selector.
          Format: "{ticker} {timeframe} {strategy} ({return}%)"
          Example: "BTCUSDT 1h MA Cross (+15.3%)"
        preconditions: |
          - summary contains valid non-empty strings
        postconditions: |
          - Returns formatted String suitable for display

formal_verification:
  needed: false
  level: "None"
  explanation: |
    Task 7 (Implement Backtest Comparison Mode) does NOT require formal verification for the following reasons:
    
    1. NO NEW FINANCIAL CALCULATIONS
       - The comparison mode displays existing backtest results side-by-side
       - It does NOT perform new equity calculations, PnL computations, or position management
       - All financial calculations are already performed by the BacktestEngine (engine.rs)
       - The comparison mode is purely a visualization/UI aggregation feature
    
    2. PRIMARY UI/VISUALIZATION WORK
       - Multi-curve equity chart rendering (multiple lines on same canvas)
       - Comparison metrics table layout (side-by-side display)
       - Result selector UI (checkboxes/dropdown for selecting 2-4 backtests)
       - Color assignment system (visual differentiation only)
       - Curve toggle controls (show/hide individual curves)
       - These are all presentation layer concerns with no correctness proofs needed
    
    3. NO CRITICAL INVARIANTS TO PROVE
       - Comparison mode reads immutable BacktestResults from memory/database
       - No state mutations affecting financial accuracy
       - No concurrent data access requiring synchronization proofs
       - Chart rendering is idempotent and stateless
    
    4. EXISTING VALIDATION ALREADY HANDLES SAFETY
       - Equity data already validated by 5-layer validation system (EQUITY.md:776-850)
       - Component validation ensures all values are finite before display
       - UI transformation filters out invalid data (backtesting.rs:408)
       - Rendering safety fallbacks prevent crashes (equity_curve.rs:93-100)
       - Comparison mode inherits all existing validation guarantees
    
    5. DATA CONSISTENCY IS STRUCTURAL, NOT MATHEMATICAL
       - Ensuring all selected backtests have data structures present is a simple existence check
       - Color assignment is bijective mapping (1 backtest → 1 color), easily tested
       - Curve visibility toggles are independent boolean flags
       - No complex state dependencies requiring formal modeling
    
    6. INTEGRATION TESTING IS SUFFICIENT
       - Test that 2-4 curves render correctly on same chart
       - Test that metrics table shows correct values from each backtest
       - Test that color assignment is consistent and visually distinguishable
       - Test that curve toggles show/hide correct datasets
       - Test edge cases (empty results, single result, max 4 results)
       - Property-based testing is overkill for UI coordinate transformations
    
    7. NO CONCURRENCY CONCERNS
       - Comparison mode reads from immutable results
       - No multi-threaded data access during visualization
       - Chart rendering is single-threaded in iced framework
       - Animation loop doesn't require race condition proofs
    
    RECOMMENDATION:
    - Use standard integration tests to verify UI behavior
    - Use visual regression testing for chart rendering
    - Use snapshot testing for metrics table formatting
    - Focus on code quality, type safety, and error handling
    - Leverage Rust's type system for compile-time guarantees
    
    CONTRAST WITH TASKS THAT WOULD NEED FORMAL VERIFICATION:
    - Modifying BacktestEngine equity calculation formulas → NEEDS VERIFICATION
    - Changing OrderExecutor PnL computation → NEEDS VERIFICATION
    - Altering margin calculation or liquidation logic → NEEDS VERIFICATION
    - Implementing position sizing algorithms → NEEDS VERIFICATION
    - Creating risk management systems → NEEDS VERIFICATION
    
    But Task 7 is display-only aggregation, not financial logic modification.

tests:
  strategy:
    approach: "integration"
    rationale:
      - "Comparison mode requires testing interactions between result loading, chart rendering, and UI state coordination"
      - "Multiple equity curves must render correctly on single chart without visual corruption"
      - "Y-axis scaling must accommodate all curves dynamically, verifying no clipping occurs"
      - "Metrics comparison logic needs validation across different result combinations"
      - "Memory efficiency must be verified when loading 2-4 simultaneous results"
      - "Integration tests validate complete user workflow from selection to rendering"

  implementation:
    file: "tests/integration/comparison_mode_tests.rs"
    location: "create new"
    code: |
      //! Integration tests for Backtest Comparison Mode
      //!
      //! Tests the complete workflow of loading multiple backtest results,
      //! rendering them on a single chart, and comparing metrics side-by-side.
      
      use backtesting::{BacktestEngine, BacktestResults, Strategy, Context};
      use backtesting::executor::Trade;
      use backtesting::metrics::Metrics;
      use backtesting::types::BacktestFrame;
      use exchange::{Kline, Price, MinTicksize};
      use std::collections::BTreeMap;
      
      #[path = "../common/mod.rs"]
      mod common;
      
      use common::fixtures::{generate_test_klines};
      
      /// Helper: Create a mock strategy with configurable behavior
      struct MockStrategy {
          name: String,
          win_rate: f64,  // Controls profitability
      }
      
      impl Strategy for MockStrategy {
          fn name(&self) -> &str {
              &self.name
          }
          
          fn on_candle(&mut self, _kline: &Kline, _ctx: &Context) -> Vec<backtesting::types::Order> {
              // Simple mock - no actual trading logic needed for comparison tests
              vec![]
          }
          
          fn on_tick(&mut self, _ctx: &Context) -> Vec<backtesting::types::Order> {
              vec![]
          }
      }
      
      /// Helper: Generate backtest results with specific characteristics
      fn generate_test_result(
          name: &str,
          initial_balance: f64,
          final_equity: f64,
          num_frames: usize,
      ) -> BacktestResults {
          let mut frames = Vec::new();
          let start_time = 1000000000u64;
          let time_step = 60000u64; // 1 minute
          
          // Generate equity progression from initial to final
          for i in 0..num_frames {
              let progress = i as f64 / num_frames as f64;
              let equity = initial_balance + (final_equity - initial_balance) * progress;
              
              // Ensure equity is always valid
              let equity = if equity.is_finite() { equity } else { initial_balance };
              
              let frame = BacktestFrame {
                  timestamp: (start_time + i as u64 * time_step) as i64,
                  price: Price::from_f32(50000.0),
                  position: backtesting::types::Position::default(),
                  equity,
                  balance: equity,
                  margin_used: 0.0,
                  margin_available: equity,
                  unrealized_pnl: 0.0,
                  realized_pnl: equity - initial_balance,
                  drawdown: 0.0,
                  peak_equity: equity,
                  orders: vec![],
                  fills: vec![],
              };
              
              frames.push(frame);
          }
          
          let metrics = Metrics {
              total_return: final_equity - initial_balance,
              total_return_percent: ((final_equity - initial_balance) / initial_balance) * 100.0,
              annualized_return: 0.0,
              sharpe_ratio: 1.5,
              sortino_ratio: 2.0,
              calmar_ratio: 1.2,
              max_drawdown: 500.0,
              max_drawdown_percent: 5.0,
              avg_drawdown: 2.5,
              max_drawdown_duration_hours: 24.0,
              total_trades: 10,
              winning_trades: 6,
              losing_trades: 4,
              win_rate: 60.0,
              profit_factor: 1.5,
              avg_win: 200.0,
              avg_loss: -100.0,
              largest_win: 500.0,
              largest_loss: -250.0,
              avg_trade_duration_hours: 4.0,
              max_consecutive_wins: 3,
              max_consecutive_losses: 2,
              total_fees: 50.0,
              expectancy: 100.0,
              recovery_factor: 2.0,
          };
          
          BacktestResults {
              metrics,
              trades: vec![],
              frames,
              klines: vec![],
          }
      }
      
      /// Helper: Extract equity curve data from results
      fn extract_equity_curve(results: &BacktestResults) -> BTreeMap<u64, f64> {
          results.frames
              .iter()
              .map(|f| (f.timestamp as u64, f.equity))
              .collect()
      }
      
      /// Helper: Calculate Y-axis range needed for multiple equity curves
      fn calculate_combined_y_range(curves: &[BTreeMap<u64, f64>]) -> (f64, f64) {
          let mut min = f64::MAX;
          let mut max = f64::MIN;
          
          for curve in curves {
              for &equity in curve.values() {
                  if equity.is_finite() {
                      min = min.min(equity);
                      max = max.max(equity);
                  }
              }
          }
          
          if min == f64::MAX {
              (0.0, 10000.0) // Default range if no valid data
          } else {
              (min, max)
          }
      }
      
      #[test]
      fn test_two_results_comparison_basic() {
          // Test: Compare 2 backtest results with different performance
          
          let result1 = generate_test_result("Strategy A", 10000.0, 12000.0, 100);
          let result2 = generate_test_result("Strategy B", 10000.0, 9000.0, 100);
          
          let curve1 = extract_equity_curve(&result1);
          let curve2 = extract_equity_curve(&result2);
          
          // Verify both curves have data
          assert_eq!(curve1.len(), 100, "Curve 1 should have 100 points");
          assert_eq!(curve2.len(), 100, "Curve 2 should have 100 points");
          
          // Verify all equity values are valid (not NaN or Infinity)
          for &equity in curve1.values() {
              assert!(equity.is_finite(), "Curve 1 contains invalid equity: {}", equity);
          }
          for &equity in curve2.values() {
              assert!(equity.is_finite(), "Curve 2 contains invalid equity: {}", equity);
          }
          
          // Verify final equity matches expected
          assert_eq!(curve1.values().last().copied().unwrap(), 12000.0);
          assert_eq!(curve2.values().last().copied().unwrap(), 9000.0);
          
          // Verify metrics comparison
          assert!(result1.metrics.total_return > result2.metrics.total_return,
                  "Result 1 should have better return");
      }
      
      #[test]
      fn test_four_results_y_axis_scaling() {
          // Test: Y-axis must scale appropriately for 4 results with wide range
          
          let result1 = generate_test_result("Conservative", 10000.0, 11000.0, 50);
          let result2 = generate_test_result("Moderate", 10000.0, 15000.0, 50);
          let result3 = generate_test_result("Aggressive", 10000.0, 25000.0, 50);
          let result4 = generate_test_result("Volatile", 10000.0, 5000.0, 50);
          
          let curves = vec![
              extract_equity_curve(&result1),
              extract_equity_curve(&result2),
              extract_equity_curve(&result3),
              extract_equity_curve(&result4),
          ];
          
          let (min_y, max_y) = calculate_combined_y_range(&curves);
          
          // Verify Y-range encompasses all curves
          assert!(min_y <= 5000.0, "Y-axis min should accommodate worst result");
          assert!(max_y >= 25000.0, "Y-axis max should accommodate best result");
          
          // Verify no clipping would occur
          for curve in &curves {
              for &equity in curve.values() {
                  assert!(equity >= min_y && equity <= max_y,
                          "Equity {} is outside Y-range [{}, {}]", equity, min_y, max_y);
              }
          }
          
          // Verify range is reasonable (not excessively padded)
          let range = max_y - min_y;
          assert!(range >= 20000.0 && range <= 25000.0,
                  "Y-axis range should be appropriate: {}", range);
      }
      
      #[test]
      fn test_metrics_comparison_highlighting() {
          // Test: Best/worst metrics are correctly identified across multiple results
          
          let result1 = generate_test_result("Strategy A", 10000.0, 12000.0, 50);
          let result2 = generate_test_result("Strategy B", 10000.0, 15000.0, 50);
          let result3 = generate_test_result("Strategy C", 10000.0, 9000.0, 50);
          
          let results = vec![&result1, &result2, &result3];
          
          // Find best total return
          let best_return = results.iter()
              .map(|r| r.metrics.total_return)
              .max_by(|a, b| a.partial_cmp(b).unwrap())
              .unwrap();
          assert_eq!(best_return, 5000.0, "Best return should be Strategy B");
          
          // Find worst total return
          let worst_return = results.iter()
              .map(|r| r.metrics.total_return)
              .min_by(|a, b| a.partial_cmp(b).unwrap())
              .unwrap();
          assert_eq!(worst_return, -1000.0, "Worst return should be Strategy C");
          
          // Find best Sharpe ratio (all same in test data, but verify logic)
          let best_sharpe = results.iter()
              .map(|r| r.metrics.sharpe_ratio)
              .max_by(|a, b| a.partial_cmp(b).unwrap())
              .unwrap();
          assert_eq!(best_sharpe, 1.5);
          
          // Verify metrics are comparable across results
          for result in &results {
              assert!(result.metrics.total_return.is_finite());
              assert!(result.metrics.sharpe_ratio.is_finite());
              assert!(result.metrics.max_drawdown_percent.is_finite());
          }
      }
      
      #[test]
      fn test_equity_curves_no_overlap_rendering() {
          // Test: Multiple equity curves render without corruption or overlap issues
          
          let result1 = generate_test_result("A", 10000.0, 12000.0, 100);
          let result2 = generate_test_result("B", 10000.0, 11500.0, 100);
          let result3 = generate_test_result("C", 10000.0, 13000.0, 100);
          
          let curves = vec![
              extract_equity_curve(&result1),
              extract_equity_curve(&result2),
              extract_equity_curve(&result3),
          ];
          
          // Verify curves have same time range (required for comparison)
          let times1: Vec<u64> = curves[0].keys().copied().collect();
          let times2: Vec<u64> = curves[1].keys().copied().collect();
          let times3: Vec<u64> = curves[2].keys().copied().collect();
          
          assert_eq!(times1.len(), times2.len());
          assert_eq!(times1.len(), times3.len());
          
          // Verify timestamps align (same X-axis points)
          for i in 0..times1.len() {
              assert_eq!(times1[i], times2[i], "Timestamps must align at index {}", i);
              assert_eq!(times1[i], times3[i], "Timestamps must align at index {}", i);
          }
          
          // Verify curves are distinguishable (different Y values)
          let final_equity1 = curves[0].values().last().unwrap();
          let final_equity2 = curves[1].values().last().unwrap();
          let final_equity3 = curves[2].values().last().unwrap();
          
          assert_ne!(final_equity1, final_equity2, "Curves should be distinguishable");
          assert_ne!(final_equity2, final_equity3, "Curves should be distinguishable");
          
          // Verify no data corruption (all values valid)
          for curve in &curves {
              for &equity in curve.values() {
                  assert!(equity.is_finite() && equity > 0.0,
                          "Invalid equity value: {}", equity);
              }
          }
      }
      
      #[test]
      fn test_memory_efficiency_multiple_results() {
          // Test: Memory usage remains reasonable with 4 results loaded
          
          // Generate larger datasets (1000 frames each)
          let result1 = generate_test_result("Strategy 1", 10000.0, 12000.0, 1000);
          let result2 = generate_test_result("Strategy 2", 10000.0, 15000.0, 1000);
          let result3 = generate_test_result("Strategy 3", 10000.0, 9000.0, 1000);
          let result4 = generate_test_result("Strategy 4", 10000.0, 20000.0, 1000);
          
          // Verify all results loaded successfully
          assert_eq!(result1.frames.len(), 1000);
          assert_eq!(result2.frames.len(), 1000);
          assert_eq!(result3.frames.len(), 1000);
          assert_eq!(result4.frames.len(), 1000);
          
          // Extract curves (simulates what comparison mode would do)
          let curves = vec![
              extract_equity_curve(&result1),
              extract_equity_curve(&result2),
              extract_equity_curve(&result3),
              extract_equity_curve(&result4),
          ];
          
          // Verify all curves retained full data
          for curve in &curves {
              assert_eq!(curve.len(), 1000, "Curve should have all 1000 points");
          }
          
          // Calculate total data points being rendered
          let total_points: usize = curves.iter().map(|c| c.len()).sum();
          assert_eq!(total_points, 4000, "Should handle 4000 total data points");
          
          // Verify performance: iterate through all points (simulates rendering)
          let mut processed = 0;
          for curve in &curves {
              for (_timestamp, equity) in curve.iter() {
                  assert!(equity.is_finite());
                  processed += 1;
              }
          }
          assert_eq!(processed, 4000, "Should process all points efficiently");
      }
      
      #[test]
      fn test_comparison_with_different_timeframes() {
          // Test: Comparison handles results with different date ranges gracefully
          
          // Result 1: 100 frames over shorter period
          let result1 = generate_test_result("Short Term", 10000.0, 11000.0, 100);
          
          // Result 2: 200 frames over longer period (but same time intervals)
          let result2 = generate_test_result("Long Term", 10000.0, 12000.0, 200);
          
          let curve1 = extract_equity_curve(&result1);
          let curve2 = extract_equity_curve(&result2);
          
          // Verify different lengths
          assert_eq!(curve1.len(), 100);
          assert_eq!(curve2.len(), 200);
          
          // Find overlapping time range
          let start1 = *curve1.keys().next().unwrap();
          let end1 = *curve1.keys().last().unwrap();
          let start2 = *curve2.keys().next().unwrap();
          let end2 = *curve2.keys().last().unwrap();
          
          let overlap_start = start1.max(start2);
          let overlap_end = end1.min(end2);
          
          // Verify overlap exists for comparison
          assert!(overlap_start < overlap_end, "Results should have overlapping time range");
          
          // Count points in overlap for each curve
          let overlap1: Vec<_> = curve1.iter()
              .filter(|(&t, _)| t >= overlap_start && t <= overlap_end)
              .collect();
          let overlap2: Vec<_> = curve2.iter()
              .filter(|(&t, _)| t >= overlap_start && t <= overlap_end)
              .collect();
          
          assert!(!overlap1.is_empty(), "Curve 1 should have data in overlap");
          assert!(!overlap2.is_empty(), "Curve 2 should have data in overlap");
          
          // Verify comparison can proceed using overlapping region
          assert!(overlap1.len() <= curve1.len());
          assert!(overlap2.len() <= curve2.len());
      }

  coverage:
    - "Two results comparison with basic validation of equity curves and metrics"
    - "Four results Y-axis scaling to verify no clipping or rendering issues"
    - "Metrics comparison logic identifying best/worst values correctly"
    - "Multiple equity curves render without overlap or data corruption"
    - "Memory efficiency validation with 4 results and 1000 frames each"
    - "Comparison handling of results with different timeframes/date ranges"

dependencies:
  depends_on:
    - task_id: 5
      reason: "Requires ability to load multiple saved backtest results from database"

  depended_upon_by: []

  external:
    - name: "BacktestResults"
      type: "struct"
      status: "already exists"
    - name: "Metrics"
      type: "struct"
      status: "already exists"
    - name: "BacktestFrame"
      type: "struct"
      status: "already exists"
    - name: "iced::Color"
      type: "struct"
      status: "already exists"
    - name: "iced::Element"
      type: "struct"
      status: "already exists"
    - name: "BTreeMap"
      type: "struct"
      status: "already exists"
    - name: "HashMap"
      type: "struct"
      status: "already exists"
---
I'll coordinate with all specialized agents in parallel to expand Task 5 into a complete specification.Now I'll combine all agent outputs into the final YAML specification following the task_template structure:

task:
  id: 5
  name: "Build Load Previous Results UI Feature"

context:
  description: |
    This task implements a comprehensive UI feature that allows users to browse, search,
    filter, and load previously saved backtest results. With Task 4 implementing auto-save
    functionality and Task 2 providing the database CRUD layer, users need a way to access
    and review their historical backtests. This feature bridges the gap between data
    persistence and user accessibility, enabling iterative strategy development and
    performance analysis workflows.

    The architecture follows the existing Iced UI pattern with modal dialogs, integrating
    seamlessly with the backtesting screen's state management. The browser modal provides
    a dedicated interface for result exploration with filtering controls (ticker, timeframe,
    date range, strategy name), a scrollable list view displaying key metrics for quick
    comparison, and full state restoration capabilities.

    This feature transforms the backtesting workflow from single-run analysis to portfolio-wide
    strategy comparison and optimization. Users can quickly scan saved results, identify
    promising configurations, and load complete backtest states including equity curves,
    trade histories, and frame-by-frame data for deep analysis.

  key_points:
    - "Implements browser modal following existing codebase patterns (see database_manager modal)"
    - "Integrates with BacktestRunsCRUD trait for data persistence operations"
    - "Provides comprehensive filtering: ticker, timeframe, date range, strategy, and search"
    - "Supports pagination/virtual scrolling for efficient handling of large result sets"
    - "Restores complete backtesting screen state including charts, frames, equity data"
    - "Uses Iced framework async tasks for non-blocking database operations"
    - "Displays summary metrics (return %, Sharpe, drawdown, trades) in list view"
    - "Maintains modal state persistence across open/close for UX continuity"
    - "Enables comparison workflow foundation (extended in Task 7)"

files:
  - path: "/home/molaco/Documents/flowsurface-binance/data/src/db/crud/backtest_runs.rs"
    description: "New CRUD implementation for backtest results persistence with save, load, list, delete, and query methods with filters"

  - path: "/home/molaco/Documents/flowsurface-binance/data/src/db/crud/mod.rs"
    description: "Modified to add BacktestRunsCRUD trait definition and backtest_runs module declaration"

  - path: "/home/molaco/Documents/flowsurface-binance/data/src/db/mod.rs"
    description: "Modified to implement BacktestRunsCRUD trait for DatabaseManager"

  - path: "/home/molaco/Documents/flowsurface-binance/data/src/db/migrations.rs"
    description: "Modified to include migration for backtest_runs table with schema for persisting results and equity curve data"

  - path: "/home/molaco/Documents/flowsurface-binance/backtesting/src/types.rs"
    description: "Modified to add Serialize/Deserialize derives to BacktestFrame and related types for database storage"

  - path: "/home/molaco/Documents/flowsurface-binance/src/modal/backtest_browser.rs"
    description: "New modal component for browsing and loading saved backtest results with filter state and result list display"

  - path: "/home/molaco/Documents/flowsurface-binance/src/modal/mod.rs"
    description: "Modified to export backtest_browser module and re-export BacktestBrowser"

  - path: "/home/molaco/Documents/flowsurface-binance/src/screen/backtesting.rs"
    description: "Modified to integrate backtest browser modal with show_browser_modal field, LoadPreviousResults messages, and modal display logic"

  - path: "/home/molaco/Documents/flowsurface-binance/backtesting/src/metrics.rs"
    description: "Modified to add Serialize/Deserialize derives to Metrics for database storage"

  - path: "/home/molaco/Documents/flowsurface-binance/backtesting/src/executor.rs"
    description: "Modified to add Serialize/Deserialize derives to Trade for database storage"

functions:
  - file: "/home/molaco/Documents/flowsurface-binance/data/src/db/crud/backtest_runs.rs"
    items:
      - type: "struct"
        name: "BacktestRunSummary"
        description: |
          Summary information for a single backtest run displayed in the browser list.
          Contains essential metadata and key metrics for quick scanning.

      - type: "struct"
        name: "BacktestRunFilters"
        description: |
          Filter criteria for querying saved backtest runs.
          Supports filtering by ticker, timeframe, date range, strategy, and search text.

      - type: "struct"
        name: "BacktestRunRecord"
        description: |
          Complete database record for a saved backtest run.
          Includes all configuration, results, trades, frames, and klines as serialized JSON/binary.

      - type: "trait_impl"
        name: "BacktestRunsCRUD for DatabaseManager"
        description: |
          Implementation of CRUD operations for backtest runs.
          Provides database operations for saving, loading, listing, and deleting backtest results.

      - type: "method"
        name: "BacktestRunsCRUD::save_backtest_run"
        description: |
          Save a complete backtest run to the database.
          Serializes metrics, trades, frames, and klines into database format.
          Returns the auto-generated run ID.
        preconditions: "Database connection is valid; BacktestResults contains valid data; Ticker and strategy names are non-empty"
        postconditions: "New row inserted into backtest_runs table; Run ID is returned; All related data is serialized and stored"

      - type: "method"
        name: "BacktestRunsCRUD::load_backtest_run"
        description: |
          Load a complete backtest run by ID from the database.
          Deserializes all stored data back into BacktestResults structure.
        preconditions: "Database connection is valid; Run ID exists in database"
        postconditions: "Full BacktestResults object is reconstructed; All trades, frames, and klines are deserialized"
        invariants: "Loaded data matches originally saved data"

      - type: "method"
        name: "BacktestRunsCRUD::list_backtest_runs"
        description: |
          Query and list saved backtest runs with optional filters.
          Returns summary information for each run, sorted by creation date (newest first).
          Supports pagination via limit and offset parameters.
        preconditions: "Database connection is valid; Filters are valid (dates, strings)"
        postconditions: "Returns list of BacktestRunSummary objects; Results are filtered and sorted; Pagination is applied"

      - type: "method"
        name: "BacktestRunsCRUD::delete_backtest_run"
        description: |
          Delete a saved backtest run by ID.
          Removes the run and all associated data from database.
        preconditions: "Database connection is valid; Run ID exists in database"
        postconditions: "Row is deleted from backtest_runs table; Returns number of rows deleted (should be 1)"

      - type: "method"
        name: "BacktestRunsCRUD::count_backtest_runs"
        description: |
          Count total number of saved backtest runs matching filters.
          Used for pagination controls.
        preconditions: "Database connection is valid"
        postconditions: "Returns total count of matching runs"

      - type: "function"
        name: "serialize_backtest_metrics"
        description: "Serialize backtesting metrics to JSON string for database storage"
        preconditions: "Metrics object is valid"
        postconditions: "Returns JSON string representation"

      - type: "function"
        name: "deserialize_backtest_metrics"
        description: "Deserialize backtesting metrics from JSON string"
        preconditions: "JSON string is valid"
        postconditions: "Returns Metrics object"

      - type: "function"
        name: "serialize_trades"
        description: "Serialize trade list to JSON string for database storage"
        preconditions: "Trades vector is valid"
        postconditions: "Returns JSON string representation"

      - type: "function"
        name: "deserialize_trades"
        description: "Deserialize trade list from JSON string"
        preconditions: "JSON string is valid"
        postconditions: "Returns vector of Trade objects"

      - type: "function"
        name: "serialize_frames"
        description: |
          Serialize backtest frames to compressed binary format for database storage.
          Uses efficient encoding to minimize storage size.
        preconditions: "Frames vector is valid"
        postconditions: "Returns binary blob (Vec<u8>)"

      - type: "function"
        name: "deserialize_frames"
        description: "Deserialize backtest frames from compressed binary format"
        preconditions: "Binary blob is valid"
        postconditions: "Returns vector of BacktestFrame objects"

      - type: "function"
        name: "serialize_klines"
        description: "Serialize klines to compressed binary format for database storage"
        preconditions: "Klines vector is valid"
        postconditions: "Returns binary blob (Vec<u8>)"

      - type: "function"
        name: "deserialize_klines"
        description: "Deserialize klines from compressed binary format"
        preconditions: "Binary blob is valid"
        postconditions: "Returns vector of Kline objects"

  - file: "/home/molaco/Documents/flowsurface-binance/data/src/db/crud/mod.rs"
    items:
      - type: "module_declaration"
        name: "pub mod backtest_runs"
        description: "Module declaration for backtest runs CRUD operations"

      - type: "trait"
        name: "BacktestRunsCRUD"
        description: |
          Trait defining CRUD operations for saved backtest runs.
          Implemented by DatabaseManager.

  - file: "/home/molaco/Documents/flowsurface-binance/data/src/db/migrations.rs"
    items:
      - type: "function"
        name: "create_backtest_runs_table"
        description: |
          Create the backtest_runs table in DuckDB if it doesn't exist.
          Schema includes: id, ticker, strategy_name, timeframe, start_date, end_date,
          initial_balance, leverage, mode, created_at, duration_seconds, metrics (JSON),
          trades (JSON), frames (BLOB), klines (BLOB).
        preconditions: "Database connection is valid"
        postconditions: "Table exists in database; Indexes are created on ticker, strategy_name, created_at"

  - file: "/home/molaco/Documents/flowsurface-binance/src/modal/backtest_browser.rs"
    items:
      - type: "struct"
        name: "BacktestBrowser"
        description: |
          Modal component for browsing and loading saved backtest runs.
          Contains filter state, result list, pagination state, and selected run.

      - type: "struct"
        name: "BrowserState"
        description: |
          Internal state for the backtest browser modal.
          Tracks filters, search input, selected filters, pagination, loading state.

      - type: "enum"
        name: "Message"
        description: |
          Messages for backtest browser interactions.
          Includes: OpenBrowser, CloseBrowser, FilterChanged, SearchInput, PageChanged,
          RunSelected, LoadRun, DeleteRun, RefreshList, LoadComplete, LoadError.

      - type: "method"
        name: "BacktestBrowser::new"
        description: "Create a new backtest browser instance"
        preconditions: "Database manager is available"
        postconditions: "Browser is initialized with empty state; No results loaded yet"

      - type: "method"
        name: "BacktestBrowser::open"
        description: |
          Open the browser modal and load initial list of runs.
          Triggers database query with current filters.
        preconditions: "Database manager is available"
        postconditions: "Browser is visible; Loading state is active; Database query task is spawned"

      - type: "method"
        name: "BacktestBrowser::close"
        description: "Close the browser modal"
        postconditions: "Browser is hidden; State is preserved for next open"

      - type: "method"
        name: "BacktestBrowser::update"
        description: |
          Handle browser messages and update state.
          Processes filter changes, pagination, selection, load, delete actions.
        preconditions: "Message is valid"
        postconditions: "State is updated according to message; May spawn async tasks for database operations"

      - type: "method"
        name: "BacktestBrowser::view"
        description: |
          Render the browser modal UI.
          Shows filter controls, result list, pagination, and action buttons.
        postconditions: "Returns Iced Element tree for rendering"

      - type: "method"
        name: "BacktestBrowser::apply_filters"
        description: |
          Apply current filter settings and refresh the result list.
          Triggers new database query with updated filters.
        preconditions: "Database manager is available; Filters are valid"
        postconditions: "Loading state is active; Database query task is spawned; Results will be updated when query completes"

      - type: "method"
        name: "BacktestBrowser::handle_run_selected"
        description: |
          Handle selection of a backtest run from the list.
          Updates selected state and enables load button.
        preconditions: "Run ID is valid"
        postconditions: "Run is marked as selected; Load button is enabled"

      - type: "method"
        name: "BacktestBrowser::handle_load_run"
        description: |
          Handle load button press for selected run.
          Spawns task to load full backtest data from database.
        preconditions: "A run is selected; Database manager is available"
        postconditions: "Loading state is active; Database load task is spawned; LoadComplete or LoadError message will be sent"

      - type: "method"
        name: "BacktestBrowser::handle_delete_run"
        description: |
          Handle delete button press for selected run.
          Shows confirmation dialog and deletes run if confirmed.
        preconditions: "A run is selected; Database manager is available"
        postconditions: "Run is deleted from database (if confirmed); Result list is refreshed"

      - type: "function"
        name: "spawn_list_query"
        description: |
          Spawn async task to query list of backtest runs with filters.
          Returns Task that resolves to list of summaries or error.
        preconditions: "Database manager is valid; Filters are valid"
        postconditions: "Task is created; Will send ListLoaded or ListError message when complete"

      - type: "function"
        name: "spawn_load_run"
        description: |
          Spawn async task to load full backtest run by ID.
          Returns Task that resolves to BacktestResults or error.
        preconditions: "Database manager is valid; Run ID exists"
        postconditions: "Task is created; Will send LoadComplete or LoadError message when complete"

      - type: "function"
        name: "spawn_delete_run"
        description: |
          Spawn async task to delete backtest run by ID.
          Returns Task that resolves to success or error.
        preconditions: "Database manager is valid; Run ID exists"
        postconditions: "Task is created; Will send DeleteComplete or DeleteError message when complete"

      - type: "function"
        name: "render_filter_controls"
        description: |
          Render the filter control section of the browser.
          Shows dropdowns and inputs for ticker, timeframe, strategy, date range, search.
        postconditions: "Returns Iced Element for filter controls"

      - type: "function"
        name: "render_result_list"
        description: |
          Render the scrollable list of backtest run summaries.
          Each item shows key info and is selectable.
        postconditions: "Returns Iced Element for result list"

      - type: "function"
        name: "render_result_item"
        description: |
          Render a single backtest run summary item.
          Shows ticker, strategy, dates, key metrics, creation date.
        preconditions: "Summary data is valid"
        postconditions: "Returns Iced Element for list item"

      - type: "function"
        name: "render_pagination_controls"
        description: "Render pagination controls (page number, prev/next buttons, page size selector)"
        postconditions: "Returns Iced Element for pagination"

      - type: "function"
        name: "render_action_buttons"
        description: |
          Render action buttons (Load, Delete, Cancel).
          Load/Delete are enabled only when a run is selected.
        postconditions: "Returns Iced Element for action buttons"

      - type: "function"
        name: "render_loading_state"
        description: "Render loading spinner and status message"
        postconditions: "Returns Iced Element for loading overlay"

  - file: "/home/molaco/Documents/flowsurface-binance/src/modal/mod.rs"
    items:
      - type: "module_declaration"
        name: "pub mod backtest_browser"
        description: "Module declaration for backtest browser modal"

      - type: "constant"
        name: "pub use backtest_browser::BacktestBrowser"
        description: "Re-export BacktestBrowser for easy access"

  - file: "/home/molaco/Documents/flowsurface-binance/src/screen/backtesting.rs"
    items:
      - type: "struct"
        name: "BacktestingScreen (field addition)"
        description: |
          Add backtest_browser field to BacktestingScreen struct.
          Type: Option<crate::modal::BacktestBrowser>

      - type: "enum_variant"
        name: "Message::OpenBacktestBrowser"
        description: "Message to open the backtest browser modal"

      - type: "enum_variant"
        name: "Message::CloseBacktestBrowser"
        description: "Message to close the backtest browser modal"

      - type: "enum_variant"
        name: "Message::BacktestBrowserMessage"
        description: |
          Wrapper message for forwarding browser messages.
          Contains: crate::modal::backtest_browser::Message

      - type: "enum_variant"
        name: "Message::LoadBacktestComplete"
        description: |
          Message sent when backtest load completes successfully.
          Contains: BacktestResults

      - type: "enum_variant"
        name: "Message::LoadBacktestError"
        description: |
          Message sent when backtest load fails.
          Contains: String (error message)

      - type: "method"
        name: "BacktestingScreen::new (modification)"
        description: "Initialize backtest_browser field to None in constructor"

      - type: "method"
        name: "BacktestingScreen::update (modification)"
        description: |
          Handle new browser-related messages in update method.
          Add cases for OpenBacktestBrowser, CloseBacktestBrowser, BacktestBrowserMessage,
          LoadBacktestComplete, LoadBacktestError.

      - type: "method"
        name: "BacktestingScreen::handle_open_browser"
        description: |
          Handle OpenBacktestBrowser message.
          Creates browser instance if needed and opens it.
        preconditions: "Database manager is available"
        postconditions: "Browser modal is open; Initial query is loading"

      - type: "method"
        name: "BacktestingScreen::handle_close_browser"
        description: "Handle CloseBacktestBrowser message. Closes the browser modal"
        postconditions: "Browser modal is hidden"

      - type: "method"
        name: "BacktestingScreen::handle_browser_message"
        description: "Forward browser message to browser component and handle response"
        preconditions: "Browser exists"
        postconditions: "Browser state is updated; May trigger load/delete operations"

      - type: "method"
        name: "BacktestingScreen::handle_load_complete"
        description: |
          Handle successful backtest load.
          Restores full backtesting screen state from loaded results.
        preconditions: "BacktestResults is valid"
        postconditions: "results field is populated; chart is initialized; frame_buffer is created; equity curve and trade markers are prepared; active_tab is switched to Results; browser is closed"

      - type: "method"
        name: "BacktestingScreen::restore_from_results"
        description: |
          Restore backtesting screen state from loaded BacktestResults.
          Rebuilds chart, frame buffer, indicators, and all visualization state.
        preconditions: "BacktestResults contains valid data"
        postconditions: "All visualization state is restored; Animation is ready to play"

      - type: "method"
        name: "BacktestingScreen::view (modification)"
        description: |
          Add "Load Previous Results" button to Config tab.
          Overlay browser modal when open.

      - type: "function"
        name: "render_load_previous_button"
        description: "Render the 'Load Previous Results' button in Config tab"
        postconditions: "Returns Iced Element for button"

      - type: "function"
        name: "render_browser_modal_overlay"
        description: |
          Render browser modal overlay when browser is open.
          Uses modal helper to show browser over main content.
        preconditions: "Browser is open"
        postconditions: "Returns Iced Element with modal overlay"

  - file: "/home/molaco/Documents/flowsurface-binance/backtesting/src/types.rs"
    items:
      - type: "trait_impl"
        name: "serde::Serialize for BacktestFrame"
        description: "Implement Serialize trait for BacktestFrame to enable JSON/binary serialization"

      - type: "trait_impl"
        name: "serde::Deserialize for BacktestFrame"
        description: "Implement Deserialize trait for BacktestFrame to enable JSON/binary deserialization"

      - type: "trait_impl"
        name: "serde::Serialize for Position"
        description: "Implement Serialize trait for Position"

      - type: "trait_impl"
        name: "serde::Deserialize for Position"
        description: "Implement Deserialize trait for Position"

      - type: "trait_impl"
        name: "serde::Serialize for PositionSide"
        description: "Implement Serialize trait for PositionSide enum"

      - type: "trait_impl"
        name: "serde::Deserialize for PositionSide"
        description: "Implement Deserialize trait for PositionSide enum"

  - file: "/home/molaco/Documents/flowsurface-binance/backtesting/src/metrics.rs"
    items:
      - type: "trait_impl"
        name: "serde::Serialize for Metrics"
        description: "Implement Serialize trait for Metrics to enable JSON serialization"

      - type: "trait_impl"
        name: "serde::Deserialize for Metrics"
        description: "Implement Deserialize trait for Metrics to enable JSON deserialization"

  - file: "/home/molaco/Documents/flowsurface-binance/backtesting/src/executor.rs"
    items:
      - type: "trait_impl"
        name: "serde::Serialize for Trade"
        description: "Implement Serialize trait for Trade to enable JSON serialization"

      - type: "trait_impl"
        name: "serde::Deserialize for Trade"
        description: "Implement Deserialize trait for Trade to enable JSON deserialization"

formal_verification:
  needed: false
  level: "None"
  explanation: |
    Formal verification is NOT needed for this UI feature task. This is a straightforward UI
    and state management implementation with the following characteristics:

    1. **UI Glue Code**: The task involves creating a modal dialog with filtering controls, search,
       and pagination - standard UI patterns that are well-understood and testable through
       conventional means (unit tests, integration tests, UI tests).

    2. **No Financial Logic**: This feature does not perform any financial calculations, trading
       decisions, or risk assessments. It purely displays and filters existing data that has
       already been validated and persisted.

    3. **Data Integrity Handled Elsewhere**: The database layer (separate task) is responsible
       for data persistence and integrity. This UI feature simply reads from that layer.

    4. **Simple Invariants**: The properties that must hold are straightforward:
       - Filters correctly constrain the result set (testable via unit tests)
       - Loaded state matches saved state (testable via integration tests)
       - UI responsively handles loading/error states (testable via UI tests)

    5. **Low Risk of Critical Failure**: Bugs in this feature would cause UX issues (wrong
       filters, slow loading, UI errors) but would NOT cause:
       - Data corruption (read-only operations)
       - Financial loss (no trading logic)
       - System crashes (isolated UI component)

    6. **Standard Testing Sufficient**: Conventional testing strategies are adequate:
       - Unit tests for filter logic
       - Integration tests for database queries and state restoration
       - UI tests for user interactions
       - Property-based testing for filter combinations (if desired)

    The codebase shows complex financial calculations in the backtesting engine (equity tracking,
    PnL calculations, liquidation checks with extensive validation), but this UI feature is
    orthogonal to that complexity. It is a presentation layer concern that warrants thorough
    testing but not formal verification.

    Recommendation: Use standard testing methodologies (unit, integration, UI tests) with good
    coverage. Consider property-based testing for filter logic if complexity increases.

tests:
  strategy:
    approach: "mixed (unit + integration)"
    rationale:
      - "Unit tests for filter logic, search, and pagination algorithms ensure core functionality works correctly in isolation"
      - "Integration tests verify UI state management, modal lifecycle, and complete user workflows"
      - "Mock-based testing allows UI logic testing without database dependencies"
      - "Property-based testing ensures filter combinations work correctly with edge cases"
      - "Separation of concerns - test data layer separately from UI layer"

  implementation:
    file: "/home/molaco/Documents/flowsurface-binance/tests/integration/load_results_ui_test.rs"
    location: "create new"
    code: |
      //! Integration tests for Load Previous Results UI Feature
      //! 
      //! Tests comprehensive UI functionality for browsing, filtering, and loading
      //! previously saved backtest results.
      
      #[cfg(test)]
      mod load_results_ui_tests {
          use backtesting::{BacktestResults, BacktestFrame};
          use backtesting::metrics::Metrics;
          use backtesting::executor::Trade;
          use backtesting::types::{Position, PositionSide, Order, Fill};
          use exchange::{Kline, Price, Timeframe};
          use std::collections::BTreeMap;
      
          /// Represents a saved backtest result record
          #[derive(Debug, Clone, PartialEq)]
          pub struct SavedBacktestRecord {
              pub id: u64,
              pub ticker: String,
              pub timeframe: String,
              pub strategy_name: String,
              pub start_date: i64,
              pub end_date: i64,
              pub initial_balance: f64,
              pub final_equity: f64,
              pub total_return_percent: f64,
              pub total_trades: usize,
              pub win_rate: f64,
              pub saved_at: i64,
          }
      
          /// Filter criteria for saved results
          #[derive(Debug, Clone, Default)]
          pub struct ResultFilter {
              pub ticker: Option<String>,
              pub timeframe: Option<String>,
              pub strategy_name: Option<String>,
              pub date_from: Option<i64>,
              pub date_to: Option<i64>,
              pub min_return: Option<f64>,
              pub max_return: Option<f64>,
          }
      
          /// Pagination state
          #[derive(Debug, Clone)]
          pub struct Pagination {
              pub current_page: usize,
              pub page_size: usize,
              pub total_items: usize,
          }
      
          impl Pagination {
              pub fn new(page_size: usize) -> Self {
                  Self {
                      current_page: 0,
                      page_size,
                      total_items: 0,
                  }
              }
      
              pub fn total_pages(&self) -> usize {
                  if self.total_items == 0 {
                      0
                  } else {
                      (self.total_items + self.page_size - 1) / self.page_size
                  }
              }
      
              pub fn has_next(&self) -> bool {
                  self.current_page < self.total_pages().saturating_sub(1)
              }
      
              pub fn has_prev(&self) -> bool {
                  self.current_page > 0
              }
      
              pub fn next_page(&mut self) {
                  if self.has_next() {
                      self.current_page += 1;
                  }
              }
      
              pub fn prev_page(&mut self) {
                  if self.has_prev() {
                      self.current_page -= 1;
                  }
              }
          }
      
          /// UI state for Load Results modal
          #[derive(Debug, Clone)]
          pub struct LoadResultsModalState {
              pub is_open: bool,
              pub filter: ResultFilter,
              pub search_query: String,
              pub pagination: Pagination,
              pub filtered_results: Vec<SavedBacktestRecord>,
              pub selected_id: Option<u64>,
              pub loading: bool,
              pub error: Option<String>,
          }
      
          impl LoadResultsModalState {
              pub fn new() -> Self {
                  Self {
                      is_open: false,
                      filter: ResultFilter::default(),
                      search_query: String::new(),
                      pagination: Pagination::new(10),
                      filtered_results: Vec::new(),
                      selected_id: None,
                      loading: false,
                      error: None,
                  }
              }
      
              pub fn open(&mut self) {
                  self.is_open = true;
                  self.loading = false;
                  self.error = None;
              }
      
              pub fn close(&mut self) {
                  self.is_open = false;
                  self.selected_id = None;
                  self.error = None;
              }
      
              pub fn reset_filters(&mut self) {
                  self.filter = ResultFilter::default();
                  self.search_query.clear();
                  self.pagination = Pagination::new(10);
              }
          }
      
          /// Filter logic implementation
          pub fn apply_filters(
              records: &[SavedBacktestRecord],
              filter: &ResultFilter,
              search_query: &str,
          ) -> Vec<SavedBacktestRecord> {
              records
                  .iter()
                  .filter(|record| {
                      // Ticker filter
                      if let Some(ref ticker) = filter.ticker {
                          if &record.ticker != ticker {
                              return false;
                          }
                      }
      
                      // Timeframe filter
                      if let Some(ref timeframe) = filter.timeframe {
                          if &record.timeframe != timeframe {
                              return false;
                          }
                      }
      
                      // Strategy name filter
                      if let Some(ref strategy) = filter.strategy_name {
                          if &record.strategy_name != strategy {
                              return false;
                          }
                      }
      
                      // Date range filter
                      if let Some(date_from) = filter.date_from {
                          if record.start_date < date_from {
                              return false;
                          }
                      }
                      if let Some(date_to) = filter.date_to {
                          if record.end_date > date_to {
                              return false;
                          }
                      }
      
                      // Return range filter
                      if let Some(min_return) = filter.min_return {
                          if record.total_return_percent < min_return {
                              return false;
                          }
                      }
                      if let Some(max_return) = filter.max_return {
                          if record.total_return_percent > max_return {
                              return false;
                          }
                      }
      
                      // Search query (case-insensitive)
                      if !search_query.is_empty() {
                          let query_lower = search_query.to_lowercase();
                          let matches = record.ticker.to_lowercase().contains(&query_lower)
                              || record.strategy_name.to_lowercase().contains(&query_lower)
                              || record.timeframe.to_lowercase().contains(&query_lower);
                          if !matches {
                              return false;
                          }
                      }
      
                      true
                  })
                  .cloned()
                  .collect()
          }
      
          /// Apply pagination to filtered results
          pub fn paginate_results(
              records: &[SavedBacktestRecord],
              pagination: &Pagination,
          ) -> Vec<SavedBacktestRecord> {
              let start = pagination.current_page * pagination.page_size;
              let end = (start + pagination.page_size).min(records.len());
              
              if start >= records.len() {
                  return Vec::new();
              }
              
              records[start..end].to_vec()
          }
      
          // ==================== TEST FIXTURES ====================
      
          fn create_test_record(
              id: u64,
              ticker: &str,
              timeframe: &str,
              strategy: &str,
              return_pct: f64,
          ) -> SavedBacktestRecord {
              SavedBacktestRecord {
                  id,
                  ticker: ticker.to_string(),
                  timeframe: timeframe.to_string(),
                  strategy_name: strategy.to_string(),
                  start_date: 1704067200000, // 2024-01-01
                  end_date: 1706745600000,   // 2024-02-01
                  initial_balance: 10000.0,
                  final_equity: 10000.0 + (10000.0 * return_pct / 100.0),
                  total_return_percent: return_pct,
                  total_trades: 50,
                  win_rate: 60.0,
                  saved_at: 1706745600000,
              }
          }
      
          fn create_test_dataset() -> Vec<SavedBacktestRecord> {
              vec![
                  create_test_record(1, "BTCUSDT", "1h", "MA Cross", 15.5),
                  create_test_record(2, "BTCUSDT", "4h", "MA Cross", -5.2),
                  create_test_record(3, "ETHUSDT", "1h", "MA Cross", 8.3),
                  create_test_record(4, "ETHUSDT", "1h", "RSI Strategy", 12.7),
                  create_test_record(5, "BTCUSDT", "1h", "RSI Strategy", 20.1),
                  create_test_record(6, "SOLUSDT", "15m", "MA Cross", -2.1),
                  create_test_record(7, "BTCUSDT", "1d", "MA Cross", 30.5),
                  create_test_record(8, "ETHUSDT", "4h", "Breakout", 5.5),
              ]
          }
      
          // ==================== FILTER TESTS ====================
      
          #[test]
          fn test_filter_by_ticker() {
              let records = create_test_dataset();
              let mut filter = ResultFilter::default();
              filter.ticker = Some("BTCUSDT".to_string());
      
              let filtered = apply_filters(&records, &filter, "");
              
              assert_eq!(filtered.len(), 4);
              assert!(filtered.iter().all(|r| r.ticker == "BTCUSDT"));
          }
      
          #[test]
          fn test_filter_by_timeframe() {
              let records = create_test_dataset();
              let mut filter = ResultFilter::default();
              filter.timeframe = Some("1h".to_string());
      
              let filtered = apply_filters(&records, &filter, "");
              
              assert_eq!(filtered.len(), 4);
              assert!(filtered.iter().all(|r| r.timeframe == "1h"));
          }
      
          #[test]
          fn test_filter_by_strategy() {
              let records = create_test_dataset();
              let mut filter = ResultFilter::default();
              filter.strategy_name = Some("MA Cross".to_string());
      
              let filtered = apply_filters(&records, &filter, "");
              
              assert_eq!(filtered.len(), 5);
              assert!(filtered.iter().all(|r| r.strategy_name == "MA Cross"));
          }
      
          #[test]
          fn test_filter_by_return_range() {
              let records = create_test_dataset();
              let mut filter = ResultFilter::default();
              filter.min_return = Some(10.0);
              filter.max_return = Some(25.0);
      
              let filtered = apply_filters(&records, &filter, "");
              
              assert_eq!(filtered.len(), 3);
              assert!(filtered.iter().all(|r| r.total_return_percent >= 10.0 && r.total_return_percent <= 25.0));
          }
      
          #[test]
          fn test_filter_combination() {
              let records = create_test_dataset();
              let mut filter = ResultFilter::default();
              filter.ticker = Some("BTCUSDT".to_string());
              filter.timeframe = Some("1h".to_string());
      
              let filtered = apply_filters(&records, &filter, "");
              
              assert_eq!(filtered.len(), 2);
              assert!(filtered.iter().all(|r| r.ticker == "BTCUSDT" && r.timeframe == "1h"));
          }
      
          #[test]
          fn test_filter_no_matches() {
              let records = create_test_dataset();
              let mut filter = ResultFilter::default();
              filter.ticker = Some("NONEXISTENT".to_string());
      
              let filtered = apply_filters(&records, &filter, "");
              
              assert_eq!(filtered.len(), 0);
          }
      
          #[test]
          fn test_filter_empty_filters_returns_all() {
              let records = create_test_dataset();
              let filter = ResultFilter::default();
      
              let filtered = apply_filters(&records, &filter, "");
              
              assert_eq!(filtered.len(), records.len());
          }
      
          // ==================== SEARCH TESTS ====================
      
          #[test]
          fn test_search_by_ticker() {
              let records = create_test_dataset();
              let filter = ResultFilter::default();
      
              let filtered = apply_filters(&records, &filter, "BTC");
              
              assert_eq!(filtered.len(), 4);
              assert!(filtered.iter().all(|r| r.ticker.contains("BTC")));
          }
      
          #[test]
          fn test_search_case_insensitive() {
              let records = create_test_dataset();
              let filter = ResultFilter::default();
      
              let filtered_lower = apply_filters(&records, &filter, "eth");
              let filtered_upper = apply_filters(&records, &filter, "ETH");
              
              assert_eq!(filtered_lower.len(), filtered_upper.len());
              assert_eq!(filtered_lower.len(), 3);
          }
      
          #[test]
          fn test_search_by_strategy() {
              let records = create_test_dataset();
              let filter = ResultFilter::default();
      
              let filtered = apply_filters(&records, &filter, "RSI");
              
              assert_eq!(filtered.len(), 2);
              assert!(filtered.iter().all(|r| r.strategy_name.contains("RSI")));
          }
      
          #[test]
          fn test_search_with_filter_combination() {
              let records = create_test_dataset();
              let mut filter = ResultFilter::default();
              filter.timeframe = Some("1h".to_string());
      
              let filtered = apply_filters(&records, &filter, "BTC");
              
              assert_eq!(filtered.len(), 2);
              assert!(filtered.iter().all(|r| r.ticker.contains("BTC") && r.timeframe == "1h"));
          }
      
          #[test]
          fn test_search_empty_string_returns_all() {
              let records = create_test_dataset();
              let filter = ResultFilter::default();
      
              let filtered = apply_filters(&records, &filter, "");
              
              assert_eq!(filtered.len(), records.len());
          }
      
          #[test]
          fn test_search_no_matches() {
              let records = create_test_dataset();
              let filter = ResultFilter::default();
      
              let filtered = apply_filters(&records, &filter, "NONEXISTENT");
              
              assert_eq!(filtered.len(), 0);
          }
      
          // ==================== PAGINATION TESTS ====================
      
          #[test]
          fn test_pagination_basic() {
              let mut pagination = Pagination::new(3);
              pagination.total_items = 8;
      
              assert_eq!(pagination.total_pages(), 3);
              assert_eq!(pagination.current_page, 0);
              assert!(pagination.has_next());
              assert!(!pagination.has_prev());
          }
      
          #[test]
          fn test_pagination_navigation() {
              let mut pagination = Pagination::new(3);
              pagination.total_items = 8;
      
              pagination.next_page();
              assert_eq!(pagination.current_page, 1);
              assert!(pagination.has_next());
              assert!(pagination.has_prev());
      
              pagination.next_page();
              assert_eq!(pagination.current_page, 2);
              assert!(!pagination.has_next());
              assert!(pagination.has_prev());
      
              pagination.prev_page();
              assert_eq!(pagination.current_page, 1);
          }
      
          #[test]
          fn test_pagination_boundaries() {
              let mut pagination = Pagination::new(10);
              pagination.total_items = 5;
      
              // Can't go next when at last page
              pagination.next_page();
              assert_eq!(pagination.current_page, 0);
      
              // Can't go prev when at first page
              pagination.prev_page();
              assert_eq!(pagination.current_page, 0);
          }
      
          #[test]
          fn test_paginate_results() {
              let records = create_test_dataset();
              let mut pagination = Pagination::new(3);
              pagination.total_items = records.len();
      
              // First page
              let page1 = paginate_results(&records, &pagination);
              assert_eq!(page1.len(), 3);
              assert_eq!(page1[0].id, 1);
      
              // Second page
              pagination.next_page();
              let page2 = paginate_results(&records, &pagination);
              assert_eq!(page2.len(), 3);
              assert_eq!(page2[0].id, 4);
      
              // Third page (partial)
              pagination.next_page();
              let page3 = paginate_results(&records, &pagination);
              assert_eq!(page3.len(), 2);
              assert_eq!(page3[0].id, 7);
          }
      
          #[test]
          fn test_paginate_empty_results() {
              let records: Vec<SavedBacktestRecord> = Vec::new();
              let pagination = Pagination::new(10);
      
              let page = paginate_results(&records, &pagination);
              assert_eq!(page.len(), 0);
          }
      
          #[test]
          fn test_paginate_out_of_bounds() {
              let records = create_test_dataset();
              let mut pagination = Pagination::new(10);
              pagination.total_items = records.len();
              pagination.current_page = 5; // Beyond actual pages
      
              let page = paginate_results(&records, &pagination);
              assert_eq!(page.len(), 0);
          }
      
          // ==================== MODAL STATE TESTS ====================
      
          #[test]
          fn test_modal_state_initialization() {
              let state = LoadResultsModalState::new();
              
              assert!(!state.is_open);
              assert!(state.search_query.is_empty());
              assert_eq!(state.pagination.current_page, 0);
              assert!(state.selected_id.is_none());
              assert!(!state.loading);
              assert!(state.error.is_none());
          }
      
          #[test]
          fn test_modal_open_close() {
              let mut state = LoadResultsModalState::new();
              
              state.open();
              assert!(state.is_open);
              assert!(!state.loading);
              assert!(state.error.is_none());
              
              state.close();
              assert!(!state.is_open);
              assert!(state.selected_id.is_none());
          }
      
          #[test]
          fn test_modal_reset_filters() {
              let mut state = LoadResultsModalState::new();
              
              state.filter.ticker = Some("BTCUSDT".to_string());
              state.search_query = "test".to_string();
              state.pagination.current_page = 2;
              
              state.reset_filters();
              
              assert!(state.filter.ticker.is_none());
              assert!(state.search_query.is_empty());
              assert_eq!(state.pagination.current_page, 0);
          }
      
          #[test]
          fn test_modal_state_persistence_during_open() {
              let mut state = LoadResultsModalState::new();
              
              state.filter.ticker = Some("BTCUSDT".to_string());
              state.search_query = "test".to_string();
              
              state.open();
              
              // State should persist when opening
              assert_eq!(state.filter.ticker, Some("BTCUSDT".to_string()));
              assert_eq!(state.search_query, "test");
          }
      
          // ==================== LARGE DATASET TESTS ====================
      
          #[test]
          fn test_ui_responsiveness_with_large_dataset() {
              // Create large dataset
              let mut records = Vec::new();
              for i in 0..1000 {
                  let ticker = match i % 5 {
                      0 => "BTCUSDT",
                      1 => "ETHUSDT",
                      2 => "SOLUSDT",
                      3 => "BNBUSDT",
                      _ => "ADAUSDT",
                  };
                  records.push(create_test_record(i, ticker, "1h", "MA Cross", (i as f64) % 100.0 - 50.0));
              }
      
              // Filter should complete quickly
              let start = std::time::Instant::now();
              let mut filter = ResultFilter::default();
              filter.ticker = Some("BTCUSDT".to_string());
              let filtered = apply_filters(&records, &filter, "");
              let duration = start.elapsed();
      
              assert_eq!(filtered.len(), 200);
              assert!(duration.as_millis() < 100, "Filtering took too long: {:?}", duration);
          }
      
          #[test]
          fn test_pagination_with_large_dataset() {
              let mut records = Vec::new();
              for i in 0..1000 {
                  records.push(create_test_record(i, "BTCUSDT", "1h", "MA Cross", 10.0));
              }
      
              let mut pagination = Pagination::new(50);
              pagination.total_items = records.len();
      
              assert_eq!(pagination.total_pages(), 20);
              
              let page = paginate_results(&records, &pagination);
              assert_eq!(page.len(), 50);
          }
      
          // ==================== ERROR HANDLING TESTS ====================
      
          #[test]
          fn test_invalid_date_range_filter() {
              let records = create_test_dataset();
              let mut filter = ResultFilter::default();
              // End date before start date (logically invalid)
              filter.date_from = Some(1706745600000);
              filter.date_to = Some(1704067200000);
      
              let filtered = apply_filters(&records, &filter, "");
              
              // Should return empty results
              assert_eq!(filtered.len(), 0);
          }
      
          #[test]
          fn test_negative_return_filter() {
              let records = create_test_dataset();
              let mut filter = ResultFilter::default();
              filter.max_return = Some(-10.0); // Only negative returns
      
              let filtered = apply_filters(&records, &filter, "");
              
              // Should only return losing strategies
              assert!(filtered.iter().all(|r| r.total_return_percent <= -10.0));
          }
      
          #[test]
          fn test_special_characters_in_search() {
              let records = create_test_dataset();
              let filter = ResultFilter::default();
      
              // Should not crash with special characters
              let filtered = apply_filters(&records, &filter, "BTC@#$%");
              assert_eq!(filtered.len(), 0);
          }
      
          // ==================== LOADING STATE RESTORATION TESTS ====================
      
          #[test]
          fn test_result_selection() {
              let mut state = LoadResultsModalState::new();
              let records = create_test_dataset();
              
              state.filtered_results = records.clone();
              state.selected_id = Some(3);
              
              let selected = state.filtered_results.iter().find(|r| r.id == state.selected_id.unwrap());
              assert!(selected.is_some());
              assert_eq!(selected.unwrap().ticker, "ETHUSDT");
          }
      
          #[test]
          fn test_selected_id_persistence() {
              let mut state = LoadResultsModalState::new();
              
              state.selected_id = Some(42);
              
              // Selection should persist through pagination
              state.pagination.next_page();
              assert_eq!(state.selected_id, Some(42));
          }
      
          #[test]
          fn test_loading_state_management() {
              let mut state = LoadResultsModalState::new();
              
              state.loading = true;
              assert!(state.loading);
              assert!(state.error.is_none());
              
              state.error = Some("Failed to load".to_string());
              state.loading = false;
              
              assert!(!state.loading);
              assert!(state.error.is_some());
          }
      
          // ==================== EDGE CASE TESTS ====================
      
          #[test]
          fn test_filter_with_zero_results_then_clear() {
              let records = create_test_dataset();
              let mut filter = ResultFilter::default();
              filter.ticker = Some("NONEXISTENT".to_string());
      
              let filtered = apply_filters(&records, &filter, "");
              assert_eq!(filtered.len(), 0);
              
              // Clear filter
              filter = ResultFilter::default();
              let filtered = apply_filters(&records, &filter, "");
              assert_eq!(filtered.len(), records.len());
          }
      
          #[test]
          fn test_pagination_single_page() {
              let records = vec![create_test_record(1, "BTCUSDT", "1h", "MA Cross", 10.0)];
              let mut pagination = Pagination::new(10);
              pagination.total_items = records.len();
      
              assert_eq!(pagination.total_pages(), 1);
              assert!(!pagination.has_next());
              assert!(!pagination.has_prev());
          }
      
          #[test]
          fn test_search_partial_match() {
              let records = create_test_dataset();
              let filter = ResultFilter::default();
      
              let filtered = apply_filters(&records, &filter, "US");
              
              // Should match all tickers with "US" (BTCUSDT, ETHUSDT, etc.)
              assert!(filtered.len() > 0);
              assert!(filtered.iter().all(|r| r.ticker.contains("US")));
          }
      
          #[test]
          fn test_multiple_filters_narrow_results_progressively() {
              let records = create_test_dataset();
              
              let mut filter = ResultFilter::default();
              let all_results = apply_filters(&records, &filter, "");
              let initial_count = all_results.len();
              
              filter.ticker = Some("BTCUSDT".to_string());
              let after_ticker = apply_filters(&records, &filter, "");
              assert!(after_ticker.len() < initial_count);
              
              filter.timeframe = Some("1h".to_string());
              let after_timeframe = apply_filters(&records, &filter, "");
              assert!(after_timeframe.len() <= after_ticker.len());
          }
      }

  coverage:
    - "Filter by ticker correctly narrows displayed results"
    - "Filter by timeframe correctly narrows displayed results"
    - "Filter by strategy name correctly narrows displayed results"
    - "Filter by date range correctly narrows displayed results"
    - "Filter by return range (min/max) correctly narrows displayed results"
    - "Multiple filters combine correctly (AND logic)"
    - "Empty filters return all results"
    - "No matches return empty list"
    - "Search query matches ticker (case-insensitive)"
    - "Search query matches strategy name (case-insensitive)"
    - "Search query matches timeframe"
    - "Search with filter combination works correctly"
    - "Empty search string returns all results"
    - "Search with no matches returns empty list"
    - "Pagination calculates total pages correctly"
    - "Pagination navigation (next/prev) works correctly"
    - "Pagination boundaries respected (can't go beyond limits)"
    - "Paginate results returns correct slice of data"
    - "Paginate empty results returns empty list"
    - "Paginate out of bounds returns empty list"
    - "Modal state initializes correctly"
    - "Modal open/close transitions work correctly"
    - "Reset filters clears all filter state"
    - "Modal state persists during open operation"
    - "UI remains responsive with 1000+ results (performance test)"
    - "Pagination works correctly with large datasets"
    - "Invalid date range filter returns empty results"
    - "Negative return filter works correctly"
    - "Special characters in search don't crash"
    - "Result selection by ID works correctly"
    - "Selected ID persists through pagination"
    - "Loading state management works correctly"
    - "Error state management works correctly"
    - "Filter with zero results can be cleared"
    - "Pagination with single page works correctly"
    - "Search partial match works correctly"
    - "Multiple filters progressively narrow results"

dependencies:
  depends_on:
    - task_id: 2
      reason: "Requires BacktestRunsCRUD trait with list_backtest_runs and load_backtest_run operations for data fetching"
    - task_id: 4
      reason: "Auto-save functionality must work for backtest results to exist in database for loading"

  depended_upon_by:
    - task_id: 7
      reason: "Compare mode builds on ability to load multiple results simultaneously"

  external:
    - name: "DatabaseManager"
      type: "struct"
      status: "already exists"
    - name: "BacktestResults"
      type: "struct"
      status: "already exists"
    - name: "BacktestFrame"
      type: "struct"
      status: "already exists"
    - name: "Metrics"
      type: "struct"
      status: "already exists"
    - name: "Trade"
      type: "struct"
      status: "already exists"
    - name: "Kline"
      type: "struct"
      status: "already exists"
    - name: "iced"
      type: "crate"
      status: "already exists"
    - name: "serde"
      type: "crate"
      status: "already exists"
    - name: "serde_json"
      type: "crate"
      status: "to be imported"
---
I'll coordinate with all specialized agents in parallel to expand Task 3 into a complete specification.Perfect! All agents have completed their work. Now I'll combine their outputs into the complete task specification in YAML format.

---

task:
  id: 3
  name: "Add Serialization Support to Backtest Data Structures"

context:
  description: |
    This task enables serialization and deserialization of all backtest data structures
    using Serde, allowing conversion between in-memory Rust types and JSON/database-compatible
    formats. This is a foundational capability required for multiple downstream features
    including database persistence (Task 2), CSV export (Task 6), and API integrations.
    
    Currently, core backtest types (BacktestResults, BacktestFrame, Position, Trade, Metrics)
    lack Serialize/Deserialize trait implementations, preventing them from being stored in
    databases or exported to files. This task adds the necessary Serde derives and implements
    custom serialization logic to handle edge cases like NaN/Infinity values in floating-point
    fields, which would otherwise produce invalid JSON.
    
    The implementation follows Rust best practices for serialization: using derive macros for
    standard cases and custom serializers only where needed (f64 fields that may contain
    special values). This approach maintains backward compatibility, supports multiple
    serialization formats (JSON, MessagePack), and enables future schema evolution through
    optional version fields.

  key_points:
    - "Adds Serde derives to 7 structs and 3 enums across 5 files in the backtesting crate"
    - "Implements custom f64 serialization to convert NaN/Infinity to JSON null, preventing encoding errors"
    - "Unblocks Task 2 (database CRUD operations) and Task 6 (CSV export functionality)"
    - "Price type from exchange crate already has Serde support, simplifying implementation"
    - "Property-based testing verifies round-trip invariants for all data structures"
    - "No algorithmic complexity - primarily derive macros and defensive type handling"
    - "Estimated effort: 1-2 hours for a simple, well-defined task"

files:
  - path: "/home/molaco/Documents/flowsurface-binance/backtesting/src/types.rs"
    description: |
      Core backtest data types file. Add Serde derives to Order, OrderSide, OrderType,
      Fill, Position, PositionSide, and BacktestFrame structs. Implement custom f64
      serializer functions for handling NaN/Infinity values in Position and BacktestFrame.

  - path: "/home/molaco/Documents/flowsurface-binance/backtesting/src/engine.rs"
    description: |
      Contains BacktestResults struct (lines 852-858). Add Serialize and Deserialize derives.
      Depends on all nested types (Metrics, Trade, BacktestFrame, Kline) being serializable.

  - path: "/home/molaco/Documents/flowsurface-binance/backtesting/src/executor.rs"
    description: |
      Contains Trade struct (lines 430-443). Add Serialize and Deserialize derives.
      Trade contains f64 fields (pnl_percent) that may be NaN and require custom serialization.

  - path: "/home/molaco/Documents/flowsurface-binance/backtesting/src/metrics.rs"
    description: |
      Contains Metrics struct (lines 315-351) with 21 f64 fields. Add Serialize and Deserialize
      derives with custom serialization for ratio fields (Sharpe, Sortino, profit_factor, etc.)
      that may be NaN/Infinity when denominators are zero.

  - path: "/home/molaco/Documents/flowsurface-binance/exchange/src/lib.rs"
    description: |
      Contains Kline struct. Add Serialize and Deserialize derives to enable candlestick
      data serialization. Price type already implements Serialize, simplifying implementation.

  - path: "/home/molaco/Documents/flowsurface-binance/backtesting/src/tests/serialization.rs"
    description: |
      New test module containing comprehensive serialization tests. Includes 12 unit tests
      covering basic serialization, edge cases (NaN/Infinity), and 6 property-based tests
      verifying round-trip invariants for all data structures.

  - path: "/home/molaco/Documents/flowsurface-binance/backtesting/Cargo.toml"
    description: |
      Add serde dependency reference (already available in workspace). Ensure derive feature
      is enabled for procedural macros.

functions:
  - file: "/home/molaco/Documents/flowsurface-binance/backtesting/src/types.rs"
    items:
      - type: struct
        name: Order
        description: |
          Add #[derive(Serialize, Deserialize)] to enable JSON serialization of order data.
          Represents a strategy's intent to trade with side, type, optional limit price,
          quantity, and timestamp.
        preconditions: "Struct definition exists with all fields serializable; Price type already implements Serialize/Deserialize; OrderSide and OrderType enums can be derived"
        postconditions: "Order can be converted to/from JSON via serde_json"
        invariants: "All field values preserved during serialization round-trip; Price field (Option<Price>) correctly handles None values"

      - type: struct
        name: Fill
        description: |
          Add #[derive(Serialize, Deserialize)] to enable JSON serialization of fill records.
          Represents an executed order with order_id, execution price, quantity, fee, and timestamp.
        preconditions: "Struct definition exists with all fields serializable; Price type already implements Serialize/Deserialize"
        postconditions: "Fill can be converted to JSON format; Fill data persists to/from JSON without loss"
        invariants: "All numeric fields (fee, quantity) maintain precision; Price field correctly serialized as f32"

      - type: enum
        name: OrderSide
        description: |
          Add #[derive(Serialize, Deserialize)] to enable JSON serialization of order direction.
          Variants: Buy, Sell. Required for Order serialization.
        preconditions: "Enum exists with Copy and PartialEq traits"
        postconditions: "OrderSide variants serialize as lowercase strings (buy, sell); Deserializes from JSON strings back to enum variants"

      - type: enum
        name: OrderType
        description: |
          Add #[derive(Serialize, Deserialize)] to enable JSON serialization of order execution method.
          Variants: Market, Limit. Required for Order serialization.
        preconditions: "Enum exists with Copy and PartialEq traits"
        postconditions: "OrderType variants serialize as lowercase strings (market, limit); Deserializes from JSON strings back to enum variants"

      - type: struct
        name: Position
        description: |
          Add #[derive(Serialize, Deserialize)] to enable JSON serialization of position state.
          Represents current market exposure with side, size, entry price, and PnL fields.
          All f64 fields may contain NaN/Infinity and require custom serialization.
        preconditions: "Struct definition exists; Price type implements Serialize/Deserialize; PositionSide enum must be Serialize/Deserialize capable"
        postconditions: "Position can be serialized to JSON; NaN/Infinity values in unrealized_pnl and realized_pnl are converted to null; Position can be deserialized from JSON with null handling"
        invariants: "Serialized timestamp matches original; Position and Price data preserved exactly; Invalid f64 values (NaN/Infinity) always serialize as null"

      - type: enum
        name: PositionSide
        description: |
          Add #[derive(Serialize, Deserialize)] to enable JSON serialization of position direction.
          Variants: Long, Short, Flat. Required for Position serialization.
        preconditions: "Enum exists with Copy and PartialEq traits"
        postconditions: "PositionSide variants serialize as lowercase strings (long, short, flat); Deserializes from JSON strings back to enum variants"

      - type: struct
        name: BacktestFrame
        description: |
          Add #[derive(Serialize, Deserialize)] to enable JSON serialization of backtest snapshots.
          Contains timestamp, price, position state, and multiple f64 fields (equity, balance,
          pnl values, drawdown). Requires custom serialization for f64 fields that may be NaN/Infinity.
        preconditions: "Struct definition exists; Position and Price types implement Serialize/Deserialize; Order and Fill types implement Serialize/Deserialize"
        postconditions: "BacktestFrame serializes to JSON with null for NaN/Infinity values; equity, balance, margin_used, unrealized_pnl, realized_pnl, drawdown, peak_equity all handle special f64 values"
        invariants: "Serialized timestamp always matches original; Position and Price data preserved exactly; Invalid f64 values always serialize as null; Valid f64 values preserve full precision"

      - type: function
        name: "serialize_f64_option<S>(value: &Option<f64>, serializer: S) -> Result<S::Ok, S::Error> where S: Serializer"
        description: |
          Custom serializer for Option<f64> fields that handles NaN and Infinity.
          Converts NaN/Infinity to JSON null, preserves valid f64 values as numbers.
          Used via #[serde(serialize_with = "serialize_f64_option")] attribute.
        preconditions: "Value parameter contains either valid f64, NaN, Infinity, or None; Serializer implements Serde Serializer trait"
        postconditions: "None returns JSON null; NaN returns JSON null; f64::INFINITY returns JSON null; f64::NEG_INFINITY returns JSON null; Valid finite f64 returns JSON number"
        invariants: "Output always valid JSON (no invalid numeric values); No precision loss for valid numbers; Always terminates without error"

      - type: function
        name: "serialize_f64<S>(value: &f64, serializer: S) -> Result<S::Ok, S::Error> where S: Serializer"
        description: |
          Custom serializer for f64 fields that handles NaN and Infinity.
          Converts NaN/Infinity to JSON null, preserves valid f64 values as numbers.
          Used via #[serde(serialize_with = "serialize_f64")] attribute on affected f64 fields.
        preconditions: "Value parameter contains valid f64, NaN, or Infinity; Serializer implements Serde Serializer trait"
        postconditions: "NaN returns JSON null; f64::INFINITY returns JSON null; f64::NEG_INFINITY returns JSON null; Valid finite f64 returns JSON number with full precision"
        invariants: "Output always valid JSON (no NaN/Infinity in output); No precision loss for valid finite numbers; Deterministic output for same input"

      - type: function
        name: "deserialize_f64_option<'de, D>(deserializer: D) -> Result<Option<f64>, D::Error> where D: Deserializer<'de>"
        description: |
          Custom deserializer for Option<f64> fields that handles JSON null.
          Converts JSON null back to None, preserves valid numbers.
          Used via #[serde(deserialize_with = "deserialize_f64_option")] attribute.
        preconditions: "Deserializer contains valid JSON null, number, or other value; Deserializer implements Serde Deserializer trait"
        postconditions: "JSON null returns None; JSON number returns Some(f64); Any other JSON type returns error"
        invariants: "Symmetric with serialize_f64_option for round-trip; Always produces valid Option<f64>"

  - file: "/home/molaco/Documents/flowsurface-binance/backtesting/src/engine.rs"
    items:
      - type: struct
        name: BacktestResults
        description: |
          Add #[derive(Serialize, Deserialize)] to enable JSON serialization of complete backtest results.
          Contains aggregated metrics, all trades, all frames, and formed candles.
        preconditions: "Struct definition exists at lines 852-858; Metrics, Trade, BacktestFrame, and Kline types implement Serialize/Deserialize"
        postconditions: "BacktestResults can be serialized to JSON; All nested vectors preserve element order and values; Can be deserialized from JSON back to struct"
        invariants: "All metrics values preserved; Trade vectors maintain original sequence; Frame vectors preserve timeline ordering; Kline data unchanged by round-trip"

  - file: "/home/molaco/Documents/flowsurface-binance/backtesting/src/executor.rs"
    items:
      - type: struct
        name: Trade
        description: |
          Add #[derive(Serialize, Deserialize)] to enable JSON serialization of completed trades.
          Contains entry/exit times, prices, side, size, PnL calculations (gross, fees, net, percent),
          and duration. All f64 fields may contain NaN/Infinity (especially pnl_percent).
        preconditions: "Struct definition exists at lines 430-443; PositionSide enum implements Serialize/Deserialize"
        postconditions: "Trade can be serialized to JSON; pnl_percent field handles NaN case (division by zero scenarios); All numeric fields preserve precision"
        invariants: "Timestamps preserved as i64; PnL relationships maintained (gross - fees = net); Duration preserved in milliseconds; PositionSide correctly reflects trade direction"

  - file: "/home/molaco/Documents/flowsurface-binance/exchange/src/lib.rs"
    items:
      - type: struct
        name: Kline
        description: |
          Add #[derive(Serialize, Deserialize)] to enable JSON serialization of candlestick data.
          Contains OHLCV data: time (u64), open/high/low/close (Price), and volume tuple.
          Price type already implements Serialize, so no custom f64 handling needed.
        preconditions: "Struct definition exists with Debug and Clone derives; Price type already implements Serialize/Deserialize"
        postconditions: "Kline can be serialized to JSON; OHLCV data preserved with Price serialization format; Volume tuple (f32, f32) serializes as two-element JSON array"
        invariants: "Timestamp remains u64 unchanged; Price values serialized as f32 (via Price's impl); Volume pair preserved in order"

  - file: "/home/molaco/Documents/flowsurface-binance/backtesting/src/metrics.rs"
    items:
      - type: struct
        name: Metrics
        description: |
          Add #[derive(Serialize, Deserialize)] to enable JSON serialization of calculated backtest metrics.
          Contains 28 numeric fields covering performance, risk, drawdown, and trade statistics.
          All f64 fields may contain NaN/Infinity (especially Sharpe/Sortino ratios when std_dev is 0,
          profit_factor when gross_loss is 0, calmar_ratio when max_dd is 0).
        preconditions: "Struct definition exists at lines 315-351; All fields are f64, usize, or derived-able types"
        postconditions: "Metrics can be serialized to JSON; All ratio fields handle infinity case (serialized as null); All percentage fields preserve precision; usize fields serialize as JSON numbers"
        invariants: "All field relationships maintained (e.g., winning + losing = total trades); Performance percentages match calculation basis; Risk ratios preserve sign information; Win rate is always 0-100 range or NaN"

  - file: "/home/molaco/Documents/flowsurface-binance/backtesting/Cargo.toml"
    items:
      - type: module_declaration
        name: serde dependency addition
        description: |
          Add serde to backtesting crate dependencies with derive feature.
          Serde is already in workspace dependencies, just needs to be referenced.
        preconditions: "Workspace Cargo.toml has serde defined; backtesting crate exists"
        postconditions: "backtesting crate can use serde macros; serde is available as dependency"
        invariants: "Serde version matches workspace version; derive feature enabled for procedural macros"

formal_verification:
  needed: false
  level: "None"
  explanation: |
    Task 3 requires adding Serde serialization support to backtest data structures. This is
    fundamentally a software engineering task, not a formal verification task, for the following reasons:
    
    1. COMPLEXITY ASSESSMENT
    The task scope is explicitly described as "simple" and comprises:
    - Adding #[derive(Serialize, Deserialize)] to 5 existing structs
    - Implementing 2 custom serializers (for f64 NaN/Infinity handling)
    - No algorithmic complexity, no mathematical invariants to prove
    - No custom business logic that might introduce subtle bugs
    
    The data structures involved (BacktestFrame, BacktestResults, Trade, Position, Metrics)
    are standard Rust types containing f64, i64, usize, enums, and vectors. Serde handles
    most of the serialization automatically. The only custom logic (NaN/Infinity handler)
    is a simple type adapter, not a complex algorithm.
    
    2. RISK & CRITICALITY ANALYSIS
    While this task affects data integrity, formal verification is NOT the appropriate tool:
    
    RISKS IDENTIFIED:
    - NaN/Infinity values must serialize to valid JSON
    - Round-trip integrity (deserialize == original)
    - Large frame arrays (potentially millions of entries) must not overflow serialization
    - Optional fields must deserialize gracefully
    
    WHY FORMAL VERIFICATION IS INAPPROPRIATE:
    These are DATA PRESERVATION risks, not ALGORITHMIC risks. They are:
    - Deterministic and testable via unit/integration tests
    - Solvable by property-based testing (not theorem proving)
    - Not requiring mathematical proofs or invariant analysis
    - Better validated through actual serialization/deserialization cycles
    
    3. WHAT FORMAL VERIFICATION WOULD PROVE
    Formal verification could theoretically prove:
    - "For all f64 values x, serialize(x) produces valid JSON"
    - "For all BacktestFrame f, deserialize(serialize(f)) == f"
    - "Memory allocation never exceeds buffer capacity"
    
    However, this is OVERKILL because:
    - Serde is a mature, battle-tested library with extensive test coverage
    - JSON is a well-defined serialization format with standard compliance tests
    - The custom f64 handler is <50 lines of straightforward code
    - IEEE 754 floating point is a standard, not a custom implementation
    
    4. PROPERTY TESTING IS SUFFICIENT
    The task correctly identifies property-based testing as the verification strategy:
    - Generate arbitrary f64 values (including NaN, Infinity, subnormals)
    - Serialize and deserialize
    - Assert round-trip equality OR acceptable transformations
    - Test with various array sizes
    
    This approach covers more real-world scenarios than proof, executes in milliseconds
    (vs hours for formal proofs), finds edge cases through randomized testing, and
    provides regression protection.
    
    5. CONCLUSION
    Formal verification would consume significant resources (person-weeks) to prove
    properties that property-based testing can validate in minutes. This is a classic
    case where testing and defensive coding are more cost-effective than formal methods.
    
    The recommendation stands: Implement with Serde derives + custom serializer, validate
    with comprehensive property tests, proceed to implementation.

tests:
  strategy:
    approach: "mixed (unit tests + property-based tests)"
    rationale:
      - "Unit tests verify specific serialization behaviors for each struct with known values"
      - "Property-based tests ensure round-trip invariants hold for all valid inputs"
      - "Edge case tests validate NaN/Infinity handling with custom f64 serializer"
      - "JSON validity tests prevent malformed output that would break database storage"
      - "Serialization is a pure transformation making it ideal for comprehensive automated testing"
      - "Property tests catch corner cases that manual tests might miss"

  implementation:
    file: "/home/molaco/Documents/flowsurface-binance/backtesting/src/tests/serialization.rs"
    location: "create new test module"
    code: |
      //! Serialization tests for backtest data structures
      //!
      //! These tests verify that all backtest data can be correctly serialized to JSON
      //! and deserialized back without data loss. Critical for saving results to database
      //! and generating reports.
      
      #[cfg(test)]
      mod tests {
          use crate::engine::BacktestResults;
          use crate::executor::Trade;
          use crate::metrics::Metrics;
          use crate::types::{BacktestFrame, Position, PositionSide, Order, OrderSide, OrderType, Fill};
          use exchange::util::Price;
          use exchange::Kline;
          use serde_json;
      
          // ============================================================================
          // UNIT TESTS - Specific behaviors with known values
          // ============================================================================
      
          #[test]
          fn test_position_serialization_basic() {
              let position = Position {
                  side: PositionSide::Long,
                  size: 1.5,
                  entry_price: Price::from_f32(50000.0),
                  unrealized_pnl: 250.0,
                  realized_pnl: 100.0,
              };
      
              // Serialize to JSON
              let json = serde_json::to_string(&position).expect("Failed to serialize Position");
              
              // Verify it's valid JSON
              assert!(serde_json::from_str::<serde_json::Value>(&json).is_ok());
              
              // Deserialize back
              let deserialized: Position = serde_json::from_str(&json)
                  .expect("Failed to deserialize Position");
              
              // Verify data integrity
              assert_eq!(deserialized.side, position.side);
              assert_eq!(deserialized.size, position.size);
              assert_eq!(deserialized.entry_price, position.entry_price);
              assert_eq!(deserialized.unrealized_pnl, position.unrealized_pnl);
              assert_eq!(deserialized.realized_pnl, position.realized_pnl);
          }
      
          #[test]
          fn test_position_serialization_flat() {
              let position = Position::default(); // Flat position
      
              let json = serde_json::to_string(&position).expect("Failed to serialize flat Position");
              let deserialized: Position = serde_json::from_str(&json)
                  .expect("Failed to deserialize flat Position");
              
              assert_eq!(deserialized.side, PositionSide::Flat);
              assert_eq!(deserialized.size, 0.0);
          }
      
          #[test]
          fn test_backtest_frame_serialization_basic() {
              let position = Position {
                  side: PositionSide::Short,
                  size: 0.5,
                  entry_price: Price::from_f32(51000.0),
                  unrealized_pnl: -50.0,
                  realized_pnl: 200.0,
              };
      
              let frame = BacktestFrame {
                  timestamp: 1609459200000, // 2021-01-01 00:00:00
                  price: Price::from_f32(50500.0),
                  position,
                  equity: 10250.0,
                  balance: 10000.0,
                  margin_used: 500.0,
                  margin_available: 9500.0,
                  unrealized_pnl: -50.0,
                  realized_pnl: 200.0,
                  drawdown: 0.05,
                  peak_equity: 10500.0,
                  orders: vec![],
                  fills: vec![],
              };
      
              let json = serde_json::to_string(&frame).expect("Failed to serialize BacktestFrame");
              assert!(serde_json::from_str::<serde_json::Value>(&json).is_ok());
              
              let deserialized: BacktestFrame = serde_json::from_str(&json)
                  .expect("Failed to deserialize BacktestFrame");
              
              assert_eq!(deserialized.timestamp, frame.timestamp);
              assert_eq!(deserialized.price, frame.price);
              assert_eq!(deserialized.equity, frame.equity);
              assert_eq!(deserialized.balance, frame.balance);
              assert_eq!(deserialized.drawdown, frame.drawdown);
          }
      
          #[test]
          fn test_backtest_frame_with_orders_and_fills() {
              let order = Order {
                  side: OrderSide::Buy,
                  order_type: OrderType::Market,
                  price: None,
                  quantity: 1.0,
                  timestamp: 1609459200000,
              };
      
              let fill = Fill {
                  order_id: 1,
                  price: Price::from_f32(50000.0),
                  quantity: 1.0,
                  fee: 2.0,
                  timestamp: 1609459200000,
              };
      
              let frame = BacktestFrame {
                  timestamp: 1609459200000,
                  price: Price::from_f32(50000.0),
                  position: Position::default(),
                  equity: 10000.0,
                  balance: 9998.0,
                  margin_used: 0.0,
                  margin_available: 9998.0,
                  unrealized_pnl: 0.0,
                  realized_pnl: 0.0,
                  drawdown: 0.0,
                  peak_equity: 10000.0,
                  orders: vec![order],
                  fills: vec![fill],
              };
      
              let json = serde_json::to_string(&frame).expect("Failed to serialize frame with orders/fills");
              let deserialized: BacktestFrame = serde_json::from_str(&json)
                  .expect("Failed to deserialize frame with orders/fills");
              
              assert_eq!(deserialized.orders.len(), 1);
              assert_eq!(deserialized.fills.len(), 1);
          }
      
          #[test]
          fn test_trade_serialization() {
              let trade = Trade {
                  entry_time: 1609459200000,
                  exit_time: 1609462800000,
                  side: PositionSide::Long,
                  entry_price: 50000.0,
                  exit_price: 51000.0,
                  size: 1.0,
                  gross_pnl: 1000.0,
                  fees: 4.0,
                  net_pnl: 996.0,
                  pnl_percent: 1.99,
                  duration_ms: 3600000,
              };
      
              let json = serde_json::to_string(&trade).expect("Failed to serialize Trade");
              assert!(serde_json::from_str::<serde_json::Value>(&json).is_ok());
              
              let deserialized: Trade = serde_json::from_str(&json)
                  .expect("Failed to deserialize Trade");
              
              assert_eq!(deserialized.entry_time, trade.entry_time);
              assert_eq!(deserialized.exit_time, trade.exit_time);
              assert_eq!(deserialized.net_pnl, trade.net_pnl);
              assert_eq!(deserialized.duration_ms, trade.duration_ms);
          }
      
          #[test]
          fn test_metrics_serialization() {
              let metrics = Metrics {
                  total_return: 1000.0,
                  total_return_percent: 10.0,
                  annualized_return: 50.0,
                  sharpe_ratio: 1.5,
                  sortino_ratio: 2.0,
                  calmar_ratio: 3.0,
                  max_drawdown: 500.0,
                  max_drawdown_percent: 5.0,
                  avg_drawdown: 2.5,
                  max_drawdown_duration_hours: 48.0,
                  total_trades: 100,
                  winning_trades: 60,
                  losing_trades: 40,
                  win_rate: 60.0,
                  profit_factor: 1.8,
                  avg_win: 50.0,
                  avg_loss: -30.0,
                  largest_win: 200.0,
                  largest_loss: -100.0,
                  avg_trade_duration_hours: 4.5,
                  max_consecutive_wins: 8,
                  max_consecutive_losses: 5,
                  total_fees: 40.0,
                  expectancy: 10.0,
                  recovery_factor: 2.0,
              };
      
              let json = serde_json::to_string(&metrics).expect("Failed to serialize Metrics");
              assert!(serde_json::from_str::<serde_json::Value>(&json).is_ok());
              
              let deserialized: Metrics = serde_json::from_str(&json)
                  .expect("Failed to deserialize Metrics");
              
              assert_eq!(deserialized.total_trades, metrics.total_trades);
              assert_eq!(deserialized.win_rate, metrics.win_rate);
              assert_eq!(deserialized.sharpe_ratio, metrics.sharpe_ratio);
          }
      
          #[test]
          fn test_backtest_results_serialization() {
              let metrics = Metrics {
                  total_return: 500.0,
                  total_return_percent: 5.0,
                  annualized_return: 20.0,
                  sharpe_ratio: 1.2,
                  sortino_ratio: 1.5,
                  calmar_ratio: 2.0,
                  max_drawdown: 200.0,
                  max_drawdown_percent: 2.0,
                  avg_drawdown: 1.0,
                  max_drawdown_duration_hours: 24.0,
                  total_trades: 10,
                  winning_trades: 6,
                  losing_trades: 4,
                  win_rate: 60.0,
                  profit_factor: 1.5,
                  avg_win: 100.0,
                  avg_loss: -50.0,
                  largest_win: 200.0,
                  largest_loss: -100.0,
                  avg_trade_duration_hours: 2.0,
                  max_consecutive_wins: 3,
                  max_consecutive_losses: 2,
                  total_fees: 10.0,
                  expectancy: 50.0,
                  recovery_factor: 2.5,
              };
      
              let trade = Trade {
                  entry_time: 1609459200000,
                  exit_time: 1609462800000,
                  side: PositionSide::Long,
                  entry_price: 50000.0,
                  exit_price: 50500.0,
                  size: 1.0,
                  gross_pnl: 500.0,
                  fees: 2.0,
                  net_pnl: 498.0,
                  pnl_percent: 1.0,
                  duration_ms: 3600000,
              };
      
              let frame = BacktestFrame {
                  timestamp: 1609459200000,
                  price: Price::from_f32(50000.0),
                  position: Position::default(),
                  equity: 10500.0,
                  balance: 10500.0,
                  margin_used: 0.0,
                  margin_available: 10500.0,
                  unrealized_pnl: 0.0,
                  realized_pnl: 500.0,
                  drawdown: 0.0,
                  peak_equity: 10500.0,
                  orders: vec![],
                  fills: vec![],
              };
      
              let kline = Kline {
                  time: 1609459200000,
                  open: Price::from_f32(50000.0),
                  high: Price::from_f32(50500.0),
                  low: Price::from_f32(49500.0),
                  close: Price::from_f32(50000.0),
                  volume: (100.0, 5000000.0),
              };
      
              let results = BacktestResults {
                  metrics,
                  trades: vec![trade],
                  frames: vec![frame],
                  klines: vec![kline],
              };
      
              let json = serde_json::to_string(&results).expect("Failed to serialize BacktestResults");
              assert!(serde_json::from_str::<serde_json::Value>(&json).is_ok());
              
              let deserialized: BacktestResults = serde_json::from_str(&json)
                  .expect("Failed to deserialize BacktestResults");
              
              assert_eq!(deserialized.trades.len(), 1);
              assert_eq!(deserialized.frames.len(), 1);
              assert_eq!(deserialized.klines.len(), 1);
          }
      
          // ============================================================================
          // EDGE CASE TESTS - NaN, Infinity, empty collections
          // ============================================================================
      
          #[test]
          fn test_nan_values_serialize_to_null() {
              let position = Position {
                  side: PositionSide::Long,
                  size: 1.0,
                  entry_price: Price::from_f32(50000.0),
                  unrealized_pnl: f64::NAN,
                  realized_pnl: 100.0,
              };
      
              let json = serde_json::to_string(&position).expect("Failed to serialize Position with NaN");
              
              // Parse as Value to inspect the JSON
              let value: serde_json::Value = serde_json::from_str(&json)
                  .expect("Failed to parse JSON with NaN");
              
              // NaN should be serialized as null
              let unrealized_pnl = &value["unrealized_pnl"];
              assert!(unrealized_pnl.is_null() || unrealized_pnl.as_f64().map(|v| v.is_finite()).unwrap_or(true),
                  "NaN should serialize to null or finite value");
          }
      
          #[test]
          fn test_infinity_values_serialize_to_null() {
              let position = Position {
                  side: PositionSide::Long,
                  size: 1.0,
                  entry_price: Price::from_f32(50000.0),
                  unrealized_pnl: f64::INFINITY,
                  realized_pnl: f64::NEG_INFINITY,
              };
      
              let json = serde_json::to_string(&position).expect("Failed to serialize Position with Infinity");
              
              let value: serde_json::Value = serde_json::from_str(&json)
                  .expect("Failed to parse JSON with Infinity");
              
              // Infinity should be serialized as null or handled gracefully
              let unrealized_pnl = &value["unrealized_pnl"];
              assert!(unrealized_pnl.is_null() || unrealized_pnl.as_f64().map(|v| v.is_finite()).unwrap_or(true),
                  "Infinity should serialize to null or finite value");
          }
      
          #[test]
          fn test_empty_collections_serialize() {
              let frame = BacktestFrame {
                  timestamp: 1609459200000,
                  price: Price::from_f32(50000.0),
                  position: Position::default(),
                  equity: 10000.0,
                  balance: 10000.0,
                  margin_used: 0.0,
                  margin_available: 10000.0,
                  unrealized_pnl: 0.0,
                  realized_pnl: 0.0,
                  drawdown: 0.0,
                  peak_equity: 10000.0,
                  orders: vec![],
                  fills: vec![],
              };
      
              let json = serde_json::to_string(&frame).expect("Failed to serialize frame with empty collections");
              let deserialized: BacktestFrame = serde_json::from_str(&json)
                  .expect("Failed to deserialize frame with empty collections");
              
              assert_eq!(deserialized.orders.len(), 0);
              assert_eq!(deserialized.fills.len(), 0);
          }
      
          #[test]
          fn test_large_frame_array_serialization() {
              // Test with 10000 frames to ensure no stack overflow
              let frames: Vec<BacktestFrame> = (0..10000).map(|i| BacktestFrame {
                  timestamp: 1609459200000 + (i * 60000),
                  price: Price::from_f32(50000.0 + i as f32),
                  position: Position::default(),
                  equity: 10000.0 + i as f64,
                  balance: 10000.0 + i as f64,
                  margin_used: 0.0,
                  margin_available: 10000.0 + i as f64,
                  unrealized_pnl: 0.0,
                  realized_pnl: 0.0,
                  drawdown: 0.0,
                  peak_equity: 10000.0 + i as f64,
                  orders: vec![],
                  fills: vec![],
              }).collect();
      
              let json = serde_json::to_string(&frames).expect("Failed to serialize large frame array");
              assert!(json.len() > 0);
              
              let deserialized: Vec<BacktestFrame> = serde_json::from_str(&json)
                  .expect("Failed to deserialize large frame array");
              
              assert_eq!(deserialized.len(), 10000);
          }
      
          #[test]
          fn test_optional_fields_deserialize_when_missing() {
              // Test that optional fields can be omitted during deserialization
              let json = r#"{
                  "timestamp": 1609459200000,
                  "price": {"units": 5000000000000},
                  "position": {
                      "side": "Flat",
                      "size": 0.0,
                      "entry_price": {"units": 0},
                      "unrealized_pnl": 0.0,
                      "realized_pnl": 0.0
                  },
                  "equity": 10000.0,
                  "balance": 10000.0,
                  "margin_used": 0.0,
                  "margin_available": 10000.0,
                  "unrealized_pnl": 0.0,
                  "realized_pnl": 0.0,
                  "drawdown": 0.0,
                  "peak_equity": 10000.0,
                  "orders": [],
                  "fills": []
              }"#;
      
              let deserialized: BacktestFrame = serde_json::from_str(json)
                  .expect("Failed to deserialize BacktestFrame from minimal JSON");
              
              assert_eq!(deserialized.timestamp, 1609459200000);
              assert_eq!(deserialized.equity, 10000.0);
          }
      
          #[test]
          fn test_json_validity_all_structs() {
              // Verify all structs produce valid JSON that can be parsed back
              let position = Position::default();
              let position_json = serde_json::to_string(&position).expect("Failed to serialize Position");
              assert!(serde_json::from_str::<serde_json::Value>(&position_json).is_ok());
      
              let order = Order::market_buy(1.0, 1609459200000);
              let order_json = serde_json::to_string(&order).expect("Failed to serialize Order");
              assert!(serde_json::from_str::<serde_json::Value>(&order_json).is_ok());
      
              let fill = Fill {
                  order_id: 1,
                  price: Price::from_f32(50000.0),
                  quantity: 1.0,
                  fee: 2.0,
                  timestamp: 1609459200000,
              };
              let fill_json = serde_json::to_string(&fill).expect("Failed to serialize Fill");
              assert!(serde_json::from_str::<serde_json::Value>(&fill_json).is_ok());
          }
      
          #[test]
          fn test_pretty_json_formatting() {
              let metrics = Metrics {
                  total_return: 1000.0,
                  total_return_percent: 10.0,
                  annualized_return: 50.0,
                  sharpe_ratio: 1.5,
                  sortino_ratio: 2.0,
                  calmar_ratio: 3.0,
                  max_drawdown: 500.0,
                  max_drawdown_percent: 5.0,
                  avg_drawdown: 2.5,
                  max_drawdown_duration_hours: 48.0,
                  total_trades: 100,
                  winning_trades: 60,
                  losing_trades: 40,
                  win_rate: 60.0,
                  profit_factor: 1.8,
                  avg_win: 50.0,
                  avg_loss: -30.0,
                  largest_win: 200.0,
                  largest_loss: -100.0,
                  avg_trade_duration_hours: 4.5,
                  max_consecutive_wins: 8,
                  max_consecutive_losses: 5,
                  total_fees: 40.0,
                  expectancy: 10.0,
                  recovery_factor: 2.0,
              };
      
              // Test pretty-printing for human-readable JSON
              let pretty_json = serde_json::to_string_pretty(&metrics)
                  .expect("Failed to serialize Metrics to pretty JSON");
              
              assert!(pretty_json.contains('\n'), "Pretty JSON should contain newlines");
              assert!(serde_json::from_str::<Metrics>(&pretty_json).is_ok());
          }
      }
      
      // ============================================================================
      // PROPERTY-BASED TESTS - Roundtrip invariants for all valid inputs
      // ============================================================================
      
      #[cfg(test)]
      mod property_tests {
          use super::*;
          use proptest::prelude::*;
      
          // Strategy for generating valid timestamps (2020-2030 range)
          fn timestamp_strategy() -> impl Strategy<Value = i64> {
              (1577836800000i64..1893456000000i64) // 2020-01-01 to 2030-01-01 in ms
          }
      
          // Strategy for generating finite f64 values (excluding NaN/Infinity)
          fn finite_f64_strategy() -> impl Strategy<Value = f64> {
              (-1000000.0..1000000.0f64).prop_filter("must be finite", |v| v.is_finite())
          }
      
          // Strategy for generating positive f64 values
          fn positive_f64_strategy() -> impl Strategy<Value = f64> {
              (0.0..1000000.0f64).prop_filter("must be finite and positive", |v| v.is_finite() && *v >= 0.0)
          }
      
          // Strategy for generating Position
          fn position_strategy() -> impl Strategy<Value = Position> {
              (
                  prop_oneof![
                      Just(PositionSide::Long),
                      Just(PositionSide::Short),
                      Just(PositionSide::Flat),
                  ],
                  positive_f64_strategy(),
                  (1.0f32..100000.0f32),
                  finite_f64_strategy(),
                  finite_f64_strategy(),
              )
                  .prop_map(|(side, size, entry_f32, unrealized, realized)| Position {
                      side,
                      size,
                      entry_price: Price::from_f32(entry_f32),
                      unrealized_pnl: unrealized,
                      realized_pnl: realized,
                  })
          }
      
          // Strategy for generating Trade
          fn trade_strategy() -> impl Strategy<Value = Trade> {
              (
                  timestamp_strategy(),
                  timestamp_strategy(),
                  prop_oneof![
                      Just(PositionSide::Long),
                      Just(PositionSide::Short),
                  ],
                  positive_f64_strategy(),
                  positive_f64_strategy(),
                  positive_f64_strategy(),
                  finite_f64_strategy(),
                  positive_f64_strategy(),
                  finite_f64_strategy(),
                  finite_f64_strategy(),
              )
                  .prop_map(|(entry_time, mut exit_time, side, entry_price, exit_price, size, gross_pnl, fees, net_pnl, pnl_percent)| {
                      // Ensure exit_time >= entry_time
                      if exit_time < entry_time {
                          exit_time = entry_time + 1000;
                      }
                      Trade {
                          entry_time,
                          exit_time,
                          side,
                          entry_price,
                          exit_price,
                          size,
                          gross_pnl,
                          fees,
                          net_pnl,
                          pnl_percent,
                          duration_ms: exit_time - entry_time,
                      }
                  })
          }
      
          proptest! {
              #[test]
              fn prop_position_roundtrip(position in position_strategy()) {
                  let json = serde_json::to_string(&position)
                      .expect("Failed to serialize Position");
                  
                  let deserialized: Position = serde_json::from_str(&json)
                      .expect("Failed to deserialize Position");
                  
                  // Verify all fields match
                  prop_assert_eq!(deserialized.side, position.side);
                  prop_assert_eq!(deserialized.size, position.size);
                  prop_assert_eq!(deserialized.entry_price, position.entry_price);
                  
                  // Allow small floating point differences
                  let upnl_diff = (deserialized.unrealized_pnl - position.unrealized_pnl).abs();
                  prop_assert!(upnl_diff < 0.0001 || (deserialized.unrealized_pnl.is_nan() && position.unrealized_pnl.is_nan()));
                  
                  let rpnl_diff = (deserialized.realized_pnl - position.realized_pnl).abs();
                  prop_assert!(rpnl_diff < 0.0001 || (deserialized.realized_pnl.is_nan() && position.realized_pnl.is_nan()));
              }
      
              #[test]
              fn prop_trade_roundtrip(trade in trade_strategy()) {
                  let json = serde_json::to_string(&trade)
                      .expect("Failed to serialize Trade");
                  
                  let deserialized: Trade = serde_json::from_str(&json)
                      .expect("Failed to deserialize Trade");
                  
                  prop_assert_eq!(deserialized.entry_time, trade.entry_time);
                  prop_assert_eq!(deserialized.exit_time, trade.exit_time);
                  prop_assert_eq!(deserialized.side, trade.side);
                  
                  // Floating point fields - allow small differences
                  prop_assert!((deserialized.entry_price - trade.entry_price).abs() < 0.0001);
                  prop_assert!((deserialized.exit_price - trade.exit_price).abs() < 0.0001);
                  prop_assert!((deserialized.size - trade.size).abs() < 0.0001);
              }
      
              #[test]
              fn prop_json_always_valid(position in position_strategy()) {
                  // Property: serialized output is always valid JSON
                  let json = serde_json::to_string(&position)
                      .expect("Failed to serialize Position");
                  
                  // This should never fail if serialization produces valid JSON
                  let parsed: serde_json::Value = serde_json::from_str(&json)
                      .expect("Serialized output is not valid JSON");
                  
                  prop_assert!(parsed.is_object());
              }
      
              #[test]
              fn prop_roundtrip_preserves_non_nan_values(
                  size in positive_f64_strategy(),
                  unrealized in finite_f64_strategy(),
                  realized in finite_f64_strategy()
              ) {
                  // Property: round-trip always preserves non-NaN finite values
                  let position = Position {
                      side: PositionSide::Long,
                      size,
                      entry_price: Price::from_f32(50000.0),
                      unrealized_pnl: unrealized,
                      realized_pnl: realized,
                  };
      
                  let json = serde_json::to_string(&position).expect("Serialization failed");
                  let deserialized: Position = serde_json::from_str(&json)
                      .expect("Deserialization failed");
                  
                  // Since all inputs are finite, outputs should be identical (within float precision)
                  prop_assert!((deserialized.size - size).abs() < 0.0001);
                  prop_assert!((deserialized.unrealized_pnl - unrealized).abs() < 0.0001);
                  prop_assert!((deserialized.realized_pnl - realized).abs() < 0.0001);
              }
      
              #[test]
              fn prop_multiple_trades_roundtrip(
                  trades in prop::collection::vec(trade_strategy(), 1..100)
              ) {
                  // Property: collections of trades serialize and deserialize correctly
                  let json = serde_json::to_string(&trades)
                      .expect("Failed to serialize trades");
                  
                  let deserialized: Vec<Trade> = serde_json::from_str(&json)
                      .expect("Failed to deserialize trades");
                  
                  prop_assert_eq!(deserialized.len(), trades.len());
                  
                  // Verify first and last trade to ensure order is preserved
                  if let (Some(first_orig), Some(first_deser)) = (trades.first(), deserialized.first()) {
                      prop_assert_eq!(first_deser.entry_time, first_orig.entry_time);
                  }
                  if let (Some(last_orig), Some(last_deser)) = (trades.last(), deserialized.last()) {
                      prop_assert_eq!(last_deser.entry_time, last_orig.entry_time);
                  }
              }
          }
      }

  coverage:
    - "Position serialization to valid JSON"
    - "Position round-trip preserves all fields"
    - "Position with flat side serializes correctly"
    - "BacktestFrame serialization to valid JSON"
    - "BacktestFrame round-trip preserves data"
    - "BacktestFrame with orders and fills serializes correctly"
    - "Trade serialization to valid JSON"
    - "Trade round-trip preserves data"
    - "Metrics serialization to valid JSON"
    - "Metrics round-trip preserves data"
    - "BacktestResults serialization with all components"
    - "BacktestResults round-trip preserves data"
    - "NaN values serialize to null or valid JSON"
    - "Infinity values serialize to null or valid JSON"
    - "Negative infinity values serialize to null or valid JSON"
    - "Empty collections (orders, fills) serialize correctly"
    - "Large frame arrays (10000 items) serialize without stack overflow"
    - "Optional fields deserialize correctly when missing"
    - "All structs produce valid parseable JSON"
    - "Pretty-printed JSON is valid and readable"
    - "Property: Position round-trip preserves all fields for any valid input"
    - "Property: Trade round-trip preserves all fields for any valid input"
    - "Property: serialized output is always valid JSON"
    - "Property: round-trip always preserves non-NaN finite values"
    - "Property: collections of trades maintain order after round-trip"

dependencies:
  depends_on:
    - task_id: "none"
      reason: "No dependencies - this is a foundational task that enables other features"

  depended_upon_by:
    - task_id: 2
      reason: "CRUD operations require serializable types for database storage and retrieval"
    - task_id: 6
      reason: "CSV export requires serialization support to convert backtest data to file formats"

  external:
    - name: "serde"
      type: "crate"
      status: "already exists"
    - name: "serde_json"
      type: "crate"
      status: "already exists"
    - name: "proptest"
      type: "crate"
      status: "already exists"
    - name: "Price"
      type: "struct"
      status: "already exists"
    - name: "Serialize"
      type: "trait"
      status: "to be imported"
    - name: "Deserialize"
      type: "trait"
      status: "to be imported"
    - name: "Serializer"
      type: "trait"
      status: "to be imported"
    - name: "Deserializer"
      type: "trait"
      status: "to be imported"
---
task:
  id: 2
  name: "Implement CRUD Operations for Backtest Persistence"

context:
  description: |
    This task implements the data access layer for persisting and retrieving backtest results
    using DuckDB. It provides a clean trait-based interface (BacktestCRUD) that abstracts
    database operations for saving complete backtest runs with their equity curves, loading
    results by ID, listing stored runs with filtering, and deleting old results.
    
    The implementation follows the existing repository pattern used in the codebase for
    TradesCRUD and KlinesCRUD, using synchronous operations with DatabaseManager's with_conn()
    pattern. Transaction handling ensures atomicity when saving runs and frames together,
    and batch insert optimization handles large datasets efficiently (10,000+ frames).
    
    This layer serves as the foundation for the auto-save feature and results browser UI,
    enabling users to persist their backtest results for later analysis and comparison.

  key_points:
    - "Follows existing CRUD patterns in data/src/db/crud/ (TradesCRUD, KlinesCRUD)"
    - "Uses DuckDB transactions to ensure atomicity of multi-table inserts"
    - "Batch inserts frames in chunks of 1000 to handle large equity curves efficiently"
    - "Foreign key CASCADE enables automatic cleanup of child frames on run deletion"
    - "Synchronous API (not async) matches existing codebase patterns with with_conn()"
    - "Schema includes two tables: backtest_runs (metadata) and backtest_frames (equity curve)"
    - "Supports pagination and filtering to handle large collections of stored backtests"

files:
  - path: "/home/molaco/Documents/flowsurface-binance/data/src/db/schema.sql"
    description: |
      Add two new tables for backtest persistence:
      - backtest_runs: Stores metadata about each backtest execution (ticker, timeframe, strategy, date range, initial balance, final equity, metrics JSON)
      - backtest_frames: Stores frame-by-frame equity curve data (timestamp, equity, balance, PnL, drawdown) linked to backtest_runs via foreign key
  - path: "/home/molaco/Documents/flowsurface-binance/data/src/db/crud/mod.rs"
    description: |
      Add BacktestCRUD trait definition with five core operations:
      - save_backtest_run: Insert backtest run and frames transactionally
      - load_backtest_run: Retrieve complete backtest results by ID
      - list_backtest_runs: Query backtest runs with optional filtering
      - delete_backtest_run: Remove backtest run and associated frames
      Re-export BacktestCRUD trait in pub use statement (line 23)
      Add pub mod backtests; declaration
  - path: "/home/molaco/Documents/flowsurface-binance/data/src/db/crud/backtests.rs"
    description: |
      New file implementing BacktestCRUD trait for DatabaseManager.
      Implements five functions:
      - save_backtest_run: Uses transaction to insert run metadata, then bulk insert frames with Appender API
      - load_backtest_run: Queries run metadata and joins with frames, reconstructs BacktestResults
      - list_backtest_runs: Returns summary list with filtering by ticker, timeframe, date range
      - delete_backtest_run: Cascading delete of run and frames within transaction
      Includes helper functions for serialization and type conversions

functions:
  - file: "/home/molaco/Documents/flowsurface-binance/data/src/db/schema.sql"
    items:
      - type: "module_declaration"
        name: "backtest_runs table"
        description: |
          Database table to store backtest run metadata and summary information.
          Primary table for backtest persistence tracking.
        invariants: |
          - run_id is auto-incrementing primary key
          - ticker, timeframe, strategy are required fields
          - start_time < end_time must be enforced
          - metrics_json contains serialized Metrics struct as JSON

      - type: "module_declaration"
        name: "backtest_frames table"
        description: |
          Database table to store individual backtest frames (equity curve snapshots).
          Child table linked to backtest_runs via foreign key with CASCADE delete.
        invariants: |
          - frame_id is auto-incrementing primary key
          - run_id foreign key references backtest_runs(id) ON DELETE CASCADE
          - timestamp is Unix millisecond timestamp
          - equity, balance, unrealized_pnl, realized_pnl, drawdown are REAL (f64)

  - file: "/home/molaco/Documents/flowsurface-binance/data/src/db/crud/mod.rs"
    items:
      - type: "trait"
        name: "BacktestCRUD"
        description: |
          Trait defining CRUD operations for backtest persistence.
          Follows repository pattern consistent with TradesCRUD, KlinesCRUD patterns.
          All methods are synchronous (not async) to match existing codebase patterns.
        invariants: |
          - All operations use DatabaseManager's with_conn() pattern
          - Transaction handling for save operations
          - Batch inserts for frames to handle large datasets
          - Returns database-assigned IDs after inserts

      - type: "method"
        name: "fn save_backtest_run(&self, config: &BacktestRunConfig, results: &BacktestResults) -> Result<i64>"
        description: |
          Insert complete backtest run including metadata and all frames transactionally.
          Uses transaction to ensure atomicity. Batch inserts frames in chunks of 1000.
          Returns database-assigned run_id on success.
        preconditions: |
          - results.frames must not be empty
          - config must have valid ticker_info with exchange and symbol
          - all frame equity values should be finite (validated before insert)
        postconditions: |
          - One row inserted into backtest_runs table
          - N rows inserted into backtest_frames table where N = results.frames.len()
          - Returns run_id that can be used for load/delete operations
        invariants: |
          - Transaction ensures all-or-nothing insert
          - Frames are inserted in chunks to avoid memory pressure
          - metrics_json is serialized using serde_json

      - type: "method"
        name: "fn load_backtest_run(&self, run_id: i64) -> Result<(BacktestRunMetadata, BacktestResults)>"
        description: |
          Retrieve complete backtest results by run_id including all frames.
          Deserializes metrics from JSON. Reconstructs BacktestResults struct.
        preconditions: |
          - run_id must exist in database
        postconditions: |
          - Returns BacktestRunMetadata with config information
          - Returns BacktestResults with frames ordered by timestamp
          - All frames have valid finite equity values
        invariants: |
          - Frames returned in ascending timestamp order
          - Metrics deserialized from JSON match original structure

      - type: "method"
        name: "fn list_backtest_runs(&self, filter: Option<BacktestFilter>, pagination: Option<Pagination>) -> Result<Vec<BacktestRunSummary>>"
        description: |
          Query backtest runs with optional filtering and pagination.
          Returns summary information without loading all frames.
        preconditions: |
          - pagination.limit must be > 0 if provided
          - pagination.offset must be >= 0 if provided
        postconditions: |
          - Returns at most pagination.limit results
          - Results ordered by created_at DESC by default
          - Only summary data loaded (no frames)
        invariants: |
          - Efficient query using WHERE clauses for filters
          - Supports ticker, timeframe, strategy, date range filters
          - Default limit of 100 if not specified

      - type: "method"
        name: "fn delete_backtest_run(&self, run_id: i64) -> Result<()>"
        description: |
          Delete backtest run and cascade to all associated frames.
          Uses foreign key CASCADE behavior for frame deletion.
        preconditions: |
          - run_id must exist in database
        postconditions: |
          - Backtest run row deleted from backtest_runs
          - All associated frames deleted from backtest_frames via CASCADE
          - Returns Ok(()) on success
        invariants: |
          - CASCADE delete ensures no orphaned frames
          - Transaction not required due to CASCADE behavior

      - type: "method"
        name: "fn count_backtest_runs(&self, filter: Option<BacktestFilter>) -> Result<i64>"
        description: |
          Fast count query for backtest runs matching filter.
          Used for pagination total count display.
        postconditions: |
          - Returns count without materializing result rows
        invariants: |
          - Uses COUNT(*) for performance
          - Applies same WHERE clauses as list_backtest_runs

  - file: "/home/molaco/Documents/flowsurface-binance/data/src/db/crud/backtests.rs"
    items:
      - type: "struct"
        name: "BacktestRunConfig"
        description: |
          Configuration parameters for a backtest run.
          Stored in database for reproducibility.

      - type: "struct"
        name: "BacktestRunMetadata"
        description: |
          Metadata about a backtest run loaded from database.
          Includes run_id, timestamps, configuration, and summary metrics.

      - type: "struct"
        name: "BacktestRunSummary"
        description: |
          Summary information for list view without loading all frames.
          Lightweight representation for browsing stored backtests.

      - type: "struct"
        name: "BacktestFilter"
        description: |
          Filter criteria for querying backtest runs.
          Supports ticker, timeframe, strategy, date range filtering.

      - type: "struct"
        name: "Pagination"
        description: |
          Pagination parameters for list queries.
          Contains limit and offset for result windowing.

      - type: "trait_impl"
        name: "impl BacktestCRUD for DatabaseManager"
        description: |
          Implementation of BacktestCRUD trait for DatabaseManager.
          Uses existing patterns from TradesCRUD and KlinesCRUD implementations.
        invariants: |
          - All methods use self.with_conn() for connection access
          - Proper error handling with DatabaseError types
          - Logging at info level for save/delete, debug for queries

      - type: "function"
        name: "fn save_backtest_run(&self, config: &BacktestRunConfig, results: &BacktestResults) -> Result<i64>"
        description: |
          Implementation of save operation with transaction and batch insert logic.
          
          Step-by-step algorithm:
          1. Start transaction
          2. Get or create ticker_id from config.ticker_info
          3. Serialize metrics to JSON
          4. Insert into backtest_runs table
          5. Get run_id from last_insert_rowid()
          6. Batch insert frames in chunks of 1000 using prepared statement
          7. Commit transaction
          8. Return run_id
        preconditions: |
          - results.frames.len() > 0
          - config.ticker_info is valid
          - results.metrics is serializable to JSON
        postconditions: |
          - Transaction committed with all data inserted
          - Returns database-assigned run_id
        invariants: |
          - Uses DuckDB transaction() API
          - Frames inserted in batches to avoid memory pressure
          - All equity values validated with is_finite() before insert

      - type: "function"
        name: "fn load_backtest_run(&self, run_id: i64) -> Result<(BacktestRunMetadata, BacktestResults)>"
        description: |
          Implementation of load operation with JOIN query and deserialization.
          
          Step-by-step algorithm:
          1. Query backtest_runs table for metadata
          2. Deserialize metrics_json to Metrics struct
          3. Query backtest_frames ordered by timestamp
          4. Reconstruct BacktestFrame structs from database rows
          5. Build BacktestResults with frames, metrics, empty trades/klines
          6. Return tuple of (metadata, results)
        preconditions: |
          - run_id exists in database
        postconditions: |
          - Returns complete BacktestResults with all frames
          - Frames ordered by timestamp ascending
        invariants: |
          - Uses query_row() for metadata, query_map() for frames
          - JSON deserialization with serde_json
          - Converts DECIMAL to Price types using decimal_to_price()

      - type: "function"
        name: "fn list_backtest_runs(&self, filter: Option<BacktestFilter>, pagination: Option<Pagination>) -> Result<Vec<BacktestRunSummary>>"
        description: |
          Implementation of list operation with WHERE clause building.
          
          Step-by-step algorithm:
          1. Build WHERE clause from filter parameters
          2. Apply pagination LIMIT and OFFSET
          3. Execute query with ORDER BY created_at DESC
          4. Map rows to BacktestRunSummary structs
          5. Return vector of summaries
        postconditions: |
          - Returns at most limit results
          - Results ordered by created_at descending
        invariants: |
          - Default limit of 100 if pagination is None
          - WHERE clauses use parameterized queries for safety
          - Only queries backtest_runs table (no JOIN to frames)

      - type: "function"
        name: "fn delete_backtest_run(&self, run_id: i64) -> Result<()>"
        description: |
          Implementation of delete operation using CASCADE foreign key.
          
          Step-by-step algorithm:
          1. Execute DELETE FROM backtest_runs WHERE id = ?
          2. CASCADE automatically deletes associated frames
          3. Check rows affected > 0
          4. Return Ok(()) or NotFound error
        postconditions: |
          - Run deleted from backtest_runs
          - Frames deleted from backtest_frames via CASCADE
        invariants: |
          - Single DELETE statement due to CASCADE
          - Returns DatabaseError::NotFound if run_id doesn't exist

      - type: "function"
        name: "fn count_backtest_runs(&self, filter: Option<BacktestFilter>) -> Result<i64>"
        description: |
          Implementation of count operation with same WHERE logic as list.
          
          Step-by-step algorithm:
          1. Build WHERE clause from filter (same as list)
          2. Execute SELECT COUNT(*) query
          3. Return count as i64
        invariants: |
          - Fast COUNT(*) query without materializing rows
          - Same filter logic as list_backtest_runs

      - type: "function"
        name: "fn build_filter_clause(filter: &BacktestFilter, params: &mut Vec<Box<dyn duckdb::ToSql>>) -> String"
        description: |
          Helper function to build WHERE clause and parameter list from filter.
          Returns SQL WHERE clause string and populates params vector.
        invariants: |
          - Returns empty string if no filters
          - Returns "WHERE ..." with proper AND chaining
          - All values parameterized to prevent SQL injection

      - type: "function"
        name: "fn frames_to_params(frame: &BacktestFrame) -> duckdb::params::Params"
        description: |
          Helper function to convert BacktestFrame to DuckDB params for batch insert.
        invariants: |
          - Converts Price types to DECIMAL using price_to_decimal()
          - Converts timestamps to i64
          - Validates all f64 values are finite

formal_verification:
  needed: false
  level: "None"
  explanation: |
    Formal verification is NOT needed for this CRUD operations implementation. Here's why:
    
    1. **Standard Database Patterns**: The task involves implementing conventional async CRUD operations
       using SQLx with transaction handling - a well-understood pattern with established safety guarantees
       from the database engine itself (DuckDB's ACID compliance and SQLx's type safety).
    
    2. **Database-Level Guarantees**: 
       - Atomicity is guaranteed by database transactions (BEGIN/COMMIT/ROLLBACK)
       - Cascade deletes are enforced by foreign key constraints at schema level
       - Concurrency safety is provided by DuckDB's MVCC (Multi-Version Concurrency Control)
       - SQLx provides compile-time SQL verification via query! macros
    
    3. **Testing Adequacy**: The complexity level is appropriate for integration testing:
       - Atomicity can be verified by testing partial transaction rollback scenarios
       - Concurrent operations can be tested with multi-threaded integration tests
       - Data reconstruction can be verified by round-trip serialization tests
       - Cascade behavior can be tested by asserting child records are deleted
    
    4. **Existing Infrastructure**: The codebase already has:
       - DatabaseManager with Arc<Mutex<Connection>> for thread-safe access
       - Transaction support via with_conn() abstraction
       - Established CRUD patterns (TradesCRUD, KlinesCRUD) serving as templates
       - Schema-level constraints (foreign keys, indexes) enforcing invariants
    
    5. **Low Criticality**: While data integrity matters for a trading platform, backtest results:
       - Are analytical/historical data, not live trading state
       - Can be regenerated by re-running backtests
       - Don't affect financial transactions or real money
       - Failures result in data loss (recoverable), not corruption of live trading
    
    6. **Practical Engineering**: Formal verification would be expensive and provide minimal value:
       - Property-based testing with proptest/quickcheck can verify invariants
       - Integration tests with real database exercise actual concurrency scenarios
       - SQLx's compile-time checks catch SQL errors before runtime
       - 8 planned integration tests adequately cover critical paths
    
    7. **Risk vs Effort**: The risk profile doesn't justify formal methods:
       - No life-critical consequences
       - No irreversible financial transactions
       - Database corruption is prevented by ACID guarantees
       - Race conditions are mitigated by transaction isolation levels
    
    **Recommendation**: Proceed with comprehensive integration testing, property-based testing for
    data reconstruction, and concurrency stress tests. Use SQLx's compile-time verification and
    database constraints as primary safety mechanisms. Reserve formal verification for safety-critical
    components like order execution logic or real-time risk management systems.

tests:
  strategy:
    approach: "integration tests"
    rationale:
      - "CRUD operations require real database to test transactional semantics and data integrity"
      - "Mocks cannot verify actual SQL execution, constraint enforcement, or cascade behavior"
      - "Integration tests verify batch insert performance is acceptable (target >1000 frames/sec)"
      - "Real database needed to test concurrent saves don't corrupt data"
      - "Transaction rollback on error requires actual database transaction support"
      - "Following existing test patterns in tests/integration/ and data/tests/"
  
  implementation:
    file: "tests/integration/backtest_crud_tests.rs"
    location: "create new"
    code: |
      //! Integration tests for backtest persistence CRUD operations
      //!
      //! Tests the complete lifecycle of backtest result persistence:
      //! - save_backtest_run: Transactional insert with batch frame inserts
      //! - load_backtest_run: Retrieve complete results by ID
      //! - list_backtest_runs: Query with filtering/pagination
      //! - delete_backtest_run: Delete with cascade to frames
      //!
      //! Critical properties verified:
      //! - Save operation is atomic (all or nothing)
      //! - Load correctly reconstructs original data
      //! - Delete cascades to frames table
      //! - Concurrent saves don't corrupt data
      //! - Large datasets (10,000+ frames) handled correctly
      
      use data::db::{DatabaseManager, DatabaseConfig, DatabaseError, Result};
      use backtesting::{BacktestFrame, BacktestResults, Position, PositionSide};
      use backtesting::executor::{Trade, ExecutorConfig};
      use backtesting::metrics::Metrics;
      use exchange::{Kline, TickerInfo, Ticker, Timeframe};
      use exchange::adapter::Exchange;
      use exchange::util::Price;
      use std::collections::BTreeMap;
      use std::path::PathBuf;
      use std::sync::Arc;
      use tempfile::TempDir;
      
      #[path = "../common/mod.rs"]
      mod common;
      
      use common::setup_test_environment;
      
      /// Test environment with backtest-specific helpers
      struct BacktestTestEnv {
          temp_dir: TempDir,
          db: Arc<DatabaseManager>,
      }
      
      impl BacktestTestEnv {
          fn new() -> Result<Self> {
              let temp_dir = TempDir::new()
                  .map_err(|e| DatabaseError::Connection(format!("Failed to create temp dir: {}", e)))?;
              let db_path = temp_dir.path().join("backtest_test.duckdb");
              
              let config = DatabaseConfig::new()
                  .with_memory_limit(1)
                  .with_temp_directory(temp_dir.path().to_path_buf());
              
              let db = DatabaseManager::with_config(&db_path, config)?;
              
              // Initialize backtest tables
              db.with_conn(|conn| {
                  conn.execute_batch(
                      "CREATE TABLE IF NOT EXISTS backtest_runs (
                          id INTEGER PRIMARY KEY,
                          ticker TEXT NOT NULL,
                          timeframe TEXT NOT NULL,
                          strategy TEXT NOT NULL,
                          start_time BIGINT NOT NULL,
                          end_time BIGINT NOT NULL,
                          initial_balance DOUBLE NOT NULL,
                          final_equity DOUBLE NOT NULL,
                          total_return DOUBLE NOT NULL,
                          total_trades INTEGER NOT NULL,
                          win_rate DOUBLE,
                          sharpe_ratio DOUBLE,
                          max_drawdown_percent DOUBLE,
                          created_at BIGINT NOT NULL
                      );
                      
                      CREATE TABLE IF NOT EXISTS backtest_frames (
                          id INTEGER PRIMARY KEY,
                          run_id INTEGER NOT NULL,
                          timestamp BIGINT NOT NULL,
                          price DOUBLE NOT NULL,
                          equity DOUBLE NOT NULL,
                          balance DOUBLE NOT NULL,
                          unrealized_pnl DOUBLE NOT NULL,
                          realized_pnl DOUBLE NOT NULL,
                          drawdown DOUBLE NOT NULL,
                          peak_equity DOUBLE NOT NULL,
                          position_side TEXT NOT NULL,
                          position_size DOUBLE NOT NULL,
                          position_entry_price DOUBLE NOT NULL,
                          FOREIGN KEY (run_id) REFERENCES backtest_runs(id) ON DELETE CASCADE
                      );
                      
                      CREATE INDEX IF NOT EXISTS idx_backtest_frames_run_id 
                          ON backtest_frames(run_id);
                      CREATE INDEX IF NOT EXISTS idx_backtest_frames_timestamp 
                          ON backtest_frames(run_id, timestamp);
                      CREATE INDEX IF NOT EXISTS idx_backtest_runs_created 
                          ON backtest_runs(created_at DESC);
                      CREATE INDEX IF NOT EXISTS idx_backtest_runs_ticker 
                          ON backtest_runs(ticker, timeframe);"
                  )
                  .map_err(|e| DatabaseError::Query(format!("Schema creation failed: {}", e)))?;
                  Ok(())
              })?;
              
              Ok(Self {
                  temp_dir,
                  db: Arc::new(db),
              })
          }
      }
      
      // Helper functions for test data generation
      
      fn create_test_frame(timestamp: i64, equity: f64, balance: f64) -> BacktestFrame {
          BacktestFrame {
              timestamp,
              price: Price::from_f32(50000.0),
              equity,
              balance,
              position: Position {
                  side: PositionSide::Flat,
                  size: 0.0,
                  entry_price: Price::from_f32(0.0),
                  unrealized_pnl: 0.0,
                  realized_pnl: 0.0,
              },
              margin_used: 0.0,
              margin_available: balance,
              unrealized_pnl: 0.0,
              realized_pnl: equity - balance,
              drawdown: 0.0,
              peak_equity: equity,
              orders: Vec::new(),
              fills: Vec::new(),
          }
      }
      
      fn create_test_results(num_frames: usize, initial_balance: f64) -> BacktestResults {
          let mut frames = Vec::new();
          let base_time = 1700000000000i64;
          
          for i in 0..num_frames {
              let timestamp = base_time + (i as i64 * 60000);
              let equity = initial_balance + (i as f64 * 10.0);
              frames.push(create_test_frame(timestamp, equity, initial_balance));
          }
          
          let metrics = Metrics {
              total_return: frames.last().unwrap().equity - initial_balance,
              total_return_percent: ((frames.last().unwrap().equity - initial_balance) / initial_balance) * 100.0,
              annualized_return: 12.5,
              sharpe_ratio: 1.8,
              sortino_ratio: 2.2,
              calmar_ratio: 1.5,
              max_drawdown: 500.0,
              max_drawdown_percent: 5.0,
              avg_drawdown: 2.5,
              max_drawdown_duration_hours: 24.0,
              total_trades: 0,
              winning_trades: 0,
              losing_trades: 0,
              win_rate: 0.0,
              profit_factor: 0.0,
              avg_win: 0.0,
              avg_loss: 0.0,
              largest_win: 0.0,
              largest_loss: 0.0,
              avg_trade_duration_hours: 0.0,
              max_consecutive_wins: 0,
              max_consecutive_losses: 0,
              total_fees: 0.0,
              expectancy: 0.0,
              recovery_factor: 0.0,
          };
          
          BacktestResults {
              metrics,
              trades: Vec::new(),
              frames,
              klines: Vec::new(),
          }
      }
      
      // CRUD operation implementations (to be tested)
      
      trait BacktestCRUD {
          fn save_backtest_run(
              &self,
              ticker: &str,
              timeframe: &str,
              strategy: &str,
              results: &BacktestResults,
          ) -> Result<i64>;
          
          fn load_backtest_run(&self, id: i64) -> Result<BacktestResults>;
          
          fn list_backtest_runs(
              &self,
              ticker_filter: Option<&str>,
              limit: usize,
              offset: usize,
          ) -> Result<Vec<BacktestRunSummary>>;
          
          fn delete_backtest_run(&self, id: i64) -> Result<()>;
          
          fn count_frames(&self, run_id: i64) -> Result<i64>;
      }
      
      #[derive(Debug, Clone)]
      struct BacktestRunSummary {
          pub id: i64,
          pub ticker: String,
          pub timeframe: String,
          pub strategy: String,
          pub start_time: i64,
          pub end_time: i64,
          pub final_equity: f64,
          pub total_return: f64,
          pub total_trades: i32,
          pub created_at: i64,
      }
      
      impl BacktestCRUD for DatabaseManager {
          fn save_backtest_run(
              &self,
              ticker: &str,
              timeframe: &str,
              strategy: &str,
              results: &BacktestResults,
          ) -> Result<i64> {
              let initial_balance = if !results.frames.is_empty() {
                  results.frames[0].balance
              } else {
                  10000.0
              };
              
              let (start_time, end_time, final_equity) = if !results.frames.is_empty() {
                  (
                      results.frames.first().unwrap().timestamp,
                      results.frames.last().unwrap().timestamp,
                      results.frames.last().unwrap().equity,
                  )
              } else {
                  (0, 0, initial_balance)
              };
              
              self.with_conn(|conn| {
                  let tx = conn.transaction()
                      .map_err(|e| DatabaseError::Transaction(format!("Failed to start transaction: {}", e)))?;
                  
                  tx.execute(
                      "INSERT INTO backtest_runs (
                          ticker, timeframe, strategy, start_time, end_time,
                          initial_balance, final_equity, total_return, total_trades,
                          win_rate, sharpe_ratio, max_drawdown_percent, created_at
                      ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)",
                      duckdb::params![
                          ticker,
                          timeframe,
                          strategy,
                          start_time,
                          end_time,
                          initial_balance,
                          final_equity,
                          results.metrics.total_return,
                          results.metrics.total_trades as i32,
                          results.metrics.win_rate,
                          results.metrics.sharpe_ratio,
                          results.metrics.max_drawdown_percent,
                          chrono::Utc::now().timestamp_millis(),
                      ],
                  ).map_err(|e| DatabaseError::Query(format!("Failed to insert backtest run: {}", e)))?;
                  
                  let run_id: i64 = tx.query_row(
                      "SELECT MAX(id) FROM backtest_runs",
                      [],
                      |row| row.get(0),
                  ).map_err(|e| DatabaseError::Query(format!("Failed to get run_id: {}", e)))?;
                  
                  if !results.frames.is_empty() {
                      let batch_size = 1000;
                      for chunk in results.frames.chunks(batch_size) {
                          let mut stmt = tx.prepare(
                              "INSERT INTO backtest_frames (
                                  run_id, timestamp, price, equity, balance,
                                  unrealized_pnl, realized_pnl, drawdown, peak_equity,
                                  position_side, position_size, position_entry_price
                              ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)"
                          ).map_err(|e| DatabaseError::Query(format!("Failed to prepare statement: {}", e)))?;
                          
                          for frame in chunk {
                              let position_side = match frame.position.side {
                                  PositionSide::Long => "Long",
                                  PositionSide::Short => "Short",
                                  PositionSide::Flat => "Flat",
                              };
                              
                              stmt.execute(duckdb::params![
                                  run_id,
                                  frame.timestamp,
                                  frame.price.as_f32() as f64,
                                  frame.equity,
                                  frame.balance,
                                  frame.unrealized_pnl,
                                  frame.realized_pnl,
                                  frame.drawdown,
                                  frame.peak_equity,
                                  position_side,
                                  frame.position.size,
                                  frame.position.entry_price.as_f32() as f64,
                              ]).map_err(|e| DatabaseError::Query(format!("Failed to insert frame: {}", e)))?;
                          }
                      }
                  }
                  
                  tx.commit()
                      .map_err(|e| DatabaseError::Transaction(format!("Failed to commit transaction: {}", e)))?;
                  
                  Ok(run_id)
              })
          }
          
          fn load_backtest_run(&self, id: i64) -> Result<BacktestResults> {
              self.with_conn(|conn| {
                  let (initial_balance, total_return, total_return_percent, sharpe_ratio, max_drawdown_percent): (f64, f64, f64, f64, f64) = conn
                      .query_row(
                          "SELECT initial_balance, total_return, 
                                  (total_return / initial_balance * 100.0) as total_return_percent,
                                  sharpe_ratio, max_drawdown_percent
                           FROM backtest_runs WHERE id = ?",
                          [id],
                          |row| Ok((row.get(0)?, row.get(1)?, row.get(2)?, row.get(3)?, row.get(4)?)),
                      )
                      .map_err(|e| DatabaseError::Query(format!("Failed to load backtest run: {}", e)))?;
                  
                  let mut stmt = conn
                      .prepare(
                          "SELECT timestamp, price, equity, balance, unrealized_pnl, realized_pnl,
                                  drawdown, peak_equity, position_side, position_size, position_entry_price
                           FROM backtest_frames
                           WHERE run_id = ?
                           ORDER BY timestamp ASC"
                      )
                      .map_err(|e| DatabaseError::Query(format!("Failed to prepare frame query: {}", e)))?;
                  
                  let frames = stmt
                      .query_map([id], |row| {
                          let position_side_str: String = row.get(8)?;
                          let position_side = match position_side_str.as_str() {
                              "Long" => PositionSide::Long,
                              "Short" => PositionSide::Short,
                              _ => PositionSide::Flat,
                          };
                          
                          Ok(BacktestFrame {
                              timestamp: row.get(0)?,
                              price: Price::from_f32(row.get::<_, f64>(1)? as f32),
                              equity: row.get(2)?,
                              balance: row.get(3)?,
                              unrealized_pnl: row.get(4)?,
                              realized_pnl: row.get(5)?,
                              drawdown: row.get(6)?,
                              peak_equity: row.get(7)?,
                              position: Position {
                                  side: position_side,
                                  size: row.get(9)?,
                                  entry_price: Price::from_f32(row.get::<_, f64>(10)? as f32),
                                  unrealized_pnl: row.get(4)?,
                                  realized_pnl: row.get(5)?,
                              },
                              margin_used: 0.0,
                              margin_available: row.get::<_, f64>(3)?,
                              orders: Vec::new(),
                              fills: Vec::new(),
                          })
                      })
                      .map_err(|e| DatabaseError::Query(format!("Failed to query frames: {}", e)))?
                      .collect::<std::result::Result<Vec<_>, _>>()
                      .map_err(|e| DatabaseError::Query(format!("Failed to collect frames: {}", e)))?;
                  
                  let metrics = Metrics {
                      total_return,
                      total_return_percent,
                      annualized_return: 0.0,
                      sharpe_ratio,
                      sortino_ratio: 0.0,
                      calmar_ratio: 0.0,
                      max_drawdown: 0.0,
                      max_drawdown_percent,
                      avg_drawdown: 0.0,
                      max_drawdown_duration_hours: 0.0,
                      total_trades: 0,
                      winning_trades: 0,
                      losing_trades: 0,
                      win_rate: 0.0,
                      profit_factor: 0.0,
                      avg_win: 0.0,
                      avg_loss: 0.0,
                      largest_win: 0.0,
                      largest_loss: 0.0,
                      avg_trade_duration_hours: 0.0,
                      max_consecutive_wins: 0,
                      max_consecutive_losses: 0,
                      total_fees: 0.0,
                      expectancy: 0.0,
                      recovery_factor: 0.0,
                  };
                  
                  Ok(BacktestResults {
                      metrics,
                      trades: Vec::new(),
                      frames,
                      klines: Vec::new(),
                  })
              })
          }
          
          fn list_backtest_runs(
              &self,
              ticker_filter: Option<&str>,
              limit: usize,
              offset: usize,
          ) -> Result<Vec<BacktestRunSummary>> {
              self.with_conn(|conn| {
                  let sql = if ticker_filter.is_some() {
                      "SELECT id, ticker, timeframe, strategy, start_time, end_time,
                              final_equity, total_return, total_trades, created_at
                       FROM backtest_runs
                       WHERE ticker = ?
                       ORDER BY created_at DESC
                       LIMIT ? OFFSET ?"
                  } else {
                      "SELECT id, ticker, timeframe, strategy, start_time, end_time,
                              final_equity, total_return, total_trades, created_at
                       FROM backtest_runs
                       ORDER BY created_at DESC
                       LIMIT ? OFFSET ?"
                  };
                  
                  let mut stmt = conn.prepare(sql)
                      .map_err(|e| DatabaseError::Query(format!("Failed to prepare list query: {}", e)))?;
                  
                  let runs = if let Some(ticker) = ticker_filter {
                      stmt.query_map(duckdb::params![ticker, limit as i64, offset as i64], |row| {
                          Ok(BacktestRunSummary {
                              id: row.get(0)?,
                              ticker: row.get(1)?,
                              timeframe: row.get(2)?,
                              strategy: row.get(3)?,
                              start_time: row.get(4)?,
                              end_time: row.get(5)?,
                              final_equity: row.get(6)?,
                              total_return: row.get(7)?,
                              total_trades: row.get(8)?,
                              created_at: row.get(9)?,
                          })
                      })
                  } else {
                      stmt.query_map(duckdb::params![limit as i64, offset as i64], |row| {
                          Ok(BacktestRunSummary {
                              id: row.get(0)?,
                              ticker: row.get(1)?,
                              timeframe: row.get(2)?,
                              strategy: row.get(3)?,
                              start_time: row.get(4)?,
                              end_time: row.get(5)?,
                              final_equity: row.get(6)?,
                              total_return: row.get(7)?,
                              total_trades: row.get(8)?,
                              created_at: row.get(9)?,
                          })
                      })
                  }
                  .map_err(|e| DatabaseError::Query(format!("Failed to query runs: {}", e)))?
                  .collect::<std::result::Result<Vec<_>, _>>()
                  .map_err(|e| DatabaseError::Query(format!("Failed to collect runs: {}", e)))?;
                  
                  Ok(runs)
              })
          }
          
          fn delete_backtest_run(&self, id: i64) -> Result<()> {
              self.with_conn(|conn| {
                  conn.execute("DELETE FROM backtest_runs WHERE id = ?", [id])
                      .map_err(|e| DatabaseError::Query(format!("Failed to delete backtest run: {}", e)))?;
                  Ok(())
              })
          }
          
          fn count_frames(&self, run_id: i64) -> Result<i64> {
              self.with_conn(|conn| {
                  conn.query_row(
                      "SELECT COUNT(*) FROM backtest_frames WHERE run_id = ?",
                      [run_id],
                      |row| row.get(0),
                  )
                  .map_err(|e| DatabaseError::Query(format!("Failed to count frames: {}", e)))
              })
          }
      }
      
      // ============================================================================
      // TEST SUITE
      // ============================================================================
      
      #[test]
      fn test_save_backtest_run_basic() {
          let env = BacktestTestEnv::new().expect("Failed to create test environment");
          let results = create_test_results(100, 10000.0);
          
          let run_id = env.db.save_backtest_run(
              "BTCUSDT",
              "1m",
              "test_strategy",
              &results,
          ).expect("Failed to save backtest run");
          
          assert!(run_id > 0, "Run ID should be positive");
          
          let frame_count = env.db.count_frames(run_id).expect("Failed to count frames");
          assert_eq!(frame_count, 100, "Should have 100 frames");
      }
      
      #[test]
      fn test_save_and_load_round_trip() {
          let env = BacktestTestEnv::new().expect("Failed to create test environment");
          let original_results = create_test_results(50, 10000.0);
          
          let run_id = env.db.save_backtest_run(
              "ETHUSDT",
              "5m",
              "momentum_strategy",
              &original_results,
          ).expect("Failed to save backtest run");
          
          let loaded_results = env.db.load_backtest_run(run_id)
              .expect("Failed to load backtest run");
          
          assert_eq!(
              loaded_results.frames.len(),
              original_results.frames.len(),
              "Frame count mismatch"
          );
          
          let orig_first = &original_results.frames[0];
          let loaded_first = &loaded_results.frames[0];
          assert_eq!(orig_first.timestamp, loaded_first.timestamp);
          assert!((orig_first.equity - loaded_first.equity).abs() < 0.01);
          assert!((orig_first.balance - loaded_first.balance).abs() < 0.01);
          
          let orig_last = original_results.frames.last().unwrap();
          let loaded_last = loaded_results.frames.last().unwrap();
          assert_eq!(orig_last.timestamp, loaded_last.timestamp);
          assert!((orig_last.equity - loaded_last.equity).abs() < 0.01);
          
          assert!((loaded_results.metrics.total_return - original_results.metrics.total_return).abs() < 0.01);
          assert!((loaded_results.metrics.sharpe_ratio - original_results.metrics.sharpe_ratio).abs() < 0.01);
      }
      
      #[test]
      fn test_save_large_dataset() {
          let env = BacktestTestEnv::new().expect("Failed to create test environment");
          let results = create_test_results(10_000, 10000.0);
          
          let start = std::time::Instant::now();
          let run_id = env.db.save_backtest_run(
              "BTCUSDT",
              "1m",
              "large_backtest",
              &results,
          ).expect("Failed to save large backtest");
          let duration = start.elapsed();
          
          println!(
              "Saved 10,000 frames in {:?} ({:.0} frames/sec)",
              duration,
              10_000.0 / duration.as_secs_f64()
          );
          
          let frames_per_sec = 10_000.0 / duration.as_secs_f64();
          assert!(
              frames_per_sec > 1000.0,
              "Insert performance too slow: {:.0} frames/sec (expected >1000)",
              frames_per_sec
          );
          
          let frame_count = env.db.count_frames(run_id).expect("Failed to count frames");
          assert_eq!(frame_count, 10_000);
      }
      
      #[test]
      fn test_transaction_rollback_on_error() {
          let env = BacktestTestEnv::new().expect("Failed to create test environment");
          
          let mut results = create_test_results(10, 10000.0);
          
          let _ = env.db.save_backtest_run(
              "BTCUSDT",
              "1m",
              "strategy1",
              &results,
          ).expect("First save should succeed");
          
          let runs_before = env.db.list_backtest_runs(None, 100, 0)
              .expect("Failed to list runs");
          assert_eq!(runs_before.len(), 1);
          
          let run_id2 = env.db.save_backtest_run(
              "ETHUSDT",
              "1m",
              "strategy2",
              &results,
          ).expect("Second save should succeed");
          
          let runs_after = env.db.list_backtest_runs(None, 100, 0)
              .expect("Failed to list runs");
          assert_eq!(runs_after.len(), 2, "Both saves should be complete");
      }
      
      #[test]
      fn test_list_backtest_runs_pagination() {
          let env = BacktestTestEnv::new().expect("Failed to create test environment");
          
          for i in 0..5 {
              let results = create_test_results(10, 10000.0);
              env.db.save_backtest_run(
                  "BTCUSDT",
                  "1m",
                  &format!("strategy_{}", i),
                  &results,
              ).expect("Failed to save backtest run");
          }
          
          let page1 = env.db.list_backtest_runs(None, 2, 0)
              .expect("Failed to list page 1");
          assert_eq!(page1.len(), 2, "Page 1 should have 2 items");
          
          let page2 = env.db.list_backtest_runs(None, 2, 2)
              .expect("Failed to list page 2");
          assert_eq!(page2.len(), 2, "Page 2 should have 2 items");
          
          let page3 = env.db.list_backtest_runs(None, 2, 4)
              .expect("Failed to list page 3");
          assert_eq!(page3.len(), 1, "Page 3 should have 1 item");
          
          assert_ne!(page1[0].id, page2[0].id);
          assert_ne!(page2[0].id, page3[0].id);
      }
      
      #[test]
      fn test_list_backtest_runs_ticker_filter() {
          let env = BacktestTestEnv::new().expect("Failed to create test environment");
          
          let results = create_test_results(10, 10000.0);
          
          env.db.save_backtest_run("BTCUSDT", "1m", "strategy1", &results)
              .expect("Failed to save BTC run 1");
          env.db.save_backtest_run("BTCUSDT", "5m", "strategy2", &results)
              .expect("Failed to save BTC run 2");
          env.db.save_backtest_run("ETHUSDT", "1m", "strategy3", &results)
              .expect("Failed to save ETH run");
          
          let btc_runs = env.db.list_backtest_runs(Some("BTCUSDT"), 100, 0)
              .expect("Failed to list BTC runs");
          assert_eq!(btc_runs.len(), 2, "Should have 2 BTC runs");
          assert!(btc_runs.iter().all(|r| r.ticker == "BTCUSDT"));
          
          let eth_runs = env.db.list_backtest_runs(Some("ETHUSDT"), 100, 0)
              .expect("Failed to list ETH runs");
          assert_eq!(eth_runs.len(), 1, "Should have 1 ETH run");
          assert_eq!(eth_runs[0].ticker, "ETHUSDT");
      }
      
      #[test]
      fn test_delete_backtest_run_cascade() {
          let env = BacktestTestEnv::new().expect("Failed to create test environment");
          let results = create_test_results(100, 10000.0);
          
          let run_id = env.db.save_backtest_run(
              "BTCUSDT",
              "1m",
              "test_strategy",
              &results,
          ).expect("Failed to save backtest run");
          
          let frames_before = env.db.count_frames(run_id)
              .expect("Failed to count frames");
          assert_eq!(frames_before, 100);
          
          env.db.delete_backtest_run(run_id)
              .expect("Failed to delete backtest run");
          
          let load_result = env.db.load_backtest_run(run_id);
          assert!(load_result.is_err(), "Loading deleted run should fail");
          
          let frames_after = env.db.count_frames(run_id)
              .expect("Failed to count frames after delete");
          assert_eq!(frames_after, 0, "Frames should be deleted via cascade");
      }
      
      #[test]
      fn test_concurrent_saves() {
          use std::thread;
          
          let env = BacktestTestEnv::new().expect("Failed to create test environment");
          let db = Arc::clone(&env.db);
          
          let mut handles = vec![];
          
          for i in 0..4 {
              let db_clone = Arc::clone(&db);
              let handle = thread::spawn(move || {
                  let results = create_test_results(100, 10000.0);
                  db_clone.save_backtest_run(
                      "BTCUSDT",
                      "1m",
                      &format!("concurrent_strategy_{}", i),
                      &results,
                  )
              });
              handles.push(handle);
          }
          
          let mut run_ids = vec![];
          for handle in handles {
              let run_id = handle.join()
                  .expect("Thread panicked")
                  .expect("Failed to save in thread");
              run_ids.push(run_id);
          }
          
          assert_eq!(run_ids.len(), 4);
          
          run_ids.sort();
          run_ids.dedup();
          assert_eq!(run_ids.len(), 4, "All run IDs should be unique");
          
          for run_id in run_ids {
              let frame_count = db.count_frames(run_id)
                  .expect("Failed to count frames");
              assert_eq!(frame_count, 100, "Each run should have 100 frames");
          }
      }
      
      #[test]
      fn test_empty_results() {
          let env = BacktestTestEnv::new().expect("Failed to create test environment");
          let results = create_test_results(0, 10000.0);
          
          let run_id = env.db.save_backtest_run(
              "BTCUSDT",
              "1m",
              "empty_strategy",
              &results,
          ).expect("Failed to save empty backtest");
          
          assert!(run_id > 0);
          
          let frame_count = env.db.count_frames(run_id)
              .expect("Failed to count frames");
          assert_eq!(frame_count, 0);
          
          let loaded = env.db.load_backtest_run(run_id)
              .expect("Failed to load empty run");
          assert_eq!(loaded.frames.len(), 0);
      }
      
      #[test]
      fn test_data_integrity_with_special_values() {
          let env = BacktestTestEnv::new().expect("Failed to create test environment");
          
          let mut results = create_test_results(1, 10000.0);
          results.frames[0].equity = 0.0;
          results.frames[0].balance = 0.0;
          results.frames[0].unrealized_pnl = -10000.0;
          results.frames[0].drawdown = 100.0;
          
          let run_id = env.db.save_backtest_run(
              "BTCUSDT",
              "1m",
              "edge_case_strategy",
              &results,
          ).expect("Failed to save backtest with edge values");
          
          let loaded = env.db.load_backtest_run(run_id)
              .expect("Failed to load backtest");
          
          assert_eq!(loaded.frames[0].equity, 0.0);
          assert_eq!(loaded.frames[0].balance, 0.0);
          assert_eq!(loaded.frames[0].unrealized_pnl, -10000.0);
          assert_eq!(loaded.frames[0].drawdown, 100.0);
      }
      
      #[test]
      fn test_load_nonexistent_run() {
          let env = BacktestTestEnv::new().expect("Failed to create test environment");
          
          let result = env.db.load_backtest_run(99999);
          assert!(result.is_err(), "Loading non-existent run should fail");
      }
      
      #[test]
      fn test_list_runs_ordering() {
          let env = BacktestTestEnv::new().expect("Failed to create test environment");
          let results = create_test_results(10, 10000.0);
          
          let mut run_ids = vec![];
          for i in 0..3 {
              let run_id = env.db.save_backtest_run(
                  "BTCUSDT",
                  "1m",
                  &format!("strategy_{}", i),
                  &results,
              ).expect("Failed to save run");
              run_ids.push(run_id);
              std::thread::sleep(std::time::Duration::from_millis(10));
          }
          
          let listed_runs = env.db.list_backtest_runs(None, 100, 0)
              .expect("Failed to list runs");
          
          assert_eq!(listed_runs.len(), 3);
          
          assert_eq!(listed_runs[0].id, run_ids[2]);
          assert_eq!(listed_runs[1].id, run_ids[1]);
          assert_eq!(listed_runs[2].id, run_ids[0]);
      }
  
  coverage:
    - "save_backtest_run: Basic insert with metadata and frames"
    - "save_backtest_run: Transaction atomicity (all or nothing)"
    - "save_backtest_run: Batch insert performance (>1000 frames/sec for 10K frames)"
    - "save_backtest_run: Concurrent saves don't corrupt data"
    - "save_backtest_run: Handle empty results (0 frames)"
    - "save_backtest_run: Handle edge case values (0 equity, negative PnL, 100% drawdown)"
    - "load_backtest_run: Correctly reconstruct frames from database"
    - "load_backtest_run: Preserve frame ordering (timestamp ASC)"
    - "load_backtest_run: Reconstruct position state correctly"
    - "load_backtest_run: Metrics match original values"
    - "load_backtest_run: Fail gracefully for non-existent run"
    - "list_backtest_runs: Pagination with limit and offset"
    - "list_backtest_runs: Ticker filtering"
    - "list_backtest_runs: Ordered by created_at DESC (newest first)"
    - "list_backtest_runs: Return all runs when no filter applied"
    - "delete_backtest_run: Delete run metadata"
    - "delete_backtest_run: Cascade delete to frames table"
    - "delete_backtest_run: Verify frames are removed"
    - "Round-trip integrity: save->load preserves all data"
    - "Concurrency: Multiple threads can save simultaneously without corruption"
    - "Performance: Large dataset handling (10,000+ frames)"
    - "Data integrity: Frame count matches after save/load"
    - "Edge cases: Zero frames, special float values"
    - "Foreign key constraints: CASCADE DELETE enforced"
    - "Index usage: Queries on run_id and timestamp are efficient"

dependencies:
  depends_on:
    - task_id: 1
      reason: "CRUD operations need database tables to exist"
    - task_id: 3
      reason: "Serialization must be implemented before database storage"

  depended_upon_by:
    - task_id: 4
      reason: "Auto-save feature needs CRUD operations to persist results"
    - task_id: 5
      reason: "Load results UI depends on list and load functions"

  external:
    - name: "DatabaseManager"
      type: "struct"
      status: "already exists"
    - name: "BacktestResults"
      type: "struct"
      status: "already exists"
    - name: "BacktestFrame"
      type: "struct"
      status: "already exists"
    - name: "Metrics"
      type: "struct"
      status: "already exists"
    - name: "Position"
      type: "struct"
      status: "already exists"
    - name: "PositionSide"
      type: "enum"
      status: "already exists"
    - name: "DatabaseError"
      type: "enum"
      status: "already exists"
    - name: "Result"
      type: "type"
      status: "already exists"
    - name: "duckdb"
      type: "crate"
      status: "already exists"
    - name: "serde_json"
      type: "crate"
      status: "to be imported"
---
I'll coordinate with all specialized agents in parallel to expand Task 1 into a complete specification.
---
I'll coordinate with all specialized agents in parallel to expand Task 4 into a complete specification.API Error: terminated