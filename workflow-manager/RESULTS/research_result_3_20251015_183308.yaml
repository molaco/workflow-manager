workflow_manager_api_analysis:
  
  # ============================================================================
  # CORE API OPERATIONS
  # ============================================================================
  
  operations:
    
    # ------------------------------------------------------------------------
    # 1. WORKFLOW DISCOVERY & METADATA
    # ------------------------------------------------------------------------
    
    list_workflows:
      description: "List all available workflows with metadata and field schemas"
      method: synchronous
      current_implementation: "runtime.rs:82-92 (WorkflowRuntime::list_workflows)"
      returns: "Vec<FullWorkflowMetadata>"
      use_cases:
        tui: "App initialization, workflow catalog view (main.rs:28-37)"
        mcp: "list_workflows tool (mcp_tools.rs:19-39)"
      data_needed:
        - workflow_id
        - workflow_name
        - description
        - field_schemas (name, type, label, required, default, cli_arg)
      performance: "Fast - reads from in-memory cache"
      notes: "Discovery happens once at startup via discover_workflows() in discovery.rs"
    
    get_workflow_metadata:
      description: "Get detailed metadata for a specific workflow by ID"
      method: synchronous
      current_implementation: "runtime.rs:94-103"
      returns: "FullWorkflowMetadata"
      use_cases:
        tui: "When viewing/editing workflow details (workflow_ops.rs:14-44)"
        mcp: "Could be exposed as separate tool, currently folded into list_workflows"
      data_needed:
        - all metadata from list_workflows for single workflow
      performance: "Fast - lookup in HashMap"
    
    # ------------------------------------------------------------------------
    # 2. WORKFLOW VALIDATION
    # ------------------------------------------------------------------------
    
    validate_workflow_inputs:
      description: "Validate field values against workflow schema before execution"
      method: synchronous
      current_implementation: "runtime.rs:105-123"
      returns: "WorkflowResult<()>"
      use_cases:
        tui: "Could be used before launching (currently validation is implicit)"
        mcp: "Called before execute_workflow (runtime.rs:131)"
      validation_rules:
        - required_field_check: "Ensure all required fields are present"
        - type_validation: "Could validate field types (Text, Number, FilePath, etc)"
        - range_validation: "For Number fields with min/max"
        - file_existence: "For FilePath fields"
      performance: "Fast - simple HashMap lookups and type checks"
      notes: "Current implementation only checks required fields"
    
    # ------------------------------------------------------------------------
    # 3. WORKFLOW EXECUTION
    # ------------------------------------------------------------------------
    
    execute_workflow:
      description: "Start workflow execution with provided parameters"
      method: asynchronous
      current_implementation: "runtime.rs:125-178"
      returns: "WorkflowHandle (contains UUID and workflow_id)"
      use_cases:
        tui: 
          - "launch_workflow (workflow_ops.rs:99-235)"
          - "launch_workflow_in_tab (workflow_ops.rs:238-470)"
        mcp: "execute_workflow tool (mcp_tools.rs:42-86)"
      execution_flow:
        - validate_inputs: "Check all required fields are present"
        - build_command: "Convert field values to CLI arguments"
        - spawn_process: "Launch workflow binary with stdout/stderr piped"
        - create_handle: "Generate UUID for tracking this execution"
        - store_state: "Save ExecutionState in HashMap"
        - spawn_log_parser: "Async task to parse __WF_EVENT__: messages from stderr"
        - return_handle: "Return UUID for status/log queries"
      data_needed:
        input:
          - workflow_id
          - parameters: "HashMap<String, String> (field_name -> value)"
        output:
          - execution_handle_id: "UUID for tracking"
          - workflow_id: "Reference to workflow definition"
          - initial_status: "WorkflowStatus::Running"
      performance: "Fast to start, long-running execution"
      async_requirements:
        - process_spawning: "tokio::process"
        - log_streaming: "background task parsing stderr"
        - broadcast_channel: "tokio::sync::broadcast for log distribution"
    
    # ------------------------------------------------------------------------
    # 4. WORKFLOW STATUS TRACKING
    # ------------------------------------------------------------------------
    
    get_status:
      description: "Get current execution status (Running, Completed, Failed)"
      method: asynchronous
      current_implementation: "runtime.rs:191-197"
      returns: "WorkflowStatus"
      use_cases:
        tui: "Polling in poll_all_tabs (tabs.rs:273-335)"
        mcp: "get_workflow_status tool (mcp_tools.rs:138-175)"
      status_transitions:
        NotStarted: "Initial state (not used in runtime)"
        Running: "Process spawned and active"
        Completed: "Process exited with success (exit code 0)"
        Failed: "Process exited with error or killed"
      update_mechanism:
        tui: "Synchronous polling via child.try_wait() every 50ms"
        mcp: "Async status stored in ExecutionState, updated by parser task"
      performance: "Fast - HashMap lookup"
    
    # ------------------------------------------------------------------------
    # 5. WORKFLOW LOG STREAMING
    # ------------------------------------------------------------------------
    
    subscribe_logs:
      description: "Subscribe to structured log events from running workflow"
      method: asynchronous_streaming
      current_implementation: "runtime.rs:180-189"
      returns: "broadcast::Receiver<WorkflowLog>"
      use_cases:
        tui: 
          - "Thread-based parsing in launch_workflow_in_tab (workflow_ops.rs:422-444)"
          - "Updates workflow_phases Arc<Mutex<Vec<WorkflowPhase>>>"
        mcp: "get_workflow_logs tool (mcp_tools.rs:89-135)"
      log_event_types:
        phase_events:
          - PhaseStarted: "{phase, name, total_phases}"
          - PhaseCompleted: "{phase, name}"
          - PhaseFailed: "{phase, name, error}"
        task_events:
          - TaskStarted: "{phase, task_id, description, total_tasks}"
          - TaskProgress: "{task_id, message}"
          - TaskCompleted: "{task_id, result}"
          - TaskFailed: "{task_id, error}"
        agent_events:
          - AgentStarted: "{task_id, agent_name, description}"
          - AgentMessage: "{task_id, agent_name, message}"
          - AgentCompleted: "{task_id, agent_name, result}"
          - AgentFailed: "{task_id, agent_name, error}"
        file_events:
          - StateFileCreated: "{phase, file_path, description}"
      streaming_protocol:
        format: "__WF_EVENT__:<JSON>"
        transport: "stderr from workflow process"
        parsing: "Line-by-line, strip prefix, deserialize JSON"
        distribution: "tokio::sync::broadcast channel (capacity 100)"
      performance: "Streaming - events emitted in real-time"
      data_structure:
        tui: "Builds hierarchical WorkflowPhase tree via handle_workflow_event"
        mcp: "Returns array of raw WorkflowLog events"
    
    # ------------------------------------------------------------------------
    # 6. WORKFLOW CANCELLATION
    # ------------------------------------------------------------------------
    
    cancel_workflow:
      description: "Kill running workflow process"
      method: asynchronous
      current_implementation: "runtime.rs:199-211"
      returns: "WorkflowResult<()>"
      use_cases:
        tui: "kill_current_tab (tabs.rs:72-87)"
        mcp: "cancel_workflow tool (mcp_tools.rs:178-215)"
      cancellation_flow:
        - lookup_execution: "Find ExecutionState by UUID"
        - kill_process: "child.kill()"
        - update_status: "Set status to Failed"
        - cleanup: "Process resources released, state remains for queries"
      performance: "Fast - sends SIGKILL"
      notes: "Graceful shutdown not implemented (no SIGTERM)"
  
  # ============================================================================
  # TUI-SPECIFIC OPERATIONS (Not in Runtime Trait)
  # ============================================================================
  
  tui_operations:
    
    workflow_discovery:
      description: "Scan filesystem for workflow binaries and extract metadata"
      implementation: "discovery.rs:15-78"
      method: synchronous
      execution_timing: "Once at TUI startup (main.rs:37)"
      search_paths:
        - "Same directory as TUI binary (target/debug or target/release)"
        - "~/.workflow-manager/workflows/"
      discovery_process:
        - scan_directories: "Find executable files"
        - filter_binaries: "Skip non-executables, build artifacts, workflow-manager itself"
        - extract_metadata: "Run each binary with --workflow-metadata flag"
        - parse_json: "Deserialize FullWorkflowMetadata from stdout"
        - build_catalog: "Create Workflow objects with source (BuiltIn/UserDefined)"
      performance: "Slow - executes N binaries at startup"
      caching: "In-memory only, lost on restart"
    
    refresh_workflows:
      description: "Re-run workflow discovery to pick up new workflows"
      implementation: "runtime.rs:49-58"
      method: synchronous
      use_cases: "Not exposed in TUI yet, but available"
      notes: "Could be triggered by file watcher or manual refresh"
    
    field_history:
      description: "Track previously used values for workflow fields"
      implementation: "app/history.rs (referenced in tabs.rs:298-316)"
      storage: "~/.workflow-manager/history.yaml"
      structure: "HashMap<workflow_id, HashMap<field_name, Vec<String>>>"
      use_cases:
        - auto_populate: "Load last-used values when editing workflow"
        - tab_completion: "Show history dropdown for Text fields"
      max_entries: "10 per field"
      update_trigger: "On successful workflow completion (tabs.rs:298-316)"
    
    session_persistence:
      description: "Save/restore open tabs and their state across TUI restarts"
      implementation: "Referenced in main.rs:394 (save_session)"
      data_saved:
        - open_tabs: "Which workflows are running/completed"
        - field_values: "Input parameters for each tab"
        - saved_logs: "Output from completed workflows"
        - ui_state: "Scroll positions, expanded items"
      notes: "Implementation not fully visible in provided code"
  
  # ============================================================================
  # DATA FLOW ANALYSIS
  # ============================================================================
  
  tui_workflow_interaction:
    
    startup_flow:
      - create_app: "App::new() in app/models/app.rs"
      - discover_workflows: "Load workflow catalog"
      - restore_session: "Reload previous tabs (if any)"
      - enter_event_loop: "run_app() polling at 50ms intervals"
    
    workflow_selection_flow:
      - user_navigates: "WorkflowList view, arrow keys change selected index"
      - user_views: "Press 'v' -> WorkflowDetail view shows metadata"
      - user_edits: "Press 'e' -> WorkflowEdit view shows fields"
      - field_editing: "Navigate fields, press Enter to edit, type value, Enter to save"
      - load_history: "Auto-populate last-used values from WorkflowHistory"
    
    workflow_launch_flow:
      - user_launches: "Press 'l' from WorkflowEdit view"
      - save_history: "Store field values for future auto-complete"
      - build_command: "Convert field values to CLI args"
      - build_binary: "Run 'cargo build --bin <workflow_id>' first"
      - spawn_process: "Command::new(binary).args().spawn()"
      - create_tab: "New WorkflowTab with unique id and instance number"
      - setup_io: "Capture stdout/stderr via pipes"
      - spawn_threads:
          - stdout_reader: "Push lines to workflow_output Arc<Mutex<Vec<String>>>"
          - stderr_parser: "Parse __WF_EVENT__: lines, call handle_workflow_event"
          - completion_watcher: "Wait for process exit, update status"
      - switch_view: "View::Tabs to show running workflow"
    
    workflow_monitoring_flow:
      - poll_all_tabs: "Called every 50ms in event loop"
      - check_status: "child.try_wait() for each running tab"
      - update_ui: "Phases updated by stderr parser thread"
      - user_navigation: "j/k to navigate hierarchy, Enter to expand/collapse"
      - agent_message_scroll: "h/l or PageUp/PageDown for long agent outputs"
    
    workflow_completion_flow:
      - process_exits: "try_wait() returns Some(status)"
      - update_status: "WorkflowStatus::Completed or Failed"
      - save_to_history: "If successful, save field values"
      - show_message: "Append success/failure message to output"
      - tab_persists: "Tab remains open for log review"
    
    hierarchical_data_structure:
      description: "TUI builds Phase->Task->Agent tree from WorkflowLog events"
      implementation: "handle_workflow_event in workflow_ops.rs:472-637"
      structure:
        WorkflowPhase:
          - id: usize
          - name: String
          - status: PhaseStatus
          - tasks: Vec<WorkflowTask>
          - output_files: Vec<(path, description)>
        WorkflowTask:
          - id: String
          - phase: usize
          - description: String
          - status: TaskStatus
          - agents: Vec<WorkflowAgent>
          - messages: Vec<String>
          - result: Option<String>
        WorkflowAgent:
          - id: String (task_id:agent_name)
          - task_id: String
          - name: String
          - description: String
          - status: AgentStatus
          - messages: Vec<String>
          - result: Option<String>
      update_logic:
        - event_driven: "Each WorkflowLog event updates corresponding node"
        - auto_create: "Phases/tasks/agents created on-demand if missing"
        - incremental: "Messages appended to existing nodes"
      ui_state:
        - expanded_phases: HashSet<phase_id>
        - expanded_tasks: HashSet<task_id>
        - expanded_agents: HashSet<agent_id>
        - selected_item: "Navigation tracks current phase/task/agent"
        - scroll_offset: "For viewport positioning"
  
  # ============================================================================
  # SYNCHRONOUS VS ASYNCHRONOUS OPERATIONS
  # ============================================================================
  
  operation_categorization:
    
    synchronous_operations:
      - list_workflows: "In-memory HashMap read"
      - get_workflow_metadata: "In-memory HashMap lookup"
      - validate_workflow_inputs: "Schema validation, no IO"
      - refresh_workflows: "File scan + process execution (slow but sync)"
      description: "All read-only metadata operations are synchronous"
      rationale: "Data is cached in memory after initial discovery"
    
    asynchronous_operations:
      - execute_workflow: "Spawns process and background tasks"
      - subscribe_logs: "Returns streaming receiver"
      - get_status: "Async trait but fast lookup"
      - cancel_workflow: "Process kill, async trait"
      description: "All execution-related operations are async"
      rationale: "Workflows are long-running, need non-blocking execution"
    
    streaming_operations:
      - subscribe_logs: "Real-time event stream via broadcast channel"
      - agent_messages: "Continuous updates as agents think/respond"
      description: "WorkflowLog events are streamed, not batched"
      implementation: "tokio::sync::broadcast with 100-message buffer"
      backpressure: "Slow consumers miss old messages (lagging receivers)"
  
  # ============================================================================
  # API DESIGN RECOMMENDATIONS
  # ============================================================================
  
  recommended_api_surface:
    
    core_operations:
      - list_workflows: "GET /workflows -> Vec<FullWorkflowMetadata>"
      - get_workflow: "GET /workflows/{id} -> FullWorkflowMetadata"
      - validate_inputs: "POST /workflows/{id}/validate {params} -> ValidationResult"
      - execute_workflow: "POST /workflows/{id}/execute {params} -> WorkflowHandle"
      - get_status: "GET /executions/{handle_id}/status -> WorkflowStatus"
      - get_logs: "GET /executions/{handle_id}/logs?limit=N -> Vec<WorkflowLog>"
      - stream_logs: "WS /executions/{handle_id}/logs -> stream<WorkflowLog>"
      - cancel_workflow: "DELETE /executions/{handle_id} -> ()"
    
    auxiliary_operations:
      - refresh_catalog: "POST /workflows/refresh -> ()"
      - get_field_history: "GET /workflows/{id}/history/{field} -> Vec<String>"
      - get_recent_executions: "GET /executions?workflow_id={id}&limit=N"
      - get_execution_details: "GET /executions/{handle_id} -> ExecutionInfo"
    
    batch_operations:
      - execute_multiple: "POST /workflows/batch {requests} -> Vec<WorkflowHandle>"
      - cancel_multiple: "DELETE /executions/batch {handle_ids} -> BatchResult"
    
    webhook_support:
      - register_webhook: "POST /webhooks {url, events} -> webhook_id"
      - on_completion: "Notify external system when workflow completes"
      - on_failure: "Notify on workflow failures"
  
  # ============================================================================
  # KEY ARCHITECTURAL INSIGHTS
  # ============================================================================
  
  insights:
    
    runtime_trait_is_universal_api:
      observation: "WorkflowRuntime trait is already a complete API contract"
      location: "workflow-manager-sdk/src/lib.rs:398-431"
      completeness: "Covers all CRUD operations needed for both TUI and MCP"
      missing_features:
        - list_executions: "Query all running/completed workflows"
        - execution_history: "Get past executions for a workflow"
        - log_replay: "Get full log history for completed workflow"
    
    tui_uses_direct_process_spawning:
      observation: "TUI bypasses WorkflowRuntime for tab execution"
      location: "workflow_ops.rs:238-470 (launch_workflow_in_tab)"
      reason: "Needs direct Child handle for process management"
      tradeoff: "Duplicated logic between TUI and ProcessBasedRuntime"
      recommendation: "Refactor TUI to use WorkflowRuntime.execute_workflow()"
    
    mcp_has_minimal_surface:
      observation: "MCP exposes only 5 tools, maps 1:1 to WorkflowRuntime methods"
      location: "mcp_tools.rs:7-215"
      tools:
        - list_workflows
        - execute_workflow
        - get_workflow_logs
        - get_workflow_status
        - cancel_workflow
      limitations:
        - get_workflow_logs: "Uses try_recv() - not true streaming"
        - no_validation_tool: "Validation only happens inside execute"
        - no_refresh: "Can't discover new workflows without restart"
    
    hierarchical_state_building:
      observation: "TUI builds rich Phase->Task->Agent tree from flat events"
      location: "workflow_ops.rs:472-637 (handle_workflow_event)"
      complexity: "200+ lines of state management logic"
      data_structures: "WorkflowPhase, WorkflowTask, WorkflowAgent"
      use_case: "Enables collapsible tree UI with detailed status"
      api_consideration: "API could expose this tree structure directly"
    
    log_streaming_is_broadcast:
      observation: "Uses tokio::sync::broadcast for 1-to-N log distribution"
      capacity: "100 messages, old messages dropped if consumer lags"
      implications:
        - multiple_consumers: "Multiple MCP clients can subscribe to same execution"
        - message_loss: "Slow consumers miss messages (not persisted)"
        - no_history: "Can't get logs from before subscription"
      recommendation: "Add log persistence for completed workflows"
    
    validation_is_minimal:
      observation: "Only checks required fields, no type validation"
      location: "runtime.rs:105-123"
      missing_validation:
        - type_checking: "Number fields could receive text"
        - range_validation: "min/max not enforced"
        - file_existence: "FilePath fields not verified"
        - enum_validation: "Select fields not validated against options"
      recommendation: "Enhance validate_workflow_inputs with comprehensive checks"
    
    chat_interface_uses_mcp_internally:
      observation: "ChatInterface creates MCP server, exposes tools to Claude"
      location: "chat.rs:70-110"
      architecture: "SDK MCP server registered in ClaudeAgentOptions"
      tools_exposed: "Same 5 tools as external MCP"
      implication: "Chat and external MCP have identical capabilities"

# ============================================================================
# SUMMARY
# ============================================================================

summary:
  essential_operations:
    - list_workflows: "Synchronous, fast, in-memory"
    - get_workflow_metadata: "Synchronous, fast, lookup by ID"
    - validate_workflow_inputs: "Synchronous, schema validation"
    - execute_workflow: "Async, returns handle immediately"
    - subscribe_logs: "Async streaming, real-time events"
    - get_status: "Async, fast status check"
    - cancel_workflow: "Async, process kill"
  
  current_state:
    - runtime_trait: "Complete API contract in workflow-manager-sdk"
    - process_runtime: "Full implementation in runtime.rs"
    - mcp_server: "5 tools exposing core operations"
    - tui: "Bypasses runtime for some operations, has direct process management"
  
  gaps_to_fill:
    - execution_listing: "No way to query all executions"
    - log_persistence: "Logs lost after process completion"
    - enhanced_validation: "Type/range/enum validation missing"
    - graceful_shutdown: "Only supports SIGKILL, no SIGTERM"
    - workflow_refresh: "Not exposed in MCP or TUI"
  
  next_steps:
    - unify_tui_with_runtime: "TUI should use WorkflowRuntime.execute_workflow"
    - add_execution_queries: "list_executions, get_execution_details"
    - persist_logs: "Store WorkflowLog events for historical access"
    - expose_hierarchy: "API method to get Phase->Task->Agent tree"
    - add_webhooks: "Notification system for workflow events"