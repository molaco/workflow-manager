workflow_execution_analysis:
  title: "Workflow Execution Architecture Analysis"
  timestamp: "2025-10-14"
  
  execution_patterns:
    primary_mode: "process-based"
    description: "Workflows are compiled as standalone binaries and executed as separate OS processes"
    
    process_execution:
      mechanism: "std::process::Command"
      locations:
        - "src/main.rs:502-563 (rerun_current_tab)"
        - "src/main.rs:1019-1099 (launch_workflow - deprecated)"
        - "src/main.rs:1174-1247 (launch_workflow_in_tab)"
      
      spawn_pattern:
        type: "std::process::Command::new(binary_path)"
        stdio_configuration:
          stdin: "null()"
          stdout: "piped()"
          stderr: "piped()"
        
        binary_discovery:
          method: "Hardcoded path: ../target/debug/{workflow_id}"
          metadata_extraction: "src/discovery.rs:118-147"
          metadata_flag: "--workflow-metadata"
          metadata_format: "JSON via stdout"
        
        argument_building:
          description: "CLI args constructed from field values"
          location: "src/main.rs:468-486, 979-1002, 1127-1145"
          pattern: "Field name → --field-name, boolean flags, quoted values"

    in_process_execution:
      status: "NOT_SUPPORTED"
      current_implementation: "None - all workflows run as external processes"
      potential_use_case: "Library-based execution for embedded workflows"
      
    hybrid_architecture:
      claude_sdk_usage:
        description: "Workflows use claude-agent-sdk as in-process library"
        examples:
          - "src/bin/simple_query.rs:86 (query function)"
          - "src/bin/hooks_demo.rs:191-239 (ClaudeSDKClient)"
          - "src/bin/research_agent.rs:529, 660, 769 (query calls)"
        pattern: "Process spawns → Workflow binary → In-process claude SDK calls"

  state_management:
    hierarchical_structure:
      levels:
        - phase: "WorkflowPhase (id, name, status, tasks, output_files)"
        - task: "WorkflowTask (id, phase, description, status, agents, messages)"
        - agent: "WorkflowAgent (id, task_id, name, description, status, messages, result)"
      location: "src/main.rs:31-85"
    
    per_tab_state:
      container: "WorkflowTab struct"
      location: "src/main.rs:88-119"
      fields:
        identity:
          - "id: unique identifier"
          - "workflow_idx: catalog index"
          - "workflow_name: display name"
          - "instance_number: #1, #2, #3"
          - "start_time: chrono::DateTime"
        
        execution:
          - "status: WorkflowStatus (NotStarted|Running|Completed|Failed)"
          - "child_process: Option<std::process::Child>"
          - "exit_code: Option<i32>"
        
        data:
          - "workflow_phases: Arc<Mutex<Vec<WorkflowPhase>>>"
          - "workflow_output: Arc<Mutex<Vec<String>>>"
          - "field_values: HashMap<String, String>"
        
        ui_state:
          - "scroll_offset: usize"
          - "expanded_phases/tasks/agents: HashSet"
          - "selected_phase/task/agent: navigation state"
          - "agent_scroll_offsets: HashMap<String, usize>"
    
    session_persistence:
      save_location: "~/.workflow-manager/session.json"
      implementation: "src/main.rs:229-263 (save_session)"
      restoration: "src/main.rs:265-328 (restore_session)"
      saved_data: "field_values, status, output logs (not live process)"

  log_capture_protocol:
    structured_events:
      format: "__WF_EVENT__:<json>"
      transport: "stderr stream"
      parser: "src/main.rs:538, 1053, 1211 (strip_prefix + serde_json)"
      
      event_types:
        sdk_location: "../workflow-manager-sdk/src/lib.rs:119-191"
        variants:
          - "PhaseStarted/Completed/Failed"
          - "TaskStarted/Progress/Completed/Failed"
          - "AgentStarted/Message/Completed/Failed"
          - "StateFileCreated"
      
      emission:
        method: "WorkflowLog::emit()"
        implementation: "workflow-manager-sdk/src/lib.rs:195-202"
        mechanism: "eprintln! + stderr.flush()"
        
      helper_macros:
        location: "workflow-manager-sdk/src/lib.rs:206-369"
        examples:
          - "log_phase_start!(phase, name, total)"
          - "log_task_start!(phase, task_id, description)"
          - "log_agent_message!(task_id, agent, message)"
    
    output_capture:
      stdout_handling:
        description: "Regular workflow output (println!)"
        capture: "Spawned thread reads BufReader<stdout>"
        location: "src/main.rs:514-526, 1030-1041, 1186-1198"
        storage: "Arc<Mutex<Vec<String>>> pushed to output"
      
      stderr_handling:
        description: "Dual-purpose: structured logs + error messages"
        capture: "Spawned thread reads BufReader<stderr>"
        location: "src/main.rs:529-549, 1044-1066, 1201-1223"
        parsing:
          structured: "Lines prefixed with __WF_EVENT__: → parsed as JSON"
          unstructured: "Other lines → pushed to output as 'ERROR: {line}'"
      
      threading_model:
        pattern: "std::thread::spawn for each stream (stdout, stderr)"
        lifecycle: "Detached threads read until EOF"
        synchronization: "Arc<Mutex<>> for shared state"

  process_lifecycle:
    spawning:
      trigger_points:
        - "launch_workflow_in_tab (new tab)"
        - "rerun_current_tab (restart)"
        - "launch_workflow (deprecated single view)"
      error_handling: "Captures spawn errors and displays in tab output"
    
    monitoring:
      method: "Child::try_wait() polling"
      location: "src/main.rs:812-873 (poll_all_tabs)"
      frequency: "Called on each UI event loop iteration"
      status_tracking: "Updates tab.status and tab.exit_code"
      
      completion_actions:
        on_success: "Set Completed, save to history"
        on_failure: "Set Failed, record exit code"
    
    termination:
      user_initiated:
        kill_action: "src/main.rs:426-441 (kill_current_tab)"
        close_action: "src/main.rs:384-424 (close_current_tab + confirmation)"
        method: "child.kill()"
        
      automatic:
        process_exit: "Detected via try_wait(), threads read to EOF and exit"
      
      cleanup:
        process_handle: "Dropped from tab.child_process"
        threads: "Self-terminate when streams close"

  api_design_considerations:
    execution_modes:
      recommendation: "Support both process-based and library-based"
      
      process_based:
        use_cases:
          - "User-defined workflows (compiled binaries)"
          - "Sandboxed execution"
          - "Resource isolation"
          - "Long-running workflows"
        
        api_surface:
          spawn:
            method: "WorkflowExecutor::spawn_process(binary_path, args)"
            returns: "WorkflowHandle<ProcessBackend>"
          
          communicate:
            stdout: "handle.stdout_stream() -> impl Stream<Item=String>"
            stderr: "handle.stderr_stream() -> impl Stream<Item=WorkflowLog>"
            events: "handle.event_stream() -> impl Stream<Item=WorkflowLog>"
          
          control:
            wait: "handle.wait() -> Result<ExitStatus>"
            kill: "handle.kill() -> Result<()>"
            poll: "handle.try_wait() -> Result<Option<ExitStatus>>"
      
      library_based:
        use_cases:
          - "Built-in workflows"
          - "Direct SDK integration"
          - "Faster startup"
          - "Shared memory state"
        
        api_surface:
          spawn:
            method: "WorkflowExecutor::spawn_library<T: Workflow>(config)"
            returns: "WorkflowHandle<LibraryBackend>"
          
          communicate:
            events: "handle.event_stream() -> impl Stream<Item=WorkflowLog>"
            output: "handle.output_stream() -> impl Stream<Item=String>"
          
          control:
            cancel: "handle.cancel() -> Result<()>"
            await: "handle.await -> Result<WorkflowResult>"
    
    sandboxing_and_limits:
      current_state: "NONE - no sandboxing or resource limits implemented"
      
      recommendations:
        filesystem_isolation:
          approach: "OS-level: chroot, containers, or working directory jail"
          library: "Consider: nix crate, firejail wrapper, docker containers"
          
        resource_limits:
          cpu: "setrlimit(RLIMIT_CPU) on Unix, JobObjects on Windows"
          memory: "setrlimit(RLIMIT_AS) on Unix, JobObjects on Windows"
          time: "tokio::time::timeout for library-based, process groups for process-based"
          
        network_isolation:
          approach: "Network namespaces (Linux), firewall rules, or deny by default"
          
        api_design:
          example: |
            WorkflowExecutor::builder()
              .sandbox(Sandbox::chroot("/tmp/workflow-jail"))
              .resource_limit(ResourceLimit::Memory(512 * 1024 * 1024))
              .resource_limit(ResourceLimit::CpuTime(Duration::from_secs(300)))
              .timeout(Duration::from_secs(600))
              .spawn()
    
    cancellation:
      process_based:
        current: "child.kill() - immediate SIGKILL"
        recommended:
          graceful: "Send SIGTERM, wait timeout, then SIGKILL"
          api: |
            handle.shutdown_graceful(timeout) -> Result<()>
            handle.kill() -> Result<()>  // forceful
        
      library_based:
        approach: "CancellationToken pattern (tokio_util::sync::CancellationToken)"
        propagation: "Pass token to workflow, check at async points"
        api: |
          let token = CancellationToken::new();
          let handle = executor.spawn_library(workflow, token.clone())?;
          token.cancel();  // Signal cancellation
          handle.await?;   // Wait for graceful shutdown

  concurrent_execution:
    current_examples:
      research_agent:
        location: "src/bin/research_agent.rs"
        pattern: "FuturesUnordered + Semaphore"
        
        phase_2_research:
          description: "Execute N research prompts concurrently"
          location: "src/bin/research_agent.rs:1307-1369"
          implementation: |
            let sem = Arc::new(Semaphore::new(batch_size));
            let mut tasks = FuturesUnordered::new();
            for prompt in prompts {
                let permit = sem.acquire().await?;
                tasks.push(execute_research_prompt(prompt));
            }
            while let Some(result) = tasks.next().await { ... }
        
        phase_3_yaml_fixing:
          description: "Fix broken YAML files in parallel"
          location: "src/bin/research_agent.rs:1414-1443"
          concurrency_control: "Semaphore with batch_size limit"
        
        phase_4_reduce:
          description: "Parallel map-reduce for document synthesis"
          location: "src/bin/research_agent.rs:970-1055"
          pattern: "Tree reduction in parallel rounds"
    
    tabbed_interface:
      description: "Multiple workflows run concurrently in separate tabs"
      location: "src/main.rs:88-119 (WorkflowTab)"
      mechanism: "Each tab has independent child process + thread readers"
      polling: "poll_all_tabs() checks all tabs each event loop"
      isolation: "Processes don't share memory, communicate via files/state"

  recommendations_summary:
    api_architecture:
      - "Design WorkflowExecutor with Backend trait (Process|Library)"
      - "Unified WorkflowHandle<B: Backend> for both execution modes"
      - "Stream-based output for stdout/stderr/events"
      - "Support both blocking and async interfaces"
    
    execution_modes:
      - "Process-based: For user workflows, isolation, resource limits"
      - "Library-based: For built-in workflows, performance, embedding"
      - "Auto-detect: If workflow implements trait, use library; else spawn process"
    
    resource_management:
      - "Implement ResourceLimits builder pattern"
      - "Support timeout, memory limit, CPU limit, filesystem quota"
      - "Use OS facilities: rlimit (Unix), JobObjects (Windows)"
      - "Consider container integration (Docker, Podman) for full isolation"
    
    cancellation:
      - "Graceful shutdown: SIGTERM → wait → SIGKILL for processes"
      - "CancellationToken pattern for library-based workflows"
      - "Unified cancel() API across both backends"
      - "Cleanup hooks for resource release"
    
    state_protocol:
      - "Keep __WF_EVENT__ stderr protocol - works well"
      - "Consider adding binary protocol option (MessagePack/ProtoBuf) for performance"
      - "Support state snapshots for pause/resume"
      - "Event versioning for backward compatibility"
    
    concurrency:
      - "Support workflow-level parallelism (tabs, separate processes)"
      - "Support task-level parallelism (FuturesUnordered within workflow)"
      - "Consider work-stealing thread pool for library-based workflows"
      - "Add concurrency limits to prevent resource exhaustion"

  code_references:
    key_files:
      main_tui: "src/main.rs"
      workflow_sdk: "../workflow-manager-sdk/src/lib.rs"
      discovery: "src/discovery.rs"
      examples:
        - "src/bin/simple_echo.rs (basic process workflow)"
        - "src/bin/simple_query.rs (claude SDK integration)"
        - "src/bin/hooks_demo.rs (SDK with hooks)"
        - "src/bin/demo_multiphase.rs (hierarchical logging)"
        - "src/bin/research_agent.rs (concurrent execution)"
    
    critical_functions:
      process_spawn: "src/main.rs:502-563, 1174-1247"
      log_parsing: "src/main.rs:538-540, 1053-1056, 1211-1213"
      event_handling: "src/main.rs:1251-1407"
      state_management: "src/main.rs:88-119 (WorkflowTab struct)"
      lifecycle_polling: "src/main.rs:812-873"
      process_termination: "src/main.rs:426-441"
      session_persistence: "src/main.rs:229-328"
      
    sdk_macros:
      log_macros: "workflow-manager-sdk/src/lib.rs:206-369"
      workflow_events: "workflow-manager-sdk/src/lib.rs:119-191"