workflow_api_analysis:
  overview: |
    The workflow-manager system uses a hybrid architecture with:
    - TUI interface (main.rs) for interactive workflow management
    - Structured logging protocol for workflow execution tracking
    - Binary-based workflow discovery and execution model
    - State file persistence for resumable multi-phase workflows

  core_operations:
    workflow_discovery:
      operation: list_workflows
      purpose: Discover and enumerate available workflow binaries
      implementation: src/discovery.rs:15 (discover_workflows)
      mechanism: |
        - Scans search paths for executable binaries
        - Invokes each binary with --workflow-metadata flag
        - Parses JSON response to extract metadata
      data_model:
        - WorkflowMetadata (id, name, description)
        - FieldSchema[] (name, type, label, description, cli_arg, required, default)
      sync_type: synchronous
      use_cases:
        tui: Populates workflow catalog on startup (main.rs:178)
        mcp: LIST_TOOLS operation to expose available workflows

    workflow_metadata:
      operation: get_workflow_metadata
      purpose: Retrieve complete field schema and configuration for a workflow
      implementation: src/discovery.rs:118 (extract_workflow_metadata)
      mechanism: |
        - Execute: <binary> --workflow-metadata
        - Parse FullWorkflowMetadata from stdout JSON
      data_model:
        - FullWorkflowMetadata with nested FieldSchema[]
        - FieldType enum (Text, Number, FilePath, Select, PhaseSelector, StateFile)
      sync_type: synchronous
      use_cases:
        tui: Field validation and form rendering (main.rs:899-910)
        mcp: TOOL_SCHEMA introspection for dynamic tool generation

    workflow_validation:
      operation: validate_workflow_inputs
      purpose: Validate field values against schema constraints
      implementation: Implicit in TUI field value collection
      requirements:
        - Required field checking
        - Type validation (number ranges, file paths, phase selectors)
        - Phase-specific requirements (required_for_phases field attribute)
      sync_type: synchronous
      use_cases:
        tui: Pre-launch validation (main.rs:984-1007)
        mcp: CALL_TOOL parameter validation before execution

    workflow_execution:
      operation: start_workflow
      purpose: Launch workflow binary with validated parameters
      implementation: main.rs:502-563 (spawn workflow process)
      mechanism: |
        - Build CLI args from field_values HashMap
        - Spawn child process with piped stdout/stderr
        - Parse structured logs from stderr (__WF_EVENT__: prefix)
        - Stream stdout/stderr to output buffers
      data_model:
        input: field_values HashMap<String, String>
        output:
          - child_process handle
          - workflow_output Arc<Mutex<Vec<String>>>
          - workflow_phases Arc<Mutex<Vec<WorkflowPhase>>>
      sync_type: asynchronous_streaming
      use_cases:
        tui: Tab-based concurrent execution (main.rs:1108-1253)
        mcp: Async tool execution with progress streaming

    workflow_status:
      operation: get_workflow_status
      purpose: Query current execution state and progress
      implementation: main.rs:816-878 (poll_all_tabs)
      mechanism: |
        - Poll child.try_wait() for process status
        - Read WorkflowStatus enum (NotStarted, Running, Completed, Failed)
        - Access phase/task/agent hierarchy from workflow_phases
      data_model:
        - WorkflowStatus (top-level)
        - PhaseStatus[] (phase hierarchy)
        - TaskStatus[] (nested under phases)
        - AgentStatus[] (nested under tasks)
      sync_type: synchronous_polling
      use_cases:
        tui: Real-time UI updates (main.rs:816)
        mcp: Progress callbacks for long-running operations

    workflow_logs:
      operation: stream_workflow_logs
      purpose: Access real-time and historical execution logs
      implementation: |
        main.rs:529-549 (stderr parsing thread)
        workflow-manager-sdk/src/lib.rs:119-191 (WorkflowLog enum)
      mechanism: |
        - Structured events via stderr: __WF_EVENT__:<json>
        - Event types: PhaseStarted, TaskStarted, AgentStarted, AgentMessage, etc.
        - Parsed and stored in hierarchical phase/task/agent structure
      data_model: |
        WorkflowLog enum with variants:
          - PhaseStarted/Completed/Failed
          - TaskStarted/Progress/Completed/Failed
          - AgentStarted/Message/Completed/Failed
          - StateFileCreated (intermediate outputs)
      sync_type: streaming_async
      use_cases:
        tui: Live log display in expandable tree view (main.rs:566-813)
        mcp: Event stream for progress monitoring

    workflow_results:
      operation: get_workflow_results
      purpose: Access workflow outputs and generated artifacts
      implementation: |
        main.rs:84 output_files (per phase)
        workflow-manager-sdk/src/lib.rs:186-190 (StateFileCreated event)
      mechanism: |
        - Workflows emit StateFileCreated events with file_path and description
        - TUI tracks output_files per phase
        - Research agent example: saves YAML files to ./RESULTS/ directory
      data_model:
        - phase.output_files: Vec<(String, String)> (path, description)
        - exit_code: Option<i32>
        - final stdout/stderr buffers
      sync_type: synchronous
      use_cases:
        tui: Display output files in phase tree view (main.rs:84)
        mcp: Return tool execution results with artifact paths

    workflow_control:
      operation: stop_workflow
      purpose: Terminate running workflow process
      implementation: main.rs:426-441 (kill_current_tab)
      mechanism: |
        - child.kill() to terminate process
        - Update status to Failed
        - Append termination message to output
      sync_type: synchronous
      use_cases:
        tui: User-initiated cancellation (main.rs:426)
        mcp: CANCEL_TOOL operation for long-running workflows

    workflow_resume:
      operation: resume_workflow
      purpose: Resume workflow from saved state files
      implementation: research_agent.rs:224-1254 (phase resumption logic)
      mechanism: |
        - State files saved per phase with timestamp
        - CLI args: --analysis-file, --prompts-file, --results-file
        - Phase selector: --phases 0,1,2,3,4
        - Workflows skip completed phases and load state
      data_model:
        - StateFile fields (pattern, phase, required_for_phases)
        - Phase-specific state files (YAML format)
      sync_type: synchronous
      use_cases:
        tui: Field browser for state file selection (main.rs:148-161)
        mcp: Resumable long-running research workflows

    session_persistence:
      operation: save/restore_session
      purpose: Persist workflow state across TUI restarts
      implementation: main.rs:229-328 (save_session, restore_session)
      mechanism: |
        - Serialize open tabs to JSON (field_values, logs, status)
        - Store in ~/.local/share/workflow-manager/session.json
        - Restore tabs on startup
      sync_type: synchronous
      use_cases:
        tui: Seamless restart without losing context (main.rs:220)
        mcp: Not applicable (MCP is stateless per connection)

    history_tracking:
      operation: get/save_field_history
      purpose: Track and suggest previously used field values
      implementation: main.rs:2029-2046 (load/save_history)
      mechanism: |
        - Store per-workflow, per-field value history
        - Save successful execution parameters
        - Provide autocomplete suggestions
      data_model: HashMap<workflow_id, HashMap<field_name, Vec<String>>>
      sync_type: synchronous
      use_cases:
        tui: Dropdown suggestions for field inputs (main.rs:150-161)
        mcp: Could provide parameter suggestions via tool descriptions

  synchronous_vs_async_operations:
    synchronous:
      - list_workflows: Fast, local binary scanning
      - get_workflow_metadata: Single binary execution (~100ms)
      - validate_workflow_inputs: Local validation logic
      - get_workflow_status: Read from shared state (no I/O)
      - get_workflow_results: File path retrieval
      - stop_workflow: Process kill signal
      - save/restore_session: Local file I/O

    async_streaming:
      - start_workflow: Long-running process with live output
      - stream_workflow_logs: Real-time event parsing from stderr
      - phase_progress_updates: Hierarchical status changes

    polling_recommended:
      - workflow_status: TUI polls every render cycle
      - log_updates: Thread-safe Arc<Mutex<>> buffers

  tui_workflow_interaction_patterns:
    startup_sequence:
      - main.rs:178: Load workflows via discovery
      - main.rs:220: Restore previous session tabs
      - main.rs:223: Initialize in Tabs view

    workflow_selection:
      - View::WorkflowList: Browse available workflows
      - View::WorkflowDetail: View metadata and fields
      - View::WorkflowEdit: Fill in field values
      - main.rs:899-910: Load defaults and history

    workflow_launch:
      - main.rs:1108-1253: launch_workflow_in_tab()
      - Creates WorkflowTab with unique instance_number
      - Spawns process with stdout/stderr capture threads
      - Switches to View::Tabs for monitoring

    concurrent_execution:
      - Multiple tabs can run simultaneously
      - Each tab has independent:
        - child_process handle
        - workflow_phases state
        - workflow_output buffer
        - UI state (expanded_phases, scroll_offset)

    real_time_monitoring:
      - main.rs:1255-1400: handle_workflow_event()
      - Parses WorkflowLog events into phase hierarchy
      - Updates PhaseStatus/TaskStatus/AgentStatus
      - Streams AgentMessage events for LLM output

    hierarchical_display:
      - Phase level: Expandable with status icons
      - Task level: Nested under phases with descriptions
      - Agent level: Sub-agents with streaming messages
      - main.rs:566-813: Navigation and expansion logic

    output_access:
      - State files tracked per phase (output_files)
      - Full stdout/stderr in workflow_output buffer
      - Scroll through agent messages (main.rs:775-813)

  mcp_server_requirements:
    tool_registration:
      purpose: Expose each workflow as an MCP tool
      implementation_approach: |
        - Call list_workflows() on MCP server init
        - Generate tool schema from FieldSchema[]
        - Map FieldType to JSON Schema types
      example: |
        workflow "research_agent" becomes:
        Tool: research_agent
        Input Schema:
          - input: string (required for phase 1)
          - system_prompt: string (file_path)
          - batch_size: number (min: 1, max: 10)
          - phases: string (phase_selector)

    tool_invocation:
      purpose: Execute workflow with MCP CALL_TOOL
      implementation_approach: |
        - Validate input parameters against schema
        - Call start_workflow() with field_values
        - Return execution handle/ID
      async_handling: |
        - Return immediately with workflow_id
        - Provide separate status query endpoint
        - Stream logs via MCP progress notifications

    progress_streaming:
      purpose: Report long-running workflow progress
      implementation_approach: |
        - Parse WorkflowLog events from stderr
        - Convert to MCP progress notifications
        - Send phase/task/agent hierarchy updates
      event_mapping: |
        PhaseStarted → progress(0.0, "Phase 1: Generate Prompts")
        TaskStarted → progress(0.25, "Task: Summarizing result 1")
        AgentMessage → progress(0.25, "Agent: Analyzing codebase...")
        PhaseCompleted → progress(0.5, "Phase 1 complete")

    result_return:
      purpose: Return workflow outputs to MCP client
      implementation_approach: |
        - Wait for WorkflowStatus::Completed or Failed
        - Collect output_files from all phases
        - Return JSON with:
          - status: "completed" | "failed"
          - exit_code: number
          - output_files: Array<{path, description, phase}>
          - logs: Optional full log buffer

    long_running_patterns:
      research_agent_example: |
        - Phase 0: Analyze codebase (30-60s)
        - Phase 1: Generate prompts (10-20s)
        - Phase 2: Execute research (5-10 min, parallel agents)
        - Phase 3: Validate YAML (2-5 min, iterative fixing)
        - Phase 4: Synthesize docs (2-3 min, map-reduce)
        Total: 10-20 minutes for complex research
      
      mcp_handling: |
        - Must support async tool execution
        - Client polls get_workflow_status()
        - Server pushes progress via notifications
        - Client can cancel via stop_workflow()

  critical_data_structures:
    workflow_metadata:
      location: workflow-manager-sdk/src/lib.rs:9-23
      fields:
        - id: Unique workflow identifier
        - name: Human-readable name
        - description: Workflow purpose

    field_schema:
      location: workflow-manager-sdk/src/lib.rs:27-37
      fields:
        - name: Field identifier
        - field_type: FieldType enum
        - label: Display label
        - description: Help text (may contain [BOOL], [TEXT] markers)
        - cli_arg: CLI flag format (e.g., "--input")
        - required: Boolean or phase-specific
        - default: Optional default value
        - required_for_phases: Optional phase dependency

    field_type_enum:
      location: workflow-manager-sdk/src/lib.rs:40-65
      variants:
        - Text: Free-form string
        - Number: Integer with optional min/max
        - FilePath: Path with optional pattern matcher
        - Select: Enum with predefined options
        - PhaseSelector: Comma-separated phase numbers
        - StateFile: Resume file with pattern and phase

    workflow_log_enum:
      location: workflow-manager-sdk/src/lib.rs:119-191
      purpose: Structured event protocol
      emission: eprintln!("__WF_EVENT__:{}", json)
      consumption: Parsed in TUI stderr thread (main.rs:538-541)

    workflow_phase_hierarchy:
      location: main.rs:79-85
      structure: |
        WorkflowPhase {
          id, name, status,
          tasks: Vec<WorkflowTask> {
            id, phase, description, status,
            agents: Vec<WorkflowAgent> {
              id, task_id, name, description, status,
              messages: Vec<String>,
              result: Option<String>
            }
          },
          output_files: Vec<(path, description)>
        }

  recommended_mcp_api_operations:
    list_tools:
      returns: Array of workflow metadata
      sync: true
      caching: Cache discovery results, refresh on demand

    describe_tool:
      input: workflow_id
      returns: FullWorkflowMetadata with field schemas
      sync: true

    validate_tool_params:
      input: workflow_id, params JSON
      returns: validation_errors Array
      sync: true

    execute_tool:
      input: workflow_id, params JSON
      returns: execution_handle (UUID)
      sync: false
      notes: Returns immediately, execution continues async

    get_execution_status:
      input: execution_handle
      returns: status, current_phase, progress_percent
      sync: true
      polling: true

    stream_execution_logs:
      input: execution_handle, since_timestamp
      returns: Array of WorkflowLog events
      sync: false
      streaming: true

    get_execution_result:
      input: execution_handle
      returns: status, exit_code, output_files, logs
      sync: true
      notes: Blocks until completion or returns partial results

    cancel_execution:
      input: execution_handle
      returns: success boolean
      sync: true

    resume_workflow:
      input: workflow_id, phase_number, state_files
      returns: execution_handle
      sync: false
      notes: Advanced feature for resumable workflows

  implementation_notes:
    state_management: |
      - TUI uses Arc<Mutex<>> for thread-safe state sharing
      - MCP server should use async-safe state store (tokio::sync)
      - Each execution needs unique handle (UUID or timestamp-based)

    concurrency: |
      - TUI supports multiple concurrent tabs
      - MCP should support multiple concurrent tool executions
      - Use tokio tasks or thread pool for process management

    error_handling: |
      - Binary not found: Return clear error with binary_path
      - Validation failure: Return schema violations
      - Process crash: Capture stderr and exit code
      - Timeout: Consider adding timeout parameter for long workflows

    security: |
      - Validate binary paths (no arbitrary execution)
      - Sandbox workflow execution if needed
      - Limit concurrent executions
      - Rate limit MCP tool calls

  example_workflow_lifecycle:
    research_agent_via_tui:
      step_1: User selects "Research Agent Workflow" from list
      step_2: TUI loads field schema and history
      step_3: User fills fields (input, system_prompt, batch_size, phases)
      step_4: TUI validates required fields for selected phases
      step_5: User presses Enter to launch
      step_6: TUI creates tab, spawns process, parses logs
      step_7: Real-time updates show phase/task/agent progress
      step_8: User can navigate hierarchy, scroll agent messages
      step_9: On completion, output files displayed per phase
      step_10: Session saved for restoration on restart

    research_agent_via_mcp:
      step_1: MCP client lists tools → sees "research_agent"
      step_2: Client describes tool → gets field schema
      step_3: Client validates parameters locally
      step_4: Client calls execute_tool → receives handle
      step_5: Client polls get_execution_status every 5s
      step_6: Server pushes progress via notifications (optional)
      step_7: On completion, client calls get_execution_result
      step_8: Client retrieves output_files and displays to user
      step_9: If needed, client can resume from state files

  key_differences_tui_vs_mcp:
    tui:
      - Interactive field editing with history/autocomplete
      - Multi-tab concurrent execution
      - Real-time hierarchical progress tree
      - Session persistence across restarts
      - Direct file browser for state files

    mcp:
      - Programmatic parameter passing
      - Single-shot or polling-based progress
      - Flat or structured progress notifications
      - Stateless per connection (client manages state)
      - File paths as string parameters

    shared_capabilities:
      - Same workflow discovery mechanism
      - Same binary execution and log parsing
      - Same structured event protocol
      - Same state file resumption logic
      - Same validation rules